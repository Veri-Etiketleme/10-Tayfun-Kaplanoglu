{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import pickle\n",
    "from ipywidgets import widgets\n",
    "from ipywidgets import interactive, interact, fixed\n",
    "\n",
    "\n",
    "from IPython.display import display \n",
    "from IPython.display import Image\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from skimage import img_as_ubyte\n",
    "from thresholding_main import *\n",
    "from calibration_main import *\n",
    "from perspective_regionofint_main import *\n",
    "from sliding_main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#used for creating the image to write the final doc\n",
    "writeup = 0\n",
    "#used in interactive thresholding operation\n",
    "verbose_threshold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Threshold operation for debuggin only\n",
    "if writeup == 1:\n",
    "    img = mpimg.imread(\"test_images/straight_lines2.jpg\")\n",
    "    mtx, dist = get_camera_calibration()\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    if verbose_threshold == 1:\n",
    "        interact (thresholding_interative, img=fixed(img), adp_thr = (0,255), k_size = (1,31,2), grad_thx_min =(0,255), \n",
    "              grad_thx_max =(0,255),\n",
    "              grad_thy_min =(0,255), grad_thy_max = (0,255), mag_th_min = (0,255),\n",
    "              mag_th_max = (0,255), dir_th_min  = (0,2,0.1), dir_th_max = (0,2,.1), \n",
    "              s_threshold_min = (0,255), \n",
    "              s_threshold_max = (0,255), v_threshold_min = (0,255), v_threshold_max = (0,255));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Undistort for writeup\n",
    "if writeup == 1:\n",
    "    #test calibration for some image\n",
    "    mtx, dist = get_camera_calibration()\n",
    "    img = mpimg.imread(\"test_images/straight_lines2.jpg\")\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=40)\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('Undistorted', fontsize=40)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Prespective transform for writeup\n",
    "if writeup == 1:\n",
    "    #img = mpimg.imread(\"test_images/test3.jpg\")\n",
    "    img = mpimg.imread(\"test_images/test6.jpg\")\n",
    "\n",
    "    top_down, M = perspective_transform(img)\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    pts = np.array([[2, img.shape[0]-10], [img.shape[1]-5, img.shape[0]-10], [.55*img.shape[1], 0.625*img.shape[0]], [.45*img.shape[1], 0.625*img.shape[0]]], np.int32)\n",
    "    #cv2.polylines(img, [pts], True, (0,255,255), 3)\n",
    "    pts = np.array([[0.75*img.shape[1],5],[0.75*img.shape[1],img.shape[0]-5], [0.25*img.shape[1],img.shape[0]-5],[0.25*img.shape[1],5]], np.int32)\n",
    "    #cv2.polylines(top_down, [pts], True, (0,255,255), 3)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(top_down)\n",
    "    ax2.set_title('Perspective transformed', fontsize=30)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#region of interest for writeup:\n",
    "#Undistort\n",
    "if writeup == 1:\n",
    "    #test calibration for some image\n",
    "    mtx, dist = get_camera_calibration()\n",
    "    img = mpimg.imread(\"test_images/straight_lines2.jpg\")\n",
    "    imshape = img.shape\n",
    "    vertices = np.array([[(.55*imshape[1], 0.6*imshape[0]), (imshape[1],imshape[0]),\n",
    "                        (0,imshape[0]),(.45*imshape[1], 0.6*imshape[0])]], dtype=np.int32)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    dst1 = region_of_interest(dst, vertices)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(dst)\n",
    "    ax1.set_title('Original Image', fontsize=40)\n",
    "    ax2.imshow(dst1)\n",
    "    ax2.set_title('Region of Interest', fontsize=40)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_on_original(undist, left_fitx, right_fitx, ploty,Minv):\n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(undist).astype(np.uint8)\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane with low confidence region in red\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (255, 0, 0))\n",
    "    \n",
    "    #confidence region in green\n",
    "    shift = 50\n",
    "    diff = (right_fitx - left_fitx)/2\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx[400:], ploty[400:]]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx[400:], ploty[400:]])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (undist.shape[1], undist.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.4, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global mtx\n",
    "global dist\n",
    "mtx, dist = get_camera_calibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    #to select whether diagnostic video(1) or submission video(0)\n",
    "    verbose = 0\n",
    "    #undistor the image\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    #apply the thresholding operation\n",
    "    thresh_combined, grad_th, col_th = thresholding(undist)\n",
    "    #Perspective transformation\n",
    "    perspective, Minv = perspective_transform(thresh_combined)\n",
    "    perspective = cv2.cvtColor(perspective, cv2.COLOR_RGB2GRAY).astype(np.uint8)\n",
    "    #pass the perspective image to the lane fitting stage\n",
    "    slides_pers, left_fitx, right_fitx, ploty, avg_cur, dist_centre_val = for_sliding_window(perspective)\n",
    "    #draw the detected lanes on the original image \n",
    "    mapped_lane = draw_on_original(undist, left_fitx, right_fitx, ploty, Minv)\n",
    "    #font and text for drawing the offset and curvature \n",
    "    curvature = \"Estimated lane curvature %.2fm\" % (avg_cur)\n",
    "    dist_centre = \"Estimated offset from lane center %.2fm\" % (dist_centre_val)\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "    # using cv2 for drawing text/images in diagnostic pipeline.\n",
    "    if verbose == 1:\n",
    "        middlepanel = np.zeros((120, 900, 3), dtype=np.uint8)\n",
    "        l1 = np.zeros((50, 50, 3), dtype=np.uint8)\n",
    "        l2 = np.zeros((50, 50, 3), dtype=np.uint8)\n",
    "        l3 = np.zeros((50, 50, 3), dtype=np.uint8)\n",
    "        l4 = np.zeros((50, 50, 3), dtype=np.uint8)\n",
    "        l5 = np.zeros((50, 50, 3), dtype=np.uint8)\n",
    "        l6 = np.zeros((50, 50, 3), dtype=np.uint8)\n",
    "        l7 = np.zeros((50, 50, 3), dtype=np.uint8)\n",
    "        legend = np.zeros((240, 1200, 3), dtype=np.uint8)\n",
    "\n",
    "        cv2.putText(middlepanel, curvature, (30, 60), font, 1, (255,255,255), 2)\n",
    "        cv2.putText(middlepanel, dist_centre, (30, 90), font, 1, (255,255,255), 2)\n",
    "        cv2.putText(l1,\"1\", (15, 35), font, 1, (255,255,0), 2)\n",
    "        cv2.putText(l2,\"2\", (15, 30), font, 1, (255,255,0), 2)\n",
    "        cv2.putText(l3,\"3\", (15, 30), font, 1, (255,255,0), 2)\n",
    "        cv2.putText(l4,\"4\", (15, 30), font, 1, (255,255,0), 2)\n",
    "        cv2.putText(l5,\"5\", (15, 30), font, 1, (255,255,0), 2)\n",
    "        cv2.putText(l6,\"6\", (15, 30), font, 1, (255,255,0), 2)\n",
    "        cv2.putText(l7,\"7\", (15, 30), font, 1, (255,255,0), 2)\n",
    "        text = \"1-Detected Lanes, 2-Color Threshold\\n3-Gradient Threshold, 4-Thresholding operations combined\\n5-Perspective Transformation, 6-Original Frame\\n7-Mapping Polynomials, Blue line-current frame polynomial fit,\\nGreen line-smoothened polynomial fit, Pink - Lane pixels\"\n",
    "\n",
    "        y0, dy = 50, 40\n",
    "        for i, line in enumerate(text.split('\\n')):\n",
    "            y = y0 + i*dy\n",
    "            cv2.putText(legend, line, (50, y ), font, 1, (255,255,255),2)\n",
    "\n",
    "        diagScreen = np.zeros((1080, 1920, 3), dtype=np.uint8)\n",
    "        #2\n",
    "        diagScreen[0:360, 1200:1560] = cv2.resize(np.dstack((col_th*255,col_th*255, col_th*255)), (360,360), interpolation=cv2.INTER_AREA) \n",
    "        #3\n",
    "        diagScreen[0:360, 1560:1920] = cv2.resize(np.dstack((grad_th*255,grad_th*255,grad_th*255)), (360,360), interpolation=cv2.INTER_AREA) \n",
    "        #4\n",
    "        diagScreen[360:720, 1200:1560] = cv2.resize(thresh_combined*255, (360,360), interpolation=cv2.INTER_AREA) \n",
    "        #5\n",
    "        diagScreen[360:720,1560:1920] = cv2.resize(np.dstack((perspective*255, perspective*255, perspective*255)), (360,360), interpolation=cv2.INTER_AREA) \n",
    "        #7\n",
    "        diagScreen[720:1080,1560:1920] = cv2.resize(slides_pers, (360,360), interpolation=cv2.INTER_AREA) \n",
    "        #6\n",
    "        diagScreen[720:1080,1200:1560] = cv2.resize(img, (360,360), interpolation=cv2.INTER_AREA) \n",
    "        #1\n",
    "        diagScreen[0:720, 0:1200] = cv2.resize(mapped_lane, (1200,720), interpolation=cv2.INTER_AREA) \n",
    "\n",
    "        #radii,offset and legend here\n",
    "        diagScreen[720:840, 0:900] = middlepanel\n",
    "        diagScreen[0:50, 0:50] = l1\n",
    "        diagScreen[0:50, 1200: 1250] = l2\n",
    "        diagScreen[0:50, 1560:1610] = l3\n",
    "        diagScreen[720:770, 1560:1610] = l7\n",
    "        diagScreen[360:410, 1560:1610] = l5\n",
    "        diagScreen[720:770, 1200:1250] = l6\n",
    "        diagScreen[360:410, 1200:1250] = l4\n",
    "        diagScreen[840:1080, 0:1200] = legend\n",
    "        #if diagnosis then return this image \n",
    "        return diagScreen\n",
    "    #else return the original mapped imaged with the curvature and offset drawn\n",
    "    cv2.putText(mapped_lane, curvature, (30, 60), font, 1.2, (255,0,0), 2)\n",
    "    cv2.putText(mapped_lane, dist_centre, (30, 120), font, 1.2, (255,0,0), 2)\n",
    "    return mapped_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video result.mp4\n",
      "[MoviePy] Writing video result.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 79/80 [00:53<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: result.mp4 \n",
      "\n",
      "CPU times: user 2min 9s, sys: 3.56 s, total: 2min 13s\n",
      "Wall time: 55.2 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'result.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"900\" height=\"540\" controls>\n",
       "  <source src=\"result.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"900\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
