{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Traffic_training&testing_code.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1bzuTg6NucbqTMeFTC7iRzRrikoEvDkiJ","authorship_tag":"ABX9TyPBlI2o37lS5CY2IOdAaIFk"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jv3MiV0Va8Ct","executionInfo":{"status":"ok","timestamp":1633013059063,"user_tz":-60,"elapsed":43625,"user":{"displayName":"BHUVANESHWARAN B","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQWg8JVm54wwAT350_vAZuub6tgb-nc7g8NhTN0Q=s64","userId":"13821534792334262308"}},"outputId":"c3a57771-51af-454d-e875-b4d413717500"},"source":["\n","import keras\n","from keras.models import Sequential\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dense\n","from keras import backend as K\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing.image import img_to_array\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from imutils import paths\n","import numpy as np\n","import matplotlib\n","import random\n","import pickle\n","import cv2\n","import os\n","\n","# Parameters:-\n","EPOCHS = 75\n","INIT_LR = 1e-3\n","BS = 32\n","IMAGE_DIMS = (96, 96, 3)\n","\n","# Input image:-\n","imagePaths = sorted(list(paths.list_images(\"/content/drive/MyDrive/Colab Notebooks/Projects/Traffic_Image_Classification/Dataset\")))\n","random.seed(42)\n","random.shuffle(imagePaths)\n","\n","# Create an list:-\n","data=[]\n","labels=[]\n","\n","# loop over the input images\n","for imagePath in imagePaths:\n","\timage = cv2.imread(imagePath)\n","\timage = cv2.resize(image,(IMAGE_DIMS[1],IMAGE_DIMS[0]))\n","\timage = img_to_array(image)\n","\tdata.append(image)\n","  \n","\n","\tl = label = imagePath.split(os.path.sep)[-2].split('_')\n"," \n","\tlabels.append(l)\n","\n","# Convert into numpy both input & lables:-\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n","\n","# binarizer implementation\n","mlb = MultiLabelBinarizer()\n","labels = mlb.fit_transform(labels)\n","\n","\n","#  loop over each of the possible class labels and show them\n","for (i, label) in enumerate(mlb.classes_):\n","\tprint(\"{}. {}\".format(i + 1, label))\n","\n","# Split Training & Testing\n","(trainX, testX, trainY, testY) = train_test_split(data,labels,test_size=0.2, random_state=42)\n","\n","# # LENET ARCHITECTURE CODE\n","\n","# initialize the model\n","model = Sequential()\n","\n","# Rows & Columns  \n","imgRows=IMAGE_DIMS[0]\n","imgCols=IMAGE_DIMS[1]\n","numChannels=IMAGE_DIMS[2]\n","numClasses=3\n","inputShape = (imgRows, imgCols, numChannels)\n","\n","activation=\"relu\"\n","weightsPath=None\n","\n","# define the first set of CONV => ACTIVATION => POOL layers\n","model.add(Conv2D(20, 5, padding=\"same\",input_shape=inputShape))\n","model.add(Activation(activation))\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","# define the second set of CONV => ACTIVATION => POOL layers\n","model.add(Conv2D(50, 5, padding=\"same\"))\n","model.add(Activation(activation))\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","# define the first FC => ACTIVATION layers\n","model.add(Flatten())\n","model.add(Dense(500))\n","model.add(Activation(activation))\n","\n","# define the second FC layer\n","model.add(Dense(numClasses))\n","\n","\n","# lastly, define the soft-max classifier\n","model.add(Activation(\"softmax\"))\n","\n","# if a weights path is supplied (inicating that the model was\n","# pre-trained), then load the weights\n","if weightsPath is not None:\n","  model.load_weights(weightsPath)\n","\n","#compile \n","model.compile(loss = \"CategoricalCrossentropy\",optimizer = 'adam',metrics = ['accuracy'])\n","\n","# # fitting the model \n","hist = model.fit(x=trainX,y=trainY,epochs = 11,batch_size = 9,validation_data =(testX,testY),verbose = 1)\n","\n","# evaluate the model\n","test_score = model.evaluate(testX,testY)\n","print(\"Test loss {:.5f},accuracy {:.3f}\".format(test_score[0],test_score[1]*100))\n","\n","# Save the model\n","# model.save('TRAINING_EXPERIENCE.h5')\n","\n","# f = open(\"mlb.pickle\", \"wb\")\n","# f.write(pickle.dumps(mlb))\n","# f.close()\n","# print(trainX.shape)\n","# print(testX.shape)\n","\n","# print(trainY.shape)\n","# print(testY.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1. critical\n","2. good\n","3. warning\n","Epoch 1/11\n","4/4 [==============================] - 2s 347ms/step - loss: 1.8772 - accuracy: 0.3871 - val_loss: 1.1837 - val_accuracy: 0.1250\n","Epoch 2/11\n","4/4 [==============================] - 1s 285ms/step - loss: 1.0905 - accuracy: 0.3548 - val_loss: 1.0314 - val_accuracy: 0.7500\n","Epoch 3/11\n","4/4 [==============================] - 1s 282ms/step - loss: 1.0094 - accuracy: 0.7419 - val_loss: 0.9390 - val_accuracy: 0.7500\n","Epoch 4/11\n","4/4 [==============================] - 1s 292ms/step - loss: 0.8301 - accuracy: 0.6129 - val_loss: 1.2400 - val_accuracy: 0.2500\n","Epoch 5/11\n","4/4 [==============================] - 1s 284ms/step - loss: 0.5453 - accuracy: 0.9355 - val_loss: 1.2756 - val_accuracy: 0.5000\n","Epoch 6/11\n","4/4 [==============================] - 1s 290ms/step - loss: 0.2705 - accuracy: 0.9355 - val_loss: 1.8602 - val_accuracy: 0.7500\n","Epoch 7/11\n","4/4 [==============================] - 1s 280ms/step - loss: 0.3223 - accuracy: 0.8387 - val_loss: 4.0539 - val_accuracy: 0.1250\n","Epoch 8/11\n","4/4 [==============================] - 1s 282ms/step - loss: 0.4089 - accuracy: 0.8710 - val_loss: 1.6193 - val_accuracy: 0.2500\n","Epoch 9/11\n","4/4 [==============================] - 1s 279ms/step - loss: 0.2440 - accuracy: 1.0000 - val_loss: 2.1974 - val_accuracy: 0.2500\n","Epoch 10/11\n","4/4 [==============================] - 1s 278ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 2.2339 - val_accuracy: 0.7500\n","Epoch 11/11\n","4/4 [==============================] - 1s 279ms/step - loss: 0.3064 - accuracy: 0.8710 - val_loss: 1.6298 - val_accuracy: 0.8750\n","1/1 [==============================] - 0s 71ms/step - loss: 1.6298 - accuracy: 0.8750\n","Test loss 1.62980,accuracy 87.500\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"22os1QRBvmoY","executionInfo":{"status":"ok","timestamp":1633015295064,"user_tz":-60,"elapsed":1393,"user":{"displayName":"BHUVANESHWARAN B","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQWg8JVm54wwAT350_vAZuub6tgb-nc7g8NhTN0Q=s64","userId":"13821534792334262308"}},"outputId":"6ea44d84-931c-411b-c832-9f037f50e66a"},"source":["# OWN DATA SET IMAGE CLASSIFICATION USING LENET-ARCHITECTURE MODEL:-\n","\n","# Importing keras libraries and packages\n","from keras.models import load_model\n","from keras.preprocessing.image import img_to_array\n","import matplotlib\n","import numpy as np\n","import cv2\n","import pickle\n","import imutils\n","\n","# Load Model:-\n","model = load_model(\"/content/drive/MyDrive/Colab Notebooks/Projects/Projects/Traffic_image_classification/ARCHITECTURE/Models/TRAINING_EXPERIENCE.h5\")  #important\n","mlb = pickle.loads(open(\"/content/drive/MyDrive/Colab Notebooks/Projects/Projects/Traffic_image_classification/ARCHITECTURE/Models/mlb.pickle\",\"rb\").read())   #important\n","\n","# Read an Input image:-\n","image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Projects/Traffic_Image_Classification/Dataset/good/2.jpg')\n","output = imutils.resize(image,width=400)\n","image = cv2.resize(image, (96, 96))\n","image = image.astype(\"float\") / 255.0\n","image = img_to_array(image)\n","image = np.expand_dims(image, axis=0)\n","proba = model.predict(image)[0]\n","print(proba)\n","idxs = np.argsort(proba)[::-1][:2]\n","print(idxs)\n","\n","for (i, j) in enumerate(idxs):\n","\tlabel = \"{}: {:.2f}%\".format(mlb.classes_[j], proba[j] * 100)\n","\tcv2.putText(output, label, (10, (i * 30) + 25), \n","\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n"," \n","cv2.imwrite('/content/drive/MyDrive/Colab Notebooks/Projects/Projects/Traffic_image_classification/TASK/Sample_output/critical_2.jpg',output)\n"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[2.1528844e-05 9.9991953e-01 5.8832367e-05]\n","[1 2]\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"FaEuOZsvfv6f"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yKAZwd9ehhht"},"source":["# New Section"]}]}