{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Based Image Segmentation of DICOM Images - Testing\n",
    "### **```Author : BlackViper42```**\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "======\n",
    "\n",
    "------\n",
    " - This notebook consists of HeadRest Segmentation of CT Scan DICOM images of head patients downloaded from `gemsvnc server-3.204.27.254` of anonymous patients. \n",
    " \n",
    " \n",
    " - Currently this notebook predicts the segmented image of original `input_image` and this can be further taken to get `output_image` without headrest by multiplying `predicted_outcome` (binary labeled image) with `input_image`.\n",
    " \n",
    " \n",
    " - Prerequisites for this notebook:\n",
    "    - Graphics Card -------------------------------  NVIDIA  Quadro M5000 - 8GB \n",
    "    - `CUDA` toolkit 7.0 or above -------------------  installed  CUDA-8.0\n",
    "    - `cuDNN` 5.1 or above --------------------------  installed  cuDNN-5.1 \n",
    "    - `tensorflow-gpu` library\n",
    " \n",
    " - [please go through this link for installation of tensorflow-gpu](https://www.tensorflow.org/install/install_linux)\n",
    " - [Tensorflow implementation of Image Segmentation on Python](https://github.com/jakeret/tf_unet)\n",
    " \n",
    " \n",
    " - If you want to run this notebook without GPUs then install `tensorflow` library and comment these lines:\n",
    " \n",
    " ```python\n",
    " config = tf.ConfigProto()\n",
    " config.gpu_options.allow_growth = True``` \n",
    "  and change\n",
    "  ```python\n",
    "  tf.Session(config=config)```\n",
    "  by \n",
    "  ```python\n",
    "  tf.Session()```\n",
    " - In order to check whether GPU is correctly called by tensorflow run this line:\n",
    " ```python\n",
    " from tensorflow.python.client import device_lib\n",
    "local_device_protos = device_lib.list_local_devices()```\n",
    "and check the output you got on `terminal` where you initialized `Jupyter notebook`. If your output shows `(/gpu:0)` in last line then it is correct. If you are using Non-GPU tensorflow then your output should be `(/cpu:0)`.\n",
    "\n",
    "\n",
    "Project Description\n",
    "======\n",
    "\n",
    "______\n",
    "\n",
    "### Data\n",
    " - Input data consists of 2D dicom format images of ** 512*512 ** pixels of various patients. Input dataset reffered here as **`train_images_input`** contains 2490 images with grayscale values. \n",
    " - Labelled data consists of binary indicated images of **0s** and **1s** where **1s** tells presence of headrest and **0s** tells background without headrest.\n",
    "\n",
    "### Model\n",
    " - Model built here is 7 layer Convolutional nueral networks with pooling and upsampling. Below is the structure of network:\n",
    " \n",
    " - Parameters which are used in this model:\n",
    " \n",
    " \n",
    "| Parameter        | Value           | \n",
    "| ------------- |:-------------:| \n",
    "| Filter size   | **`3*3`**   |\n",
    "| Pool size    | **`2*2`**   |\n",
    "| Zero Padding  | **`1`**  |\n",
    "| Padding    | **`VALID`**   |\n",
    "| Cost Function      | **`Softmax Cross Entropy`** | \n",
    "| Optimizer      |  **`Momentum`**    |  \n",
    "| Epocs | **`150`**      | \n",
    "| Training Iterations     | **`50`** |\n",
    "| Learning Rate        |  **`0.2`**  |\n",
    "| Decay Rate         |  **`0.95`**   |\n",
    "\n",
    "\n",
    "\n",
    " - Accuracy is calculated on pixel wise correct classification of an image. \n",
    " - Predictions after each epoc is stored in **`prediction_model_50_500_3`** folder.\n",
    " - Model outputs are stored in pickel format in **`unet_trained_50_500_3`** folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "## ``` Importing Libraries```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function,absolute_import, unicode_literals\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt                                    ##...Plotting libraries\n",
    "import matplotlib                                                  \n",
    "import numpy as np                                                 ##...for mathematical operations\n",
    "import glob                                                        ##...for importing directories and paths\n",
    "from PIL import Image                                              ##...for saving images\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "from collections import OrderedDict\n",
    "import logging                                                     ##...for making logs on progress based on real time\n",
    "import tensorflow as tf                                            ##...for building Convolutional Neural Networks \n",
    "import dicom\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy.ndimage\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from sklearn.cluster import KMeans\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.graph_objs import *\n",
    "from matplotlib.patches import Ellipse\n",
    "from skimage import io, color, measure, draw, img_as_bool\n",
    "from scipy import optimize\n",
    "import pandas as pd\n",
    "from skimage import color\n",
    "import scipy.misc\n",
    "import sys\n",
    "import zipfile\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib                    ##...to check whether GPU is called properly or not\n",
    "local_device_protos = device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()                                          ##...to allow bfc::Allocator provide more than default \n",
    "config.gpu_options.allow_growth = True                             ##...memory  to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "## ``` Importing Data :: Preprocessing```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Importing Data from the given **```input_folder```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path = \"/home/ctuser/images/input/input.tar\"\n",
    "data_path = \"/home/ctuser/images/input/\"\n",
    "output_data_path = \"/home/ctuser/images/output/\"\n",
    "a=[]\n",
    "z = tarfile.open(input_path, \"r\")\n",
    "z.extractall(data_path)\n",
    "\n",
    "\n",
    "#z = zipfile.ZipFile(input_path, \"r\")\n",
    "#z.extractall(data_path)\n",
    "for filename in z.getnames():\n",
    "    a.append(filename.split(\"/\")[1] +\"-out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Loading CT Scan Images and calculate HU units for each pixels\n",
    "\n",
    "> **```load_scan```** : loading all the image slices for each patient folder\n",
    "\n",
    "> **```get_pixels_hu```** : Storing HU_units pixel array in **```numpy```** format for image processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_scan(path):\n",
    "    slices = [dicom.read_file(path + '/' + s) for s in z.getnames()]\n",
    "    #a=[]\n",
    "    #for s in slices:\n",
    "    #    a.append(s.InstanceNumber)\n",
    "    #slices.sort(key = lambda x: int(x.InstanceNumber))\n",
    "    #try:\n",
    "    #    slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    #except:\n",
    "    #    slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "    #for s in slices:\n",
    "    #    s.SliceThickness = slice_thickness\n",
    "    return slices\n",
    "\n",
    "def get_pixels_hu(scans):\n",
    "    image = np.stack([s.pixel_array for s in scans])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "\n",
    "    # Set outside-of-scan pixels to 1\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    image[image == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    intercept = scans[0].RescaleIntercept\n",
    "    slope = scans[0].RescaleSlope\n",
    "    \n",
    "    if slope != 1:\n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "        \n",
    "    image += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "#def store_dcm_format(output_data_path, patient_out, out_test, a):\n",
    "#    #nx = out_test.shape[1]\n",
    "#    #ny = out_test.shape[2]\n",
    "#    #out_test = out_test.reshape((-1,nx,ny))\n",
    "#    out_test = out_test*4000.\n",
    "#    out_test = out_test.astype(np.int16)\n",
    "#    out_test_zip = zipfile.ZipFile(output_data_path+\"out_test.zip\", 'w')\n",
    "#    for i in range(0,len(patient_out)):\n",
    "#        #print(np.unique(patient_out[0].pixel_array))\n",
    "#        #outo = out_test[i,...,0].flat\n",
    "#        #print(np.unique(out_test[i,...,0]))\n",
    "#        patient_out[i].pixel_array = out_test[i,...,0]\n",
    "#        #print(np.unique(patient_out[0].pixel_array))\n",
    "#        #patient_out[i].pixel_array\n",
    "#        patient_out[i].PixelData = patient_out[i].pixel_array.tostring()\n",
    "#        storing_path = a[i]\n",
    "#        #patient_out[i].save_as(output_data_path+\"/\"+storing_path)\n",
    "#        dicom.write_file(output_data_path+\"/\"+storing_path, patient_out[i])    \n",
    "#        #out_test_zip.write(storing_path, compress_type=zipfile.ZIP_DEFLATED)\n",
    "#    \n",
    "#    out_test_zip.close()\n",
    "        \n",
    "\n",
    "id=1000000\n",
    "patient = load_scan(data_path)\n",
    "patient_out = load_scan(data_path)\n",
    "imgs = get_pixels_hu(patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offset = np.ones_like(imgs,dtype=np.float32)\n",
    "imgs = imgs.astype(\"float32\")\n",
    "offset = offset*1024.\n",
    "imgs+=offset\n",
    "offset=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Creating Class - **```BaseDataProvider```** for importing data and making **```4D Tensors```** and giving batch-wise output when called.\n",
    "\n",
    "> Parameter here is **```n```** - Number of randomly sample data you want to call in **```4D Tensor```** format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseDataProvider(object):\n",
    "    \"\"\"\n",
    "    This class is used to import, preprocessing of data\n",
    "    before feeding into Convolutional neural networks.\n",
    "    It also create labels into same fashion.\n",
    "    \"\"\"\n",
    "    \n",
    "    #channels = 1\n",
    "    #n_class = 2\n",
    "    def __init__(self,data,a_min=None,a_max=None,channels =1,n_class =2):\n",
    "        self.a_min = a_min if a_min is not None else -np.inf\n",
    "        self.a_max = a_max if a_max is not None else np.inf\n",
    "        self.data = data\n",
    "        self.file_count = data.shape[0]\n",
    "        self.n_class=n_class\n",
    "        self.channels = channels\n",
    "    \n",
    "    def _next_data(self,i):\n",
    "        #idx = np.random.choice(self.file_count)\n",
    "        return self.data[i]\n",
    "    \n",
    "    def _load_data_and_label(self,i):\n",
    "        data = self._next_data(i)\n",
    "        \n",
    "        train_data, min_data_i, max_data_i = self._process_data(data)\n",
    "        \n",
    "        train_data = self._postprocess_data(train_data)\n",
    "        \n",
    "        nx = data.shape[1]\n",
    "        ny = data.shape[0]\n",
    "        \n",
    "        return train_data.reshape(1, ny, nx, self.channels), min_data_i, max_data_i\n",
    "    \n",
    "    def _process_data(self, data):\n",
    "        data = np.clip(data, self.a_min, self.a_max)\n",
    "        min_val = np.amin(data)\n",
    "        max_val = np.amax(data)\n",
    "        data = data-np.amin(data)    \n",
    "        data = data/np.amax(data)\n",
    "        return data, min_val, max_val\n",
    "    \n",
    "    def _postprocess_data(self,data):\n",
    "        \"\"\"\n",
    "        Post processing can be done to make it more easier \n",
    "        for CNN to work and give better accuracy.\n",
    "        \n",
    "        \"\"\"\n",
    "        return data\n",
    "    \n",
    "    def __call__(self,n):\n",
    "        i=0\n",
    "        train_data, min_data_i, max_data_i = self._load_data_and_label(i)\n",
    "        nx = train_data.shape[1]\n",
    "        ny = train_data.shape[2]\n",
    "        \n",
    "        X = np.zeros((n, nx, ny, self.channels))\n",
    "        Y = np.zeros((n, 2))\n",
    "        X[0] = train_data\n",
    "        Y[0, 0] = min_data_i\n",
    "        Y[0, 1] = max_data_i\n",
    "        for i in range(1,n):\n",
    "            train_data, min_data_i, max_data_i = self._load_data_and_label(i)\n",
    "            X[i] = train_data\n",
    "            Y[i, 0] = min_data_i\n",
    "            Y[i, 1] = max_data_i\n",
    "            \n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydata = BaseDataProvider(data=imgs,channels=1,n_class=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = imgs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, minmax = mydata(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "## **```Building Convolutional Networks```**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Defining some functions which we will use in later part of notebook:\n",
    "  - **```plot_prediction```** : takes ```test_data, labels, predictions``` and plot the images; can be used to save the output as well.\n",
    "  - **```crop_to_shape```** : crop ```initial_tensor``` to ```final_tensor``` shape\n",
    "  - **```to_rgb```** : convert given image to RGB format; not used here\n",
    "  - **```error_rate```** : error of prediction in **%** format\n",
    "  - **```get_image_summary```** : gives image summary \n",
    "  - **```combine_img_prediction ```** : Combines the data, grouth thruth and the prediction into one rgb image; amethod to visualize\n",
    "  - **```save_image ```** : to save the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_prediction(x_test, prediction, save=False):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    test_size = x_test.shape[0]\n",
    "    fig, ax = plt.subplots(test_size, 2, figsize=(20,15), sharey=True, sharex=True)\n",
    "    ax = np.atleast_2d(ax)\n",
    "    for i in range(test_size):\n",
    "        cax = ax[i, 0].imshow(x_test[i,...,0])\n",
    "        plt.colorbar(cax, ax=ax[i,0])\n",
    "        #cax = ax[i, 1].imshow(y_test[i, ..., 1])\n",
    "        #plt.colorbar(cax, ax=ax[i,1])\n",
    "        pred = prediction[i, ..., 1]\n",
    "        #pred -= np.amin(pred)                           ## recheck this :: might create some errors later.\n",
    "        #pred /= np.amax(pred)\n",
    "        cax = ax[i, 1].imshow(pred)\n",
    "        plt.colorbar(cax, ax=ax[i,1])\n",
    "        if i==0:\n",
    "            ax[i, 0].set_title(\"x\")\n",
    "            #ax[i, 1].set_title(\"y\")\n",
    "            ax[i, 1].set_title(\"pred\")\n",
    "    #fig.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        fig.savefig(save)\n",
    "    else:\n",
    "        fig.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def storing_dicom(x_test, prediction):\n",
    "    out_test = np.zeros_like(x_test,dtype=\"float32\")\n",
    "    test_size = x_test.shape[0]\n",
    "    for i in range(test_size):\n",
    "        ini = x_test[i,...,0]\n",
    "        pred = prediction[i, ..., 1]\n",
    "        mask = np.zeros_like(pred,dtype=\"float32\")\n",
    "        mask_2 = np.ones_like(pred,dtype=\"float32\")\n",
    "        mask[pred>=0.5]=1.0\n",
    "        dilation = morphology.dilation(mask,np.ones([4,4]))\n",
    "        mask = mask_2-dilation\n",
    "        out = mask*ini\n",
    "        out_test[i,...,0]=out\n",
    "    #for i in range(test_size):\n",
    "    #    pred = out_test[i,...,0]\n",
    "    #    path = \"%s/%s.jpg\"%(output_path, \"slice_%s\"%i)\n",
    "    #    scipy.misc.imsave(path, pred)\n",
    "    return out_test       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_to_shape(data, shape):\n",
    "    \"\"\"\n",
    "    Crops the array to the given image shape by removing the border (expects a tensor of shape [batches, nx, ny, channels].\n",
    "    \n",
    "    :param data: the array to crop\n",
    "    :param shape: the target shape\n",
    "    \"\"\"\n",
    "    offset0 = (data.shape[1] - shape[1])//2\n",
    "    offset1 = (data.shape[2] - shape[2])//2\n",
    "    if data.shape[1] == shape[1]:\n",
    "        return data\n",
    "    else:\n",
    "        return data[:, offset0:(-offset0), offset1:(-offset1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_rgb(img):\n",
    "    \"\"\"\n",
    "    Converts the given array into a RGB image. If the number of channels is not\n",
    "    3 the array is tiled such that it has 3 channels. Finally, the values are\n",
    "    rescaled to [0,255) \n",
    "    \n",
    "    :param img: the array to convert [nx, ny, channels]\n",
    "    \n",
    "    :returns img: the rgb image [nx, ny, 3]\n",
    "    \"\"\"\n",
    "    img = np.atleast_3d(img)\n",
    "    channels = img.shape[2]\n",
    "    if channels < 3:\n",
    "        img = np.tile(img, 3)\n",
    "    \n",
    "    img[np.isnan(img)] = 0\n",
    "    img -= np.amin(img)\n",
    "    img /= np.amax(img)\n",
    "    img *= 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_rate(predictions, labels):\n",
    "    \"\"\"\n",
    "    Return the error rate based on dense predictions and 1-hot labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    return 100.0 - (100.0 * np.sum(np.argmax(predictions, 3) == np.argmax(labels, 3)) /\n",
    "                    (predictions.shape[0]*predictions.shape[1]*predictions.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_summary(img, idx=0):\n",
    "    \"\"\"\n",
    "    Make an image summary for 4d tensor image with index idx\n",
    "    \"\"\"\n",
    "    \n",
    "    V = tf.slice(img, (0, 0, 0, idx), (1, -1, -1, 1))\n",
    "    V -= tf.reduce_min(V)\n",
    "    V /= tf.reduce_max(V)\n",
    "    V *= 255\n",
    "    \n",
    "    img_w = tf.shape(img)[1]\n",
    "    img_h = tf.shape(img)[2]\n",
    "    V = tf.reshape(V, tf.stack((img_w, img_h, 1)))\n",
    "    V = tf.transpose(V, (2, 0, 1))\n",
    "    V = tf.reshape(V, tf.stack((-1, img_w, img_h, 1)))\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_img_prediction(data, gt, pred):\n",
    "    \"\"\"\n",
    "    Combines the data, grouth thruth and the prediction into one rgb image\n",
    "    \n",
    "    :param data: the data tensor\n",
    "    :param gt: the ground thruth tensor\n",
    "    :param pred: the prediction tensor\n",
    "    \n",
    "    :returns img: the concatenated rgb image \n",
    "    \"\"\"\n",
    "    ny = pred.shape[2]\n",
    "    ch = data.shape[3]\n",
    "    img = np.concatenate((to_rgb(crop_to_shape(data, pred.shape).reshape(-1, ny, ch)), \n",
    "                          to_rgb(crop_to_shape(gt[..., 1], pred.shape).reshape(-1, ny, 1)), \n",
    "                          to_rgb(pred[..., 1].reshape(-1, ny, 1))), axis=1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def save_image(img, path):\n",
    "    \"\"\"\n",
    "    Writes the image to disk\n",
    "    \n",
    "    :param img: the rgb image to save\n",
    "    :param path: the target path\n",
    "    \"\"\"\n",
    "    Image.fromarray(img.round().astype(np.uint8)).save(path, 'JPEG', dpi=[300,300], quality=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **```layers initialization functions```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, stddev=0.1):\n",
    "    initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def weight_variable_devonc(shape, stddev=0.1):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=stddev))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W,keep_prob_):\n",
    "    conv_2d = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    return tf.nn.dropout(conv_2d, keep_prob_)\n",
    "\n",
    "def deconv2d(x, W,stride):\n",
    "    x_shape = tf.shape(x)\n",
    "    output_shape = tf.stack([x_shape[0], x_shape[1]*2, x_shape[2]*2, x_shape[3]//2])\n",
    "    return tf.nn.conv2d_transpose(x, W, output_shape, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "def max_pool(x,n):\n",
    "    return tf.nn.max_pool(x, ksize=[1, n, n, 1], strides=[1, n, n, 1], padding='VALID')\n",
    "\n",
    "def crop_and_concat(x1,x2):\n",
    "    x1_shape = tf.shape(x1)\n",
    "    x2_shape = tf.shape(x2)\n",
    "    # offsets for the top left corner of the crop\n",
    "    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2, 0]\n",
    "    size = [-1, x2_shape[1], x2_shape[2], -1]\n",
    "    x1_crop = tf.slice(x1, offsets, size)\n",
    "    return tf.concat([x1_crop, x2], 3)   \n",
    "\n",
    "def pixel_wise_softmax(output_map):\n",
    "    exponential_map = tf.exp(output_map)\n",
    "    evidence = tf.add(exponential_map,tf.reverse(exponential_map,[False,False,False,True]))\n",
    "    return tf.div(exponential_map,evidence, name=\"pixel_wise_softmax\")\n",
    "\n",
    "def pixel_wise_softmax_2(output_map):\n",
    "    exponential_map = tf.exp(output_map)\n",
    "    sum_exp = tf.reduce_sum(exponential_map, 3, keep_dims=True)\n",
    "    tensor_sum_exp = tf.tile(sum_exp, tf.stack([1, 1, 1, tf.shape(output_map)[3]]))\n",
    "    return tf.div(exponential_map,tensor_sum_exp)\n",
    "\n",
    "def cross_entropy(y_,output_map):\n",
    "    return -tf.reduce_mean(y_*tf.log(tf.clip_by_value(output_map,1e-10,1.0)), name=\"cross_entropy\")\n",
    "#     return tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(output_map), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')  ## to get log of real time and progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "______\n",
    "## **```Model Training```**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> **``` Model_3 layer ```** : layers = 7 with convolutional varying : 2,4,8 each 3,3,1 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_conv_net_3(x, keep_prob, channels, n_class, layers=7, features_root=16, filter_size=3, pool_size=2, summaries=False):\n",
    "    \"\"\"\n",
    "    Creates a new convolutional unet for the given parametrization.\n",
    "    \n",
    "    :param x: input tensor, shape [?,nx,ny,channels]\n",
    "    :param keep_prob: dropout probability tensor\n",
    "    :param channels: number of channels in the input image\n",
    "    :param n_class: number of output labels\n",
    "    :param layers: number of layers in the net\n",
    "    :param features_root: number of features in the first layer\n",
    "    :param filter_size: size of the convolution filter\n",
    "    :param pool_size: size of the max pooling operation\n",
    "    :param summaries: Flag if summaries should be created\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(\"Layers {layers}, features {features}, filter size {filter_size}x{filter_size},pool size: {pool_size}x{pool_size}\".format(layers=layers,\n",
    "                                                                                                           features=features_root,\n",
    "                                                                                                           filter_size=filter_size,\n",
    "                                                                                                           pool_size=pool_size))\n",
    "    # Placeholder for the input image\n",
    "    nx = tf.shape(x)[1]\n",
    "    ny = tf.shape(x)[2]\n",
    "    x_image = tf.reshape(x, tf.stack([-1,nx,ny,channels]))\n",
    "    in_node = x_image\n",
    "    batch_size = tf.shape(x_image)[0]\n",
    " \n",
    "    weights1 = []\n",
    "    weights2= []\n",
    "    weights3 = []\n",
    "    biases1 = []\n",
    "    biases2 = []\n",
    "    biases3 = []\n",
    "    convs1 = []\n",
    "    convs2 = []\n",
    "    convs3 = []\n",
    "    pools = OrderedDict()\n",
    "    deconv = OrderedDict()\n",
    "    dw_h_convs = OrderedDict()\n",
    "    up_h_convs = OrderedDict()\n",
    "    paddings=[[0,0],[1,1],[1,1],[0,0]]\n",
    "    in_size = 1000\n",
    "    size = in_size\n",
    "    # down layers\n",
    "    for layer in range(0, layers):\n",
    "        features = 2**layer*features_root\n",
    "        stddev = np.sqrt(2 / (filter_size**2 * features))\n",
    "        if layer == 0:\n",
    "            w1 = weight_variable([filter_size, filter_size, channels, features], stddev)\n",
    "        else:\n",
    "            w1 = weight_variable([filter_size, filter_size, features//2, features], stddev)\n",
    "            \n",
    "        w2 = weight_variable([filter_size, filter_size, features, features], stddev)\n",
    "        b1 = bias_variable([features])\n",
    "        b2 = bias_variable([features])\n",
    "        \n",
    "        in_node = tf.pad(in_node,paddings,\"CONSTANT\")\n",
    "        conv1 = conv2d(in_node, w1, keep_prob)\n",
    "        tmp_h_conv = tf.nn.relu(conv1 + b1)\n",
    "        tmp_h_conv = tf.pad(tmp_h_conv,paddings,\"CONSTANT\")\n",
    "        conv2 = conv2d(tmp_h_conv, w2, keep_prob)\n",
    "        if layer>=3:\n",
    "            tmp_h_conv2 = tf.nn.relu(conv2 + b2)\n",
    "        else:\n",
    "            dw_h_convs[layer] = tf.nn.relu(conv2 + b2)\n",
    "        \n",
    "        ####\n",
    "        if layer>=3:\n",
    "            w3 = weight_variable([filter_size, filter_size, features, features], stddev)\n",
    "            b3 = bias_variable([features])\n",
    "            w4 = weight_variable([filter_size, filter_size, features, features], stddev)\n",
    "            b4 = bias_variable([features])\n",
    "            tmp_h_conv2 = tf.pad(tmp_h_conv2,paddings,\"CONSTANT\")\n",
    "            conv3 = conv2d(tmp_h_conv2, w3, keep_prob)\n",
    "            tmp_h_conv3 = tf.nn.relu(conv3 +b3)\n",
    "            tmp_h_conv3 = tf.pad(tmp_h_conv3,paddings,\"CONSTANT\")\n",
    "            conv4 = conv2d(tmp_h_conv3, w4, keep_prob)\n",
    "            if layer>=6:\n",
    "                tmp_h_conv4 = tf.nn.relu(conv4 + b4)\n",
    "            else:\n",
    "                dw_h_convs[layer] = tf.nn.relu(conv4 + b4)\n",
    "        ####\n",
    "        ####\n",
    "        if layer>=6:\n",
    "            w5 = weight_variable([filter_size, filter_size, features, features], stddev)\n",
    "            b5 = bias_variable([features])\n",
    "            w6 = weight_variable([filter_size, filter_size, features, features], stddev)\n",
    "            b6 = bias_variable([features])\n",
    "            w7 = weight_variable([filter_size, filter_size, features, features], stddev)\n",
    "            b7 = bias_variable([features])\n",
    "            w8 = weight_variable([filter_size, filter_size, features, features], stddev)\n",
    "            b8 = bias_variable([features])\n",
    "            tmp_h_conv4 = tf.pad(tmp_h_conv4,paddings,\"CONSTANT\")\n",
    "            conv5 = conv2d(tmp_h_conv4, w5, keep_prob)\n",
    "            tmp_h_conv5 = tf.nn.relu(conv5 +b5)\n",
    "            tmp_h_conv5 = tf.pad(tmp_h_conv5,paddings,\"CONSTANT\")\n",
    "            conv6 = conv2d(tmp_h_conv5, w6, keep_prob)\n",
    "            tmp_h_conv6 = tf.nn.relu(conv6 +b6)\n",
    "            tmp_h_conv6 = tf.pad(tmp_h_conv6,paddings,\"CONSTANT\")\n",
    "            conv7 = conv2d(tmp_h_conv6, w7, keep_prob)\n",
    "            tmp_h_conv7 = tf.nn.relu(conv7 +b7)\n",
    "            tmp_h_conv7 = tf.pad(tmp_h_conv7,paddings,\"CONSTANT\")\n",
    "            conv8 = conv2d(tmp_h_conv7, w8, keep_prob)\n",
    "            dw_h_convs[layer] = tf.nn.relu(conv8 + b8)\n",
    "        ####\n",
    "        if layer<3:\n",
    "            weights1.append((w1, w2))\n",
    "            biases1.append((b1, b2))\n",
    "            convs1.append((conv1, conv2))\n",
    "        ####\n",
    "        if layer>=3 and layer<6:\n",
    "            weights2.append((w1, w2, w3, w4))\n",
    "            biases2.append((b1, b2, b3, b4))\n",
    "            convs2.append((conv1, conv2, conv3, conv4))\n",
    "        ####\n",
    "        ####\n",
    "        if layer>=6:\n",
    "            weights3.append((w1, w2, w3, w4, w5, w6, w7, w8))\n",
    "            biases3.append((b1, b2, b3, b4, b5, b6, b7,  b8))\n",
    "            convs3.append((conv1, conv2, conv3, conv4, conv5, conv6, conv7, conv8))\n",
    "        ####\n",
    "        \n",
    "        size -= 4\n",
    "        if layer < layers-1:\n",
    "            pools[layer] = max_pool(dw_h_convs[layer], pool_size)\n",
    "            in_node = pools[layer]\n",
    "            size /= 2\n",
    "        \n",
    "    in_node = dw_h_convs[layers-1]\n",
    "        \n",
    "    # up layers\n",
    "    for layer in range(layers-2, -1, -1):\n",
    "        \n",
    "        features = 2**(layer+1)*features_root\n",
    "        stddev = np.sqrt(2 / (filter_size**2 * features))\n",
    "        \n",
    "        wd = weight_variable_devonc([pool_size, pool_size, features//2, features], stddev)\n",
    "        bd = bias_variable([features//2])\n",
    "        h_deconv = tf.nn.relu(deconv2d(in_node, wd, pool_size) + bd)\n",
    "        h_deconv_concat = crop_and_concat(dw_h_convs[layer], h_deconv)\n",
    "        deconv[layer] = h_deconv_concat\n",
    "        \n",
    "        w1 = weight_variable([filter_size, filter_size, features, features//2], stddev)\n",
    "        w2 = weight_variable([filter_size, filter_size, features//2, features//2], stddev)\n",
    "        b1 = bias_variable([features//2])\n",
    "        b2 = bias_variable([features//2])\n",
    "        \n",
    "        h_deconv_concat = tf.pad(h_deconv_concat,paddings,\"CONSTANT\")\n",
    "        conv1 = conv2d(h_deconv_concat, w1, keep_prob)\n",
    "        h_conv = tf.nn.relu(conv1 + b1)\n",
    "        h_conv = tf.pad(h_conv,paddings,\"CONSTANT\")\n",
    "        conv2 = conv2d(h_conv, w2, keep_prob)\n",
    "        if layer>=3:\n",
    "            w3 = weight_variable([filter_size, filter_size, features//2, features//2], stddev)\n",
    "            b3 = bias_variable([features//2])\n",
    "            w4 = weight_variable([filter_size, filter_size, features//2, features//2], stddev)\n",
    "            b4 = bias_variable([features//2])\n",
    "            h_conv2 = tf.nn.relu(conv2 + b2)\n",
    "            h_conv2 = tf.pad(h_conv2,paddings,\"CONSTANT\")\n",
    "            conv3 = conv2d(h_conv2, w3, keep_prob)\n",
    "            h_conv3 = tf.nn.relu(conv3 + b3)\n",
    "            h_conv3 = tf.pad(h_conv3,paddings,\"CONSTANT\")\n",
    "            conv4 = conv2d(h_conv3, w4, keep_prob)\n",
    "            in_node = tf.nn.relu(conv4 + b4)\n",
    "            up_h_convs[layer] = in_node\n",
    "        else:\n",
    "            in_node = tf.nn.relu(conv2 + b2)\n",
    "            up_h_convs[layer] = in_node\n",
    "\n",
    "        ####\n",
    "        if layer<3:\n",
    "            weights1.append((w1, w2))\n",
    "            biases1.append((b1, b2))\n",
    "            convs1.append((conv1, conv2))\n",
    "        ####\n",
    "        if layer>=3:\n",
    "            weights2.append((w1, w2, w3, w4))\n",
    "            biases2.append((b1, b2, b3, b4))\n",
    "            convs2.append((conv1, conv2, conv3, conv4))\n",
    "        \n",
    "        size *= 2\n",
    "        size -= 4\n",
    "\n",
    "    # Output Map\n",
    "    weight = weight_variable([1, 1, features_root, n_class], stddev)\n",
    "    bias = bias_variable([n_class])\n",
    "    conv = conv2d(in_node, weight, tf.constant(1.0))\n",
    "    output_map = tf.nn.relu(conv + bias)\n",
    "    up_h_convs[\"out\"] = output_map\n",
    "    \n",
    "    if summaries:\n",
    "        for i, (c1, c2) in enumerate(convs):\n",
    "            tf.summary.image('summary_conv_%02d_01'%i, get_image_summary(c1))\n",
    "            tf.summary.image('summary_conv_%02d_02'%i, get_image_summary(c2))\n",
    "            \n",
    "        for k in pools.keys():\n",
    "            tf.summary.image('summary_pool_%02d'%k, get_image_summary(pools[k]))\n",
    "        \n",
    "        for k in deconv.keys():\n",
    "            tf.summary.image('summary_deconv_concat_%02d'%k, get_image_summary(deconv[k]))\n",
    "            \n",
    "        for k in dw_h_convs.keys():\n",
    "            tf.summary.histogram(\"dw_convolution_%02d\"%k + '/activations', dw_h_convs[k])\n",
    "\n",
    "        for k in up_h_convs.keys():\n",
    "            tf.summary.histogram(\"up_convolution_%s\"%k + '/activations', up_h_convs[k])\n",
    "            \n",
    "    variables = []\n",
    "    for w1,w2 in weights1:\n",
    "        variables.append(w1)\n",
    "        variables.append(w2)\n",
    "    \n",
    "    for w1,w2,w3,w4 in weights2:\n",
    "        variables.append(w1)\n",
    "        variables.append(w2)\n",
    "        variables.append(w3)\n",
    "        variables.append(w4)\n",
    "    \n",
    "    for w1,w2,w3,w4,w5,w6,w7,w8 in weights3:\n",
    "        variables.append(w1)\n",
    "        variables.append(w2)\n",
    "        variables.append(w3)\n",
    "        variables.append(w4)\n",
    "        variables.append(w5)\n",
    "        variables.append(w6)\n",
    "        variables.append(w7)\n",
    "        variables.append(w8)\n",
    "    \n",
    "    for b1,b2 in biases1:\n",
    "        variables.append(b1)\n",
    "        variables.append(b2)\n",
    "        \n",
    "    for b1,b2,b3,b4 in biases2:\n",
    "        variables.append(b1)\n",
    "        variables.append(b2)\n",
    "        variables.append(b3)\n",
    "        variables.append(b4)\n",
    "    \n",
    "    for b1,b2,b3,b4,b5,b6,b7,b8 in biases3:\n",
    "        variables.append(b1)\n",
    "        variables.append(b2)\n",
    "        variables.append(b3)\n",
    "        variables.append(b4)\n",
    "        variables.append(b5)\n",
    "        variables.append(b6)\n",
    "        variables.append(b7)\n",
    "        variables.append(b8)\n",
    "\n",
    "    \n",
    "    return output_map, variables, int(in_size - size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Unet(object):\n",
    "    \"\"\"\n",
    "    A unet implementation\n",
    "    \n",
    "    :param channels: (optional) number of channels in the input image\n",
    "    :param n_class: (optional) number of output labels\n",
    "    :param cost: (optional) name of the cost function. Default is 'cross_entropy'\n",
    "    :param cost_kwargs: (optional) kwargs passed to the cost function. See Unet._get_cost for more options\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels=1, n_class=2, cost=\"cross_entropy\", cost_kwargs={}, **kwargs):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.n_class = n_class\n",
    "        self.summaries = kwargs.get(\"summaries\", True)\n",
    "        \n",
    "        self.x = tf.placeholder(\"float\", shape=[None, None, None, channels])\n",
    "        self.y = tf.placeholder(\"float\", shape=[None, None, None, n_class])\n",
    "        self.keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "        \n",
    "        logits, self.variables, self.offset = create_conv_net_3(self.x, self.keep_prob, channels, n_class, **kwargs)\n",
    "        \n",
    "        self.cost = self._get_cost(logits, cost, cost_kwargs)\n",
    "        \n",
    "        self.gradients_node = tf.gradients(self.cost, self.variables)\n",
    "         \n",
    "        self.cross_entropy = tf.reduce_mean(cross_entropy(tf.reshape(self.y, [-1, n_class]),\n",
    "                                                          tf.reshape(pixel_wise_softmax_2(logits), [-1, n_class])))\n",
    "        \n",
    "        self.predicter = pixel_wise_softmax_2(logits)\n",
    "        self.correct_pred = tf.equal(tf.argmax(self.predicter, 3), tf.argmax(self.y, 3))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n",
    "        \n",
    "    def _get_cost(self, logits, cost_name, cost_kwargs):\n",
    "        \"\"\"\n",
    "        Constructs the cost function, either cross_entropy, weighted cross_entropy or dice_coefficient.\n",
    "        Optional arguments are: \n",
    "        class_weights: weights for the different classes in case of multi-class imbalance\n",
    "        regularizer: power of the L2 regularizers added to the loss function\n",
    "        \"\"\"\n",
    "        \n",
    "        flat_logits = tf.reshape(logits, [-1, self.n_class])\n",
    "        flat_labels = tf.reshape(self.y, [-1, self.n_class])\n",
    "        if cost_name == \"cross_entropy\":\n",
    "            class_weights = cost_kwargs.pop(\"class_weights\", None)\n",
    "            \n",
    "            if class_weights is not None:\n",
    "                class_weights = tf.constant(np.array(class_weights, dtype=np.float32))\n",
    "        \n",
    "                weight_map = tf.multiply(flat_labels, class_weights)\n",
    "                weight_map = tf.reduce_sum(weight_map, axis=1)\n",
    "        \n",
    "                loss_map = tf.nn.softmax_cross_entropy_with_logits(flat_logits, flat_labels)\n",
    "                weighted_loss = tf.multiply(loss_map, weight_map)\n",
    "        \n",
    "                loss = tf.reduce_mean(weighted_loss)\n",
    "                \n",
    "            else:\n",
    "                loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=flat_logits, \n",
    "                                                                              labels=flat_labels))\n",
    "        elif cost_name == \"dice_coefficient\":\n",
    "            eps = 1e-5\n",
    "            prediction = pixel_wise_softmax_2(logits)\n",
    "            intersection = tf.reduce_sum(prediction * self.y)\n",
    "            union =  eps + tf.reduce_sum(prediction) + tf.reduce_sum(self.y)\n",
    "            loss = -(2 * intersection/ (union))\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Unknown cost function: \"%cost_name)\n",
    "\n",
    "        regularizer = cost_kwargs.pop(\"regularizer\", None)\n",
    "        if regularizer is not None:\n",
    "            regularizers = sum([tf.nn.l2_loss(variable) for variable in self.variables])\n",
    "            loss += (regularizer * regularizers)\n",
    "            \n",
    "        return loss\n",
    "\n",
    "    def predict(self, model_path, x_test):\n",
    "        \"\"\"\n",
    "        Uses the model to create a prediction for the given data\n",
    "        \n",
    "        :param model_path: path to the model checkpoint to restore\n",
    "        :param x_test: Data to predict on. Shape [n, nx, ny, channels]\n",
    "        :returns prediction: The unet prediction Shape [n, px, py, labels] (px=nx-self.offset/2) \n",
    "        \"\"\"\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session(config=config) as sess:\n",
    "            # Initialize variables\n",
    "            sess.run(init)\n",
    "        \n",
    "            # Restore model weights from previously saved model\n",
    "            self.restore(sess, model_path)\n",
    "            \n",
    "            y_dummy = np.empty((x_test.shape[0], x_test.shape[1], x_test.shape[2], self.n_class))\n",
    "            prediction = sess.run(self.predicter, feed_dict={self.x: x_test, self.y: y_dummy, self.keep_prob: 1.})\n",
    "            \n",
    "        return prediction\n",
    "    \n",
    "    def save(self, sess, model_path):\n",
    "        \"\"\"\n",
    "        Saves the current session to a checkpoint\n",
    "        \n",
    "        :param sess: current session\n",
    "        :param model_path: path to file system location\n",
    "        \"\"\"\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, model_path)\n",
    "        return save_path\n",
    "    \n",
    "    def restore(self, sess, model_path):\n",
    "        \"\"\"\n",
    "        Restores a session from a checkpoint\n",
    "        \n",
    "        :param sess: current session instance\n",
    "        :param model_path: path to file system checkpoint location\n",
    "        \"\"\"\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_path)\n",
    "        logging.info(\"Model restored from file: %s\" % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-27 11:54:51,930 Layers 7, features 16, filter size 3x3,pool size: 2x2\n"
     ]
    }
   ],
   "source": [
    "net = Unet(channels=mydata.channels, n_class=mydata.n_class, layers=7, features_root=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    ">  Making predictions on **```K```** data samples using saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ctuser/Desktop/Image_Seg/unet_trained_50_500_3/model_50_500_3.cpkt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-27 11:54:57,948 Restoring parameters from /home/ctuser/Desktop/Image_Seg/unet_trained_50_500_3/model_50_500_3.cpkt\n",
      "2017-07-27 11:55:01,478 Model restored from file: /home/ctuser/Desktop/Image_Seg/unet_trained_50_500_3/model_50_500_3.cpkt\n"
     ]
    }
   ],
   "source": [
    "prediction = net.predict(\"/home/ctuser/Desktop/Image_Seg/unet_trained_50_500_3/model_50_500_3.cpkt\", X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_test = storing_dicom(x_test=X_test,prediction=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = out_test.shape[0]\n",
    "for i in range(0,n):\n",
    "    out_test[i,...,0] = out_test[i,...,0]*minmax[i,1]\n",
    "    out_test[i,...,0] = out_test[i,...,0]+minmax[i,0]\n",
    "\n",
    "out_test = out_test.astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def UID_update(s, InstanceUID):\n",
    "    if InstanceUID==\"SeriesInstanceUID\":\n",
    "        last_dig =  s.SeriesInstanceUID[len(s.SeriesInstanceUID)-1]\n",
    "        last_dig = (int(last_dig) +1)%9\n",
    "        s.SeriesInstanceUID = s.SeriesInstanceUID[0:(len(s.SeriesInstanceUID)-1)] + str(last_dig)\n",
    "        return s.SeriesInstanceUID\n",
    "    if InstanceUID==\"FrameOfReferenceUID\":\n",
    "        last_dig = s.FrameOfReferenceUID[len(s.FrameOfReferenceUID)-1]\n",
    "        last_dig = (int(last_dig) +1)%9\n",
    "        s.FrameOfReferenceUID = s.FrameOfReferenceUID[0:(len(s.FrameOfReferenceUID)-1)] + str(last_dig)\n",
    "        return s.FrameOfReferenceUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def store_in_input(path,out_test):\n",
    "    out_test_zip = zipfile.ZipFile(output_data_path+\"out_test.zip\", 'w')\n",
    "    slices = [dicom.read_file(path + '/' + s) for s in z.getnames()]\n",
    "    #slices.sort(key = lambda x: int(x.InstanceNumber))\n",
    "    for i in range(0,len(slices)):\n",
    "        s = slices[i]\n",
    "        s.SeriesInstanceUID= UID_update(s, \"SeriesInstanceUID\")\n",
    "        s.FrameOfReferenceUID = UID_update(s, \"FrameOfReferenceUID\")\n",
    "        s.SeriesNumber = '200' \n",
    "        storing_path = a[i]\n",
    "        out_test_flat = out_test[i].flat\n",
    "        #for n,val in enumerate(s.pixel_array.flat):\n",
    "        s.pixel_array.flat[:]=out_test_flat[:]\n",
    "        #s.pixel_array = copy(out_test[i,...,0])\n",
    "        s.PixelData = s.pixel_array.tostring()\n",
    "        s.save_as(output_data_path+'/'+a[i])\n",
    "        out_test_zip.write(output_data_path+storing_path, compress_type=zipfile.ZIP_DEFLATED)\n",
    "        print(i)\n",
    "    out_test_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "store_in_input(data_path,out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
