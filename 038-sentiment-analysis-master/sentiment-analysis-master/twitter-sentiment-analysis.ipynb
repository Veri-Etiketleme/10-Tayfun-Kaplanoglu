{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3281,
     "status": "ok",
     "timestamp": 1558409673974,
     "user": {
      "displayName": "long doan",
      "photoUrl": "https://lh4.googleusercontent.com/-lI2ML69qv6s/AAAAAAAAAAI/AAAAAAAAAEk/ujLJCd_FyHc/s64/photo.jpg",
      "userId": "04258800431087948794"
     },
     "user_tz": -420
    },
    "id": "WvZiempWJwEi",
    "outputId": "0d1d3101-9a83-466d-9274-33958d454c8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish import libraries\n"
     ]
    }
   ],
   "source": [
    "#read data with format\n",
    "import pandas as pd\n",
    "\n",
    "#math calculation\n",
    "import numpy as np\n",
    "\n",
    "#sql\n",
    "import sqlite3\n",
    "\n",
    "#clean text\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "#Sampling split\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "\n",
    "#Algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "#RNN\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNLSTM, Dense, Bidirectional\n",
    "from keras.utils import plot_model\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "#utils\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm #progress bar\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Finish import libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1679,
     "status": "ok",
     "timestamp": 1558409674773,
     "user": {
      "displayName": "long doan",
      "photoUrl": "https://lh4.googleusercontent.com/-lI2ML69qv6s/AAAAAAAAAAI/AAAAAAAAAEk/ujLJCd_FyHc/s64/photo.jpg",
      "userId": "04258800431087948794"
     },
     "user_tz": -420
    },
    "id": "Px80xC8ZT6Cv",
    "outputId": "19ded979-f059-495d-ea28-e38f18fdb0e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#Google Colab\n",
    "#connect gdrive\n",
    "from google.colab import drive\n",
    "from os.path import join\n",
    "drive.mount('/content/gdrive')\n",
    "FILEPATH = '/content/gdrive/My Drive/twitter-sentiment-analysis/'\n",
    "\n",
    "#w2v custom lib\n",
    "from importlib.machinery import SourceFileLoader\n",
    "word2vecReaderUtils = SourceFileLoader('word2vecReaderUtils', join(FILEPATH, 'word2vecReaderUtils.py')).load_module()\n",
    "word2vecReader = SourceFileLoader('word2vecReader', join(FILEPATH, 'word2vecReader.py')).load_module()\n",
    "from word2vecReader import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1093,
     "status": "ok",
     "timestamp": 1558409680018,
     "user": {
      "displayName": "long doan",
      "photoUrl": "https://lh4.googleusercontent.com/-lI2ML69qv6s/AAAAAAAAAAI/AAAAAAAAAEk/ujLJCd_FyHc/s64/photo.jpg",
      "userId": "04258800431087948794"
     },
     "user_tz": -420
    },
    "id": "bc5Zb7-wJwE1",
    "outputId": "59f7e9f2-ca4b-4ae1-cbc7-0d4e81fbcbde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish loading dataset\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(join(FILEPATH, 'database.sqlite'))\n",
    "df = pd.read_sql_query(\"select * from Tweets;\", conn)\n",
    "print(\"Finish loading dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ighFwXDoIhuX"
   },
   "outputs": [],
   "source": [
    "#CONFIG\n",
    "#GENERAL\n",
    "SPLIT_RATIO = 0.2\n",
    "K_FOLDS = 5\n",
    "SEED = 6\n",
    "\n",
    "#Logistic Regression\n",
    "SOLVER_LR = 'liblinear'\n",
    "MULTI_CLASS_LR = 'ovr'\n",
    "MAX_ITER_LR = 500\n",
    "\n",
    "#SVM\n",
    "KERNEL_SVM = 'linear'\n",
    "\n",
    "#RNN\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 8\n",
    "INPUT_SIZE = 400 #fixed, number of features in embedding\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM_RATE = 0.9\n",
    "DROPOUT_RATE = 0.25\n",
    "STEP_PER_EPOCH = 1000\n",
    "\n",
    "def seed_torch(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2fM6tHEWCQGW"
   },
   "source": [
    "PREPROCESSING DATA\n",
    "\n",
    "Clean text by remove misspell word, @..., website link, etc\n",
    "\n",
    "Load Word2Vec model and perform word embedding (skip if dont want to retrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4811,
     "status": "ok",
     "timestamp": 1558409686895,
     "user": {
      "displayName": "long doan",
      "photoUrl": "https://lh4.googleusercontent.com/-lI2ML69qv6s/AAAAAAAAAAI/AAAAAAAAAEk/ujLJCd_FyHc/s64/photo.jpg",
      "userId": "04258800431087948794"
     },
     "user_tz": -420
    },
    "id": "r1Axc1z5JwFG",
    "outputId": "773e6503-9c4a-4acb-8988-e13ebdbf2ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish cleaning text\n"
     ]
    }
   ],
   "source": [
    "df['encode_airline_sentiment'] = (df['airline_sentiment'] != 'negative').astype(int)\n",
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'\n",
    "misspell_dict = {\"aren't\" : \"are not\",\n",
    "                \"can't\" : \"cannot\",\n",
    "                \"couldn't\" : \"could not\",\n",
    "                \"didn't\" : \"did not\",\n",
    "                \"doesn't\" : \"does not\",\n",
    "                \"don't\" : \"do not\",\n",
    "                \"hadn't\" : \"had not\",\n",
    "                \"hasn't\" : \"has not\",\n",
    "                \"haven't\" : \"have not\",\n",
    "                \"he'd\" : \"he would\",\n",
    "                \"he'll\" : \"he will\",\n",
    "                \"he's\" : \"he is\",\n",
    "                \"i'd\" : \"I would\",\n",
    "                \"i'll\" : \"I will\",\n",
    "                \"i'm\" : \"I am\",\n",
    "                \"isn't\" : \"is not\",\n",
    "                \"it's\" : \"it is\",\n",
    "                \"it'll\":\"it will\",\n",
    "                \"i've\" : \"I have\",\n",
    "                \"let's\" : \"let us\",\n",
    "                \"mightn't\" : \"might not\",\n",
    "                \"mustn't\" : \"must not\",\n",
    "                \"shan't\" : \"shall not\",\n",
    "                \"she'd\" : \"she would\",\n",
    "                \"she'll\" : \"she will\",\n",
    "                \"she's\" : \"she is\",\n",
    "                \"shouldn't\" : \"should not\",\n",
    "                \"that's\" : \"that is\",\n",
    "                \"there's\" : \"there is\",\n",
    "                \"they'd\" : \"they would\",\n",
    "                \"they'll\" : \"they will\",\n",
    "                \"they're\" : \"they are\",\n",
    "                \"they've\" : \"they have\",\n",
    "                \"we'd\" : \"we would\",\n",
    "                \"we're\" : \"we are\",\n",
    "                \"weren't\" : \"were not\",\n",
    "                \"we've\" : \"we have\",\n",
    "                \"what'll\" : \"what will\",\n",
    "                \"what're\" : \"what are\",\n",
    "                \"what's\" : \"what is\",\n",
    "                \"what've\" : \"what have\",\n",
    "                \"where's\" : \"where is\",\n",
    "                \"who'd\" : \"who would\",\n",
    "                \"who'll\" : \"who will\",\n",
    "                \"who're\" : \"who are\",\n",
    "                \"who's\" : \"who is\",\n",
    "                \"who've\" : \"who have\",\n",
    "                \"won't\" : \"will not\",\n",
    "                \"wouldn't\" : \"would not\",\n",
    "                \"you'd\" : \"you would\",\n",
    "                \"you'll\" : \"you will\",\n",
    "                \"you're\" : \"you are\",\n",
    "                \"you've\" : \"you have\",\n",
    "                \"'re\": \" are\",\n",
    "                \"wasn't\": \"was not\",\n",
    "                \"we'll\":\" will\",\n",
    "                \"didn't\": \"did not\",\n",
    "                \"tryin'\":\"trying\"}\n",
    "misspell_pattern = re.compile(r'\\b(' + '|'.join(misspell_dict.keys()) + r')\\b')\n",
    "\n",
    "def text_cleaner(text):\n",
    "    clean_text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    clean_text = re.sub(combined_pat, '', clean_text)\n",
    "    clean_text = re.sub(www_pat, '', clean_text)\n",
    "    \n",
    "    lower_case = clean_text.lower()\n",
    "    misspell_handled = misspell_pattern.sub(lambda x: misspell_dict[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", misspell_handled)\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()\n",
    "\n",
    "cleaned_data = []\n",
    "\n",
    "for text in df['text']:\n",
    "    cleaned_data.append(text_cleaner(text))\n",
    "    \n",
    "df['clean_text'] = cleaned_data\n",
    "df['text_len'] = [len(t) for t in df['clean_text']]\n",
    "print('Finish cleaning text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "so9xzDdBWjZd"
   },
   "outputs": [],
   "source": [
    "def load_trained_w2v_embedding():\n",
    "    print(\"Loading the model, this can take some time...\")\n",
    "    model_embed = Word2Vec.load_word2vec_format(join(FILEPATH, 'word2vec_twitter_model.bin'), binary=True)\n",
    "    print(\"The vocabulary size is: \"+str(len(model_embed.vocab)))\n",
    "    model_embed_vocab = list(model_embed.vocab.keys())\n",
    "    \n",
    "    return model_embed, model_embed_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9x_tMMi81hMt"
   },
   "outputs": [],
   "source": [
    "def perform_embedding():\n",
    "    embedded = np.zeros((len(df), INPUT_SIZE))\n",
    "    i = 0\n",
    "    for example in df['clean_text']:\n",
    "        embedded_vector = np.zeros((1, INPUT_SIZE))\n",
    "        for word in example:\n",
    "            if word in model_embed_vocab:\n",
    "                embedded_vector = np.add(embedded_vector, np.asarray(model_embed.__getitem__(word)))\n",
    "        embedded[i] = embedded_vector\n",
    "        print('example ' + str(i + 1) + ' finished embedding')\n",
    "        i+=1\n",
    "        \n",
    "    np.save(join(FILEPATH, 'embedded.npy'), embedded)\n",
    "    print('Finish perform word embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 72074,
     "status": "ok",
     "timestamp": 1558409760012,
     "user": {
      "displayName": "long doan",
      "photoUrl": "https://lh4.googleusercontent.com/-lI2ML69qv6s/AAAAAAAAAAI/AAAAAAAAAEk/ujLJCd_FyHc/s64/photo.jpg",
      "userId": "04258800431087948794"
     },
     "user_tz": -420
    },
    "id": "KB3DTKzgUrG_",
    "outputId": "b5d326ad-719d-44ab-d201-6f2faf93aea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model, this can take some time...\n",
      "The vocabulary size is: 3039345\n"
     ]
    }
   ],
   "source": [
    "#Load pretrained embedding\n",
    "model_embed, model_embed_vocab = load_trained_w2v_embedding()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jwyeQdCU8tu"
   },
   "outputs": [],
   "source": [
    "#Perform embedding on own dataset (for LogReg and SVM algorithm)\n",
    "perform_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6ovAXZe7dX1"
   },
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "for word in model_embed_vocab:\n",
    "    embedding_index[word] = np.asarray(model_embed.__getitem__(word))\n",
    "del model_embed, model_embed_vocab #save ram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zcERtaUPgvYZ"
   },
   "source": [
    "Load processed data into input and perfrom prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qLMnXaP6DrV3"
   },
   "outputs": [],
   "source": [
    "X = np.load(join(FILEPATH, 'embedded.npy'))\n",
    "y = df['encode_airline_sentiment'].values\n",
    "\n",
    "folds = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "def evaluate_logistic_regression(X, y, folds):\n",
    "    clf = LogisticRegression(random_state=SEED, solver=SOLVER_LR,multi_class=MULTI_CLASS_LR, max_iter=MAX_ITER_LR)\n",
    "    score = cross_val_score(clf, X, y, cv=folds)\n",
    "    return score\n",
    "\n",
    "def evaluate_svm(X, y, folds):\n",
    "    svm_linear = svm.SVC(kernel=KERNEL_SVM, random_state=SEED)\n",
    "    score = cross_val_score(svm_linear, X, y, cv=folds)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXOJMxG14GSI"
   },
   "outputs": [],
   "source": [
    "max_len = -1\n",
    "for text in df['clean_text']:\n",
    "    max_len = max(max_len, len(text.split()))\n",
    "\n",
    "def text_to_array(text):\n",
    "    empyt_emb = np.zeros(INPUT_SIZE)\n",
    "    text = text.split()[:max_len]\n",
    "    embeds = [embedding_index.get(x, empyt_emb) for x in text]\n",
    "    embeds+= [empyt_emb] * (max_len - len(embeds))\n",
    "    return np.array(embeds)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(CuDNNLSTM(max_len, return_sequences=True),\n",
    "                            input_shape=(max_len, INPUT_SIZE)))\n",
    "    model.add(Bidirectional(CuDNNLSTM(max_len)))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    plot_model(model, to_file='model.png')\n",
    "\n",
    "#     sgd = optimizers.SGD(lr=LEARNING_RATE, momentum=MOMENTUM_RATE, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_RNN(fold):\n",
    "    X = np.array([text_to_array(X_text) for X_text in df['clean_text'].values])\n",
    "    y = df['encode_airline_sentiment'].values\n",
    "    \n",
    "    model_wrapper = KerasClassifier(build_fn=create_model,\n",
    "                                   epochs=EPOCHS,\n",
    "                                   batch_size=BATCH_SIZE,\n",
    "                                   verbose=True)\n",
    "    \n",
    "    score = cross_val_score(model_wrapper, X, y, cv=fold)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12774,
     "status": "ok",
     "timestamp": 1558409793811,
     "user": {
      "displayName": "long doan",
      "photoUrl": "https://lh4.googleusercontent.com/-lI2ML69qv6s/AAAAAAAAAAI/AAAAAAAAAEk/ujLJCd_FyHc/s64/photo.jpg",
      "userId": "04258800431087948794"
     },
     "user_tz": -420
    },
    "id": "47foXGfDubPP",
    "outputId": "9c3fde0a-da60-4a08-9d11-e9cb258837c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71532091 0.72049689 0.72868485 0.70614641 0.72790055]\n"
     ]
    }
   ],
   "source": [
    "score = evaluate_logistic_regression(X, y, folds)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1678
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 155402,
     "status": "ok",
     "timestamp": 1558409944396,
     "user": {
      "displayName": "long doan",
      "photoUrl": "https://lh4.googleusercontent.com/-lI2ML69qv6s/AAAAAAAAAAI/AAAAAAAAAEk/ujLJCd_FyHc/s64/photo.jpg",
      "userId": "04258800431087948794"
     },
     "user_tz": -420
    },
    "id": "YfrwHn_VD5Za",
    "outputId": "09589dbb-7d10-4b93-f7e8-2210c25ddb66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/8\n",
      "11587/11587 [==============================] - 9s 754us/step - loss: 0.4882 - acc: 0.7590\n",
      "Epoch 2/8\n",
      "11587/11587 [==============================] - 3s 246us/step - loss: 0.3754 - acc: 0.8346\n",
      "Epoch 3/8\n",
      "11587/11587 [==============================] - 3s 245us/step - loss: 0.3599 - acc: 0.8434\n",
      "Epoch 4/8\n",
      "11587/11587 [==============================] - 3s 244us/step - loss: 0.3492 - acc: 0.8508\n",
      "Epoch 5/8\n",
      "11587/11587 [==============================] - 3s 243us/step - loss: 0.3357 - acc: 0.8554\n",
      "Epoch 6/8\n",
      "11587/11587 [==============================] - 3s 268us/step - loss: 0.3319 - acc: 0.8559\n",
      "Epoch 7/8\n",
      "11587/11587 [==============================] - 3s 274us/step - loss: 0.3269 - acc: 0.8573\n",
      "Epoch 8/8\n",
      "11587/11587 [==============================] - 3s 276us/step - loss: 0.3142 - acc: 0.8644\n",
      "2898/2898 [==============================] - 1s 191us/step\n",
      "Epoch 1/8\n",
      "11587/11587 [==============================] - 4s 315us/step - loss: 0.4838 - acc: 0.7676\n",
      "Epoch 2/8\n",
      "11587/11587 [==============================] - 3s 247us/step - loss: 0.3829 - acc: 0.8302\n",
      "Epoch 3/8\n",
      "11587/11587 [==============================] - 3s 245us/step - loss: 0.3563 - acc: 0.8465\n",
      "Epoch 4/8\n",
      "11587/11587 [==============================] - 3s 246us/step - loss: 0.3452 - acc: 0.8535\n",
      "Epoch 5/8\n",
      "11587/11587 [==============================] - 3s 245us/step - loss: 0.3334 - acc: 0.8555\n",
      "Epoch 6/8\n",
      "11587/11587 [==============================] - 3s 246us/step - loss: 0.3268 - acc: 0.8622\n",
      "Epoch 7/8\n",
      "11587/11587 [==============================] - 3s 246us/step - loss: 0.3192 - acc: 0.8625\n",
      "Epoch 8/8\n",
      "11587/11587 [==============================] - 3s 243us/step - loss: 0.3088 - acc: 0.8675\n",
      "2898/2898 [==============================] - 1s 200us/step\n",
      "Epoch 1/8\n",
      "11588/11588 [==============================] - 4s 326us/step - loss: 0.4861 - acc: 0.7648\n",
      "Epoch 2/8\n",
      "11588/11588 [==============================] - 3s 247us/step - loss: 0.3758 - acc: 0.8344\n",
      "Epoch 3/8\n",
      "11588/11588 [==============================] - 3s 247us/step - loss: 0.3591 - acc: 0.8423\n",
      "Epoch 4/8\n",
      "11588/11588 [==============================] - 3s 249us/step - loss: 0.3476 - acc: 0.8455\n",
      "Epoch 5/8\n",
      "11588/11588 [==============================] - 3s 247us/step - loss: 0.3344 - acc: 0.8530\n",
      "Epoch 6/8\n",
      "11588/11588 [==============================] - 3s 246us/step - loss: 0.3258 - acc: 0.8576\n",
      "Epoch 7/8\n",
      "11588/11588 [==============================] - 3s 246us/step - loss: 0.3125 - acc: 0.8643\n",
      "Epoch 8/8\n",
      "11588/11588 [==============================] - 3s 247us/step - loss: 0.3076 - acc: 0.8651\n",
      "2897/2897 [==============================] - 1s 225us/step\n",
      "Epoch 1/8\n",
      "11589/11589 [==============================] - 4s 341us/step - loss: 0.5122 - acc: 0.7453\n",
      "Epoch 2/8\n",
      "11589/11589 [==============================] - 3s 246us/step - loss: 0.3748 - acc: 0.8377\n",
      "Epoch 3/8\n",
      "11589/11589 [==============================] - 3s 247us/step - loss: 0.3505 - acc: 0.8503\n",
      "Epoch 4/8\n",
      "11589/11589 [==============================] - 3s 248us/step - loss: 0.3396 - acc: 0.8508\n",
      "Epoch 5/8\n",
      "11589/11589 [==============================] - 3s 270us/step - loss: 0.3309 - acc: 0.8576\n",
      "Epoch 6/8\n",
      "11589/11589 [==============================] - 3s 279us/step - loss: 0.3215 - acc: 0.8638\n",
      "Epoch 7/8\n",
      "11589/11589 [==============================] - 3s 277us/step - loss: 0.3120 - acc: 0.8644\n",
      "Epoch 8/8\n",
      "11589/11589 [==============================] - 3s 259us/step - loss: 0.3068 - acc: 0.8656\n",
      "2896/2896 [==============================] - 1s 255us/step\n",
      "Epoch 1/8\n",
      "11589/11589 [==============================] - 5s 429us/step - loss: 0.4892 - acc: 0.7635\n",
      "Epoch 2/8\n",
      "11589/11589 [==============================] - 3s 264us/step - loss: 0.3837 - acc: 0.8324\n",
      "Epoch 3/8\n",
      "11589/11589 [==============================] - 3s 252us/step - loss: 0.3573 - acc: 0.8449\n",
      "Epoch 4/8\n",
      "11589/11589 [==============================] - 3s 249us/step - loss: 0.3414 - acc: 0.8527\n",
      "Epoch 5/8\n",
      "11589/11589 [==============================] - 3s 250us/step - loss: 0.3332 - acc: 0.8564\n",
      "Epoch 6/8\n",
      "11589/11589 [==============================] - 3s 251us/step - loss: 0.3241 - acc: 0.8625\n",
      "Epoch 7/8\n",
      "11589/11589 [==============================] - 3s 249us/step - loss: 0.3165 - acc: 0.8665\n",
      "Epoch 8/8\n",
      "11589/11589 [==============================] - 3s 248us/step - loss: 0.3123 - acc: 0.8656\n",
      "2896/2896 [==============================] - 1s 283us/step\n",
      "[0.85334714 0.83609386 0.846738   0.82907459 0.83183702]\n"
     ]
    }
   ],
   "source": [
    "score = evaluate_RNN(folds)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1292590,
     "status": "ok",
     "timestamp": 1558411082557,
     "user": {
      "displayName": "long doan",
      "photoUrl": "https://lh4.googleusercontent.com/-lI2ML69qv6s/AAAAAAAAAAI/AAAAAAAAAEk/ujLJCd_FyHc/s64/photo.jpg",
      "userId": "04258800431087948794"
     },
     "user_tz": -420
    },
    "id": "TwL2m0UtwxRl",
    "outputId": "637ef6f3-1093-4f49-9d77-4404499fc19d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7073844  0.72463768 0.73110114 0.70476519 0.73549724]\n"
     ]
    }
   ],
   "source": [
    "score = evaluate_svm(X, y, folds)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "twitter-sentiment-analysis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
