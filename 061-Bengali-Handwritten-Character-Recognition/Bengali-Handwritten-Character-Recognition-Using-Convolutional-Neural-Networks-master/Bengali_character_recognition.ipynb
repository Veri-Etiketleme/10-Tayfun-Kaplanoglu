{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "from PIL import Image\n",
    "from six.moves import range\n",
    "\n",
    "# Config the matlotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished augmenting Train/172\n",
      "Finished augmenting Train/173\n",
      "Finished augmenting Train/174\n",
      "Finished augmenting Train/175\n",
      "Finished augmenting Train/176\n",
      "Finished augmenting Train/177\n",
      "Finished augmenting Train/178\n",
      "Finished augmenting Train/179\n",
      "Finished augmenting Train/180\n",
      "Finished augmenting Train/181\n",
      "Finished augmenting Train/182\n",
      "Finished augmenting Train/183\n",
      "Finished augmenting Train/184\n",
      "Finished augmenting Train/185\n",
      "Finished augmenting Train/186\n",
      "Finished augmenting Train/187\n",
      "Finished augmenting Train/188\n",
      "Finished augmenting Train/189\n",
      "Finished augmenting Train/190\n",
      "Finished augmenting Train/191\n",
      "Finished augmenting Train/192\n",
      "Finished augmenting Train/193\n",
      "Finished augmenting Train/194\n",
      "Finished augmenting Train/195\n",
      "Finished augmenting Train/196\n",
      "Finished augmenting Train/197\n",
      "Finished augmenting Train/198\n",
      "Finished augmenting Train/199\n",
      "Finished augmenting Train/200\n",
      "Finished augmenting Train/201\n",
      "Finished augmenting Train/202\n",
      "Finished augmenting Train/203\n",
      "Finished augmenting Train/204\n",
      "Finished augmenting Train/205\n",
      "Finished augmenting Train/206\n",
      "Finished augmenting Train/207\n",
      "Finished augmenting Train/208\n",
      "Finished augmenting Train/209\n",
      "Finished augmenting Train/210\n",
      "Finished augmenting Train/211\n",
      "Finished augmenting Train/212\n",
      "Finished augmenting Train/213\n",
      "Finished augmenting Train/214\n",
      "Finished augmenting Train/215\n",
      "Finished augmenting Train/216\n",
      "Finished augmenting Train/217\n",
      "Finished augmenting Train/218\n",
      "Finished augmenting Train/219\n",
      "Finished augmenting Train/220\n",
      "Finished augmenting Train/221\n"
     ]
    }
   ],
   "source": [
    "train_folder = \"Train\"\n",
    "test_folder = \"Test\"\n",
    "dimensions = (50, 50)\n",
    "\n",
    "max_angle = 15\n",
    "\n",
    "def rotate_img(image, angle, color, filter = Image.NEAREST):\n",
    "    \n",
    "    if image.mode == \"P\" or filter == Image.NEAREST:\n",
    "        matte = Image.new(\"1\", image.size, 1) # mask\n",
    "    else:\n",
    "        matte = Image.new(\"L\", image.size, 255) # true matte\n",
    "    bg = Image.new(image.mode, image.size, color)\n",
    "    bg.paste(\n",
    "        image.rotate(angle, filter), \n",
    "        matte.rotate(angle, filter)\n",
    "    )\n",
    "    return bg\n",
    "\n",
    "def make_greyscale_white_bg(im, r, b, g):\n",
    "\n",
    "    im = im.convert('RGBA')   # Convert to RGBA\n",
    "    \n",
    "    \n",
    "    data = np.array(im)   # \"data\" is a height x width x 4 numpy array\n",
    "    red, green, blue, alpha = data.T # Temporarily unpack the bands for readability\n",
    "\n",
    "    # Replace grey with white... (leaves alpha values alone...)\n",
    "    grey_areas = (red == r) & (blue == b) & (green == g)\n",
    "    data[..., :-1][grey_areas.T] = (255, 255, 255) # Transpose back needed\n",
    "    \n",
    "    im2 = Image.fromarray(data)\n",
    "    im2 = im2.convert('L')   # convert to greyscale image\n",
    "    \n",
    "    \n",
    "    \n",
    "    #im2.show()\n",
    "    \n",
    "    return im2\n",
    "\n",
    "def random_rotate(img, copies, curr_filename, path):\n",
    "    \n",
    "    c_color = img.getpixel((0,0))\n",
    "    \n",
    "    for i in range(copies):\n",
    "        \n",
    "        new_im = rotate_img(img, np.random.randint((0 - max_angle), max_angle), c_color)\n",
    "        new_im.save(os.path.join(path, \"bcc\" + str(curr_filename).zfill(6) + \".bmp\"))\n",
    "        \n",
    "        curr_filename = curr_filename + 1\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "def augment_by_rotations(folder, prev_cnt):\n",
    "    \n",
    "    classes = [os.path.join(folder, d) for d in sorted(os.listdir(folder))]  # get list of all sub-folders in folder\n",
    "    \n",
    "    for path_to_folder in classes: \n",
    "    \n",
    "        if os.path.isdir(path_to_folder):\n",
    "            images = [os.path.join(path_to_folder, i) for i in sorted(os.listdir(path_to_folder)) if i != '.DS_Store']\n",
    "            filename = prev_cnt\n",
    "            for image in images:\n",
    "\n",
    "                im = Image.open(image)\n",
    "\n",
    "                random_rotate(im, 4, filename, path_to_folder)\n",
    "                filename = filename + 4\n",
    "\n",
    "            print(\"Finished augmenting \" + path_to_folder)\n",
    "        \n",
    "        \n",
    "\n",
    "def invert_colors(im):\n",
    "    \n",
    "    im = im.convert('RGBA')   # Convert to RGBA  \n",
    "    data = np.array(im)   # \"data\" is a height x width x 4 numpy array\n",
    "    red, green, blue, alpha = data.T # Temporarily unpack the bands for readability\n",
    "    \n",
    "\n",
    "    # Replace grey with white... (leaves alpha values alone...)\n",
    "    black_areas = (red == 0) & (blue == 0) & (green == 0)\n",
    "    data[..., :-1][black_areas.T] = (255, 0, 0) # Transpose back needed\n",
    "    \n",
    "    white_areas = (red == 255) & (blue == 255) & (green == 255)\n",
    "    data[..., :-1][white_areas.T] = (0, 0, 0) # Transpose back needed\n",
    "    \n",
    "    red_areas = (red == 255) & (blue == 0) & (green == 0)\n",
    "    data[..., :-1][red_areas.T] = (255, 255, 255) # Transpose back needed\n",
    "\n",
    "    im2 = Image.fromarray(data)\n",
    "    im2 = im2.convert('L')   # convert to greyscale image\n",
    "    \n",
    "    \n",
    "    \n",
    "    #im2.show()\n",
    "    \n",
    "    return im2\n",
    "    \n",
    "    \n",
    "\n",
    "def test_rotations():\n",
    "        \n",
    "    img = Image.open(\"Train/172/bcc000002.bmp\")\n",
    "    \n",
    "    #img = img.rotate(30)\n",
    "    \n",
    "    img = img.resize(dimensions)\n",
    "    \n",
    "    \n",
    "    \n",
    "    rot = make_greyscale_white_bg(img, 127, 127, 127)\n",
    "    \n",
    "    rot = invert_colors(rot)\n",
    "    c_color = rot.getpixel((0, 0))\n",
    "    rot = rotate_img(rot, 10, c_color)\n",
    "    \n",
    "    w, h = rot.size\n",
    "    rot.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def process_images(folder):\n",
    "    \n",
    "    classes = [os.path.join(folder, d) for d in sorted(os.listdir(folder))]  # get list of all sub-folders in folder\n",
    "    img_cnt = 0\n",
    "    \n",
    "    for class_x in classes:\n",
    "        \n",
    "        if os.path.isdir(class_x):\n",
    "            \n",
    "            # get paths to all the images in this folder\n",
    "            images = [os.path.join(class_x, i) for i in sorted(os.listdir(class_x)) if i != '.DS_Store']\n",
    "            \n",
    "            for image in images:\n",
    "                \n",
    "                img_cnt = img_cnt + 1\n",
    "                \n",
    "                if(img_cnt % 1000 == 0): \n",
    "                    print(\"Processed %s images\" % str(img_cnt))\n",
    "                \n",
    "                im = Image.open(image)\n",
    "                im = im.resize(dimensions)   # resize image according to dimensions set\n",
    "                \n",
    "                im = make_greyscale_white_bg(im, 127, 127, 127) # turn grey background (if any) to white, and\n",
    "                                                                  # convert into greyscale image with 1 channel\n",
    "                    \n",
    "                im = invert_colors(im)\n",
    "                im.save(image)   # overwrite previous image file with new image\n",
    "                \n",
    "    print(\"Finished processing images, images found = \")\n",
    "    print(img_cnt)\n",
    "                \n",
    "#process_images(test_folder)\n",
    "#process_images(train_folder)\n",
    "\n",
    "#augment_by_rotations(\"Train/172\")\n",
    "\n",
    "augment_by_rotations(train_folder, 240)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the entire dataset into a 3D array (image index, x, y) of floating point values, normalized to have approximately zero mean and standard deviation ~0.5 to make training easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling Train/172.pickle.\n",
      "Train/172\n",
      "Could not read: Train/172/.DS_Store : cannot identify image file <open file 'Train/172/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (1100, 50, 50)\n",
      "Mean: -0.24997\n",
      "Standard deviation: 0.432756\n",
      "Pickling Train/173.pickle.\n",
      "Train/173\n",
      "Could not read: Train/173/.DS_Store : cannot identify image file <open file 'Train/173/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.211432\n",
      "Standard deviation: 0.453097\n",
      "Pickling Train/174.pickle.\n",
      "Train/174\n",
      "Could not read: Train/174/.DS_Store : cannot identify image file <open file 'Train/174/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.294222\n",
      "Standard deviation: 0.403799\n",
      "Pickling Train/175.pickle.\n",
      "Train/175\n",
      "Could not read: Train/175/.DS_Store : cannot identify image file <open file 'Train/175/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.307094\n",
      "Standard deviation: 0.393966\n",
      "Pickling Train/176.pickle.\n",
      "Train/176\n",
      "Could not read: Train/176/.DS_Store : cannot identify image file <open file 'Train/176/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.305621\n",
      "Standard deviation: 0.394663\n",
      "Pickling Train/177.pickle.\n",
      "Train/177\n",
      "Could not read: Train/177/.DS_Store : cannot identify image file <open file 'Train/177/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.306034\n",
      "Standard deviation: 0.394389\n",
      "Pickling Train/178.pickle.\n",
      "Train/178\n",
      "Could not read: Train/178/.DS_Store : cannot identify image file <open file 'Train/178/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.240636\n",
      "Standard deviation: 0.436093\n",
      "Pickling Train/179.pickle.\n",
      "Train/179\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.295907\n",
      "Standard deviation: 0.401349\n",
      "Pickling Train/180.pickle.\n",
      "Train/180\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.32865\n",
      "Standard deviation: 0.376696\n",
      "Pickling Train/181.pickle.\n",
      "Train/181\n",
      "Could not read: Train/181/.DS_Store : cannot identify image file <open file 'Train/181/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.2604\n",
      "Standard deviation: 0.426839\n",
      "Pickling Train/182.pickle.\n",
      "Train/182\n",
      "Could not read: Train/182/.DS_Store : cannot identify image file <open file 'Train/182/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.29856\n",
      "Standard deviation: 0.40053\n",
      "Pickling Train/183.pickle.\n",
      "Train/183\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.212001\n",
      "Standard deviation: 0.452369\n",
      "Pickling Train/184.pickle.\n",
      "Train/184\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.253839\n",
      "Standard deviation: 0.430774\n",
      "Pickling Train/185.pickle.\n",
      "Train/185\n",
      "Could not read: Train/185/.DS_Store : cannot identify image file <open file 'Train/185/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.274144\n",
      "Standard deviation: 0.417763\n",
      "Pickling Train/186.pickle.\n",
      "Train/186\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.242562\n",
      "Standard deviation: 0.423613\n",
      "Pickling Train/187.pickle.\n",
      "Train/187\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.237506\n",
      "Standard deviation: 0.431138\n",
      "Pickling Train/188.pickle.\n",
      "Train/188\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.269922\n",
      "Standard deviation: 0.408805\n",
      "Pickling Train/189.pickle.\n",
      "Train/189\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.292934\n",
      "Standard deviation: 0.400194\n",
      "Pickling Train/190.pickle.\n",
      "Train/190\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.27982\n",
      "Standard deviation: 0.410448\n",
      "Pickling Train/191.pickle.\n",
      "Train/191\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.23589\n",
      "Standard deviation: 0.439196\n",
      "Pickling Train/192.pickle.\n",
      "Train/192\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.252794\n",
      "Standard deviation: 0.430169\n",
      "Pickling Train/193.pickle.\n",
      "Train/193\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.316618\n",
      "Standard deviation: 0.38376\n",
      "Pickling Train/194.pickle.\n",
      "Train/194\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.300048\n",
      "Standard deviation: 0.398971\n",
      "Pickling Train/195.pickle.\n",
      "Train/195\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.258534\n",
      "Standard deviation: 0.423719\n",
      "Pickling Train/196.pickle.\n",
      "Train/196\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.285691\n",
      "Standard deviation: 0.404571\n",
      "Pickling Train/197.pickle.\n",
      "Train/197\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.296363\n",
      "Standard deviation: 0.381646\n",
      "Pickling Train/198.pickle.\n",
      "Train/198\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.246071\n",
      "Standard deviation: 0.435251\n",
      "Pickling Train/199.pickle.\n",
      "Train/199\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.260723\n",
      "Standard deviation: 0.426408\n",
      "Pickling Train/200.pickle.\n",
      "Train/200\n",
      "Could not read: Train/200/.DS_Store : cannot identify image file <open file 'Train/200/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.316397\n",
      "Standard deviation: 0.384664\n",
      "Pickling Train/201.pickle.\n",
      "Train/201\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.238827\n",
      "Standard deviation: 0.43115\n",
      "Pickling Train/202.pickle.\n",
      "Train/202\n",
      "Could not read: Train/202/.DS_Store : cannot identify image file <open file 'Train/202/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.272873\n",
      "Standard deviation: 0.417631\n",
      "Pickling Train/203.pickle.\n",
      "Train/203\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.256846\n",
      "Standard deviation: 0.41177\n",
      "Pickling Train/204.pickle.\n",
      "Train/204\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.241255\n",
      "Standard deviation: 0.427016\n",
      "Pickling Train/205.pickle.\n",
      "Train/205\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.224598\n",
      "Standard deviation: 0.432069\n",
      "Pickling Train/206.pickle.\n",
      "Train/206\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.225118\n",
      "Standard deviation: 0.432355\n",
      "Pickling Train/207.pickle.\n",
      "Train/207\n",
      "Could not read: Train/207/.DS_Store : cannot identify image file <open file 'Train/207/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.236307\n",
      "Standard deviation: 0.426427\n",
      "Pickling Train/208.pickle.\n",
      "Train/208\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.246649\n",
      "Standard deviation: 0.419173\n",
      "Pickling Train/209.pickle.\n",
      "Train/209\n",
      "Could not read: Train/209/.DS_Store : cannot identify image file <open file 'Train/209/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.26134\n",
      "Standard deviation: 0.414852\n",
      "Pickling Train/210.pickle.\n",
      "Train/210\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.266048\n",
      "Standard deviation: 0.409686\n",
      "Pickling Train/211.pickle.\n",
      "Train/211\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.240896\n",
      "Standard deviation: 0.407741\n",
      "Pickling Train/212.pickle.\n",
      "Train/212\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.221823\n",
      "Standard deviation: 0.438395\n",
      "Pickling Train/213.pickle.\n",
      "Train/213\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.256854\n",
      "Standard deviation: 0.427535\n",
      "Pickling Train/214.pickle.\n",
      "Train/214\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.26251\n",
      "Standard deviation: 0.425461\n",
      "Pickling Train/215.pickle.\n",
      "Train/215\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.313156\n",
      "Standard deviation: 0.383027\n",
      "Pickling Train/216.pickle.\n",
      "Train/216\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.326468\n",
      "Standard deviation: 0.371515\n",
      "Pickling Train/217.pickle.\n",
      "Train/217\n",
      "Could not read: Train/217/.DS_Store : cannot identify image file <open file 'Train/217/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.304055\n",
      "Standard deviation: 0.395763\n",
      "Pickling Train/218.pickle.\n",
      "Train/218\n",
      "Could not read: Train/218/.DS_Store : cannot identify image file <open file 'Train/218/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.251216\n",
      "Standard deviation: 0.431032\n",
      "Pickling Train/219.pickle.\n",
      "Train/219\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.306682\n",
      "Standard deviation: 0.391864\n",
      "Pickling Train/220.pickle.\n",
      "Train/220\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.210457\n",
      "Standard deviation: 0.448947\n",
      "Pickling Train/221.pickle.\n",
      "Train/221\n",
      "Could not read: Train/221/.DS_Store : cannot identify image file <open file 'Train/221/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (1200, 50, 50)\n",
      "Mean: -0.257295\n",
      "Standard deviation: 0.42748\n",
      "Pickling Test/172.pickle.\n",
      "Test/172\n",
      "Could not read: Test/172/.DS_Store : cannot identify image file <open file 'Test/172/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.248881\n",
      "Standard deviation: 0.432611\n",
      "Pickling Test/173.pickle.\n",
      "Test/173\n",
      "Could not read: Test/173/.DS_Store : cannot identify image file <open file 'Test/173/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.246167\n",
      "Standard deviation: 0.435203\n",
      "Pickling Test/174.pickle.\n",
      "Test/174\n",
      "Could not read: Test/174/.DS_Store : cannot identify image file <open file 'Test/174/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.299319\n",
      "Standard deviation: 0.40028\n",
      "Pickling Test/175.pickle.\n",
      "Test/175\n",
      "Could not read: Test/175/.DS_Store : cannot identify image file <open file 'Test/175/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.303651\n",
      "Standard deviation: 0.396594\n",
      "Pickling Test/176.pickle.\n",
      "Test/176\n",
      "Could not read: Test/176/.DS_Store : cannot identify image file <open file 'Test/176/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.299218\n",
      "Standard deviation: 0.400131\n",
      "Pickling Test/177.pickle.\n",
      "Test/177\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.310478\n",
      "Standard deviation: 0.39097\n",
      "Pickling Test/178.pickle.\n",
      "Test/178\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.234757\n",
      "Standard deviation: 0.440612\n",
      "Pickling Test/179.pickle.\n",
      "Test/179\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.291479\n",
      "Standard deviation: 0.403601\n",
      "Pickling Test/180.pickle.\n",
      "Test/180\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.321236\n",
      "Standard deviation: 0.38277\n",
      "Pickling Test/181.pickle.\n",
      "Test/181\n",
      "Could not read: Test/181/.DS_Store : cannot identify image file <open file 'Test/181/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.253747\n",
      "Standard deviation: 0.430828\n",
      "Pickling Test/182.pickle.\n",
      "Test/182\n",
      "Could not read: Test/182/.DS_Store : cannot identify image file <open file 'Test/182/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.293519\n",
      "Standard deviation: 0.403518\n",
      "Pickling Test/183.pickle.\n",
      "Test/183\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.207157\n",
      "Standard deviation: 0.452157\n",
      "Pickling Test/184.pickle.\n",
      "Test/184\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.2446\n",
      "Standard deviation: 0.436086\n",
      "Pickling Test/185.pickle.\n",
      "Test/185\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.250213\n",
      "Standard deviation: 0.432889\n",
      "Pickling Test/186.pickle.\n",
      "Test/186\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.232852\n",
      "Standard deviation: 0.436909\n",
      "Pickling Test/187.pickle.\n",
      "Test/187\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.22759\n",
      "Standard deviation: 0.433329\n",
      "Pickling Test/188.pickle.\n",
      "Test/188\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.261296\n",
      "Standard deviation: 0.415743\n",
      "Pickling Test/189.pickle.\n",
      "Test/189\n",
      "Could not read: Test/189/.DS_Store : cannot identify image file <open file 'Test/189/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.284178\n",
      "Standard deviation: 0.403849\n",
      "Pickling Test/190.pickle.\n",
      "Test/190\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.276803\n",
      "Standard deviation: 0.414646\n",
      "Pickling Test/191.pickle.\n",
      "Test/191\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.225183\n",
      "Standard deviation: 0.444849\n",
      "Pickling Test/192.pickle.\n",
      "Test/192\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.247491\n",
      "Standard deviation: 0.431216\n",
      "Pickling Test/193.pickle.\n",
      "Test/193\n",
      "Could not read: Test/193/.DS_Store : cannot identify image file <open file 'Test/193/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.31465\n",
      "Standard deviation: 0.385286\n",
      "Pickling Test/194.pickle.\n",
      "Test/194\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.305737\n",
      "Standard deviation: 0.395378\n",
      "Pickling Test/195.pickle.\n",
      "Test/195\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.258796\n",
      "Standard deviation: 0.424992\n",
      "Pickling Test/196.pickle.\n",
      "Test/196\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.261089\n",
      "Standard deviation: 0.422224\n",
      "Pickling Test/197.pickle.\n",
      "Test/197\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.293792\n",
      "Standard deviation: 0.385068\n",
      "Pickling Test/198.pickle.\n",
      "Test/198\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.252845\n",
      "Standard deviation: 0.430781\n",
      "Pickling Test/199.pickle.\n",
      "Test/199\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.257059\n",
      "Standard deviation: 0.427831\n",
      "Pickling Test/200.pickle.\n",
      "Test/200\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.308515\n",
      "Standard deviation: 0.390069\n",
      "Pickling Test/201.pickle.\n",
      "Test/201\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.255332\n",
      "Standard deviation: 0.426898\n",
      "Pickling Test/202.pickle.\n",
      "Test/202\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.254626\n",
      "Standard deviation: 0.429789\n",
      "Pickling Test/203.pickle.\n",
      "Test/203\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.269465\n",
      "Standard deviation: 0.396535\n",
      "Pickling Test/204.pickle.\n",
      "Test/204\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.253911\n",
      "Standard deviation: 0.421119\n",
      "Pickling Test/205.pickle.\n",
      "Test/205\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.222547\n",
      "Standard deviation: 0.43328\n",
      "Pickling Test/206.pickle.\n",
      "Test/206\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.235327\n",
      "Standard deviation: 0.432204\n",
      "Pickling Test/207.pickle.\n",
      "Test/207\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.229539\n",
      "Standard deviation: 0.426761\n",
      "Pickling Test/208.pickle.\n",
      "Test/208\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.241629\n",
      "Standard deviation: 0.417391\n",
      "Pickling Test/209.pickle.\n",
      "Test/209\n",
      "Could not read: Test/209/.DS_Store : cannot identify image file <open file 'Test/209/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.259408\n",
      "Standard deviation: 0.408056\n",
      "Pickling Test/210.pickle.\n",
      "Test/210\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.275574\n",
      "Standard deviation: 0.413457\n",
      "Pickling Test/211.pickle.\n",
      "Test/211\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.217399\n",
      "Standard deviation: 0.413587\n",
      "Pickling Test/212.pickle.\n",
      "Test/212\n",
      "Could not read: Test/212/.DS_Store : cannot identify image file <open file 'Test/212/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.21147\n",
      "Standard deviation: 0.438345\n",
      "Pickling Test/213.pickle.\n",
      "Test/213\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.24905\n",
      "Standard deviation: 0.42947\n",
      "Pickling Test/214.pickle.\n",
      "Test/214\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.249644\n",
      "Standard deviation: 0.429525\n",
      "Pickling Test/215.pickle.\n",
      "Test/215\n",
      "Could not read: Test/215/.DS_Store : cannot identify image file <open file 'Test/215/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.302798\n",
      "Standard deviation: 0.390899\n",
      "Pickling Test/216.pickle.\n",
      "Test/216\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.326408\n",
      "Standard deviation: 0.37004\n",
      "Pickling Test/217.pickle.\n",
      "Test/217\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.291377\n",
      "Standard deviation: 0.405757\n",
      "Pickling Test/218.pickle.\n",
      "Test/218\n",
      "Could not read: Test/218/.DS_Store : cannot identify image file <open file 'Test/218/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.23901\n",
      "Standard deviation: 0.438674\n",
      "Pickling Test/219.pickle.\n",
      "Test/219\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.288184\n",
      "Standard deviation: 0.404615\n",
      "Pickling Test/220.pickle.\n",
      "Test/220\n",
      "Could not read: Test/220/.DS_Store : cannot identify image file <open file 'Test/220/.DS_Store', mode 'rb' at 0x108ce3c90> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.196174\n",
      "Standard deviation: 0.456729\n",
      "Pickling Test/221.pickle.\n",
      "Test/221\n",
      "Could not read: Test/221/.DS_Store : cannot identify image file <open file 'Test/221/.DS_Store', mode 'rb' at 0x108687a50> - it's ok, skipping.\n",
      "Full dataset tensor: (60, 50, 50)\n",
      "Mean: -0.257716\n",
      "Standard deviation: 0.422888\n"
     ]
    }
   ],
   "source": [
    "image_size = 50  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "  \"\"\"Load the data for a single letter label.\"\"\"\n",
    "\n",
    "  image_files = os.listdir(folder)\n",
    "  dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "  print(folder)\n",
    "    \n",
    "  num_images = 0\n",
    "  for image_index, image in enumerate(image_files):\n",
    "    image_file = os.path.join(folder, image)\n",
    "    try:\n",
    "      image_data = (ndimage.imread(image_file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "      if image_data.shape != (image_size, image_size):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      dataset[num_images, :, :] = image_data\n",
    "      num_images = num_images + 1\n",
    "    except IOError as e:\n",
    "      print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "    \n",
    "  dataset = dataset[0:num_images, :, :]\n",
    "  if num_images < min_num_images:\n",
    "    raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                    (num_images, min_num_images))\n",
    "    \n",
    "  print('Full dataset tensor:', dataset.shape)\n",
    "  print('Mean:', np.mean(dataset))\n",
    "  print('Standard deviation:', np.std(dataset))\n",
    "  return dataset\n",
    "        \n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "  dataset_names = []\n",
    "  folders_list = os.listdir(data_folders)\n",
    "  for folder in folders_list:\n",
    "        \n",
    "    #print(os.path.join(data_folders, folder))\n",
    "    curr_folder_path = os.path.join(data_folders, folder)\n",
    "    if os.path.isdir(curr_folder_path):\n",
    "        set_filename = curr_folder_path + '.pickle'\n",
    "        dataset_names.append(set_filename)\n",
    "        if os.path.exists(set_filename) and not force:\n",
    "          # You may override by setting force=True.\n",
    "          print('%s already present - Skipping pickling.' % set_filename)\n",
    "        else:\n",
    "          print('Pickling %s.' % set_filename)\n",
    "          dataset = load_letter(curr_folder_path, min_num_images_per_class)\n",
    "          try:\n",
    "            with open(set_filename, 'wb') as f:\n",
    "                pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "                f.close()\n",
    "          except Exception as e:\n",
    "            print('Unable to save data to', set_filename, ':', e)\n",
    "  \n",
    "  return dataset_names\n",
    "\n",
    "train_datasets = maybe_pickle(train_folder, 1050, True)\n",
    "test_datasets = maybe_pickle(test_folder, 58, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the training dataset and also create a validation set for hyperparameter training. Also merge the test dataset. Then randomize all the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (50000, 50, 50) (50000,)\n",
      "Validation: (5000, 50, 50) (5000,)\n",
      "Testing: (3000, 50, 50) (3000,)\n"
     ]
    }
   ],
   "source": [
    "def make_arrays(nb_rows, img_size):\n",
    "  if nb_rows:\n",
    "    dataset = np.ndarray((nb_rows, img_size, img_size), dtype=np.float32)\n",
    "    labels = np.ndarray(nb_rows, dtype=np.int32)\n",
    "  else:\n",
    "    dataset, labels = None, None\n",
    "  return dataset, labels\n",
    "\n",
    "def merge_datasets(pickle_files, train_size, valid_size=0):\n",
    "  num_classes = len(pickle_files)\n",
    "  valid_dataset, valid_labels = make_arrays(valid_size, image_size)\n",
    "  train_dataset, train_labels = make_arrays(train_size, image_size)\n",
    "  vsize_per_class = valid_size // num_classes\n",
    "  tsize_per_class = train_size // num_classes\n",
    "    \n",
    "  start_v, start_t = 0, 0\n",
    "  end_v, end_t = vsize_per_class, tsize_per_class\n",
    "  end_l = vsize_per_class+tsize_per_class\n",
    "  for label, pickle_file in enumerate(pickle_files):       \n",
    "    try:\n",
    "      with open(pickle_file, 'rb') as f:\n",
    "        letter_set = pickle.load(f)\n",
    "        f.close()\n",
    "        # let's shuffle the letters to have random validation and training set\n",
    "        np.random.shuffle(letter_set)\n",
    "        if valid_dataset is not None:\n",
    "          valid_letter = letter_set[:vsize_per_class, :, :]\n",
    "          valid_dataset[start_v:end_v, :, :] = valid_letter\n",
    "          valid_labels[start_v:end_v] = label\n",
    "          start_v += vsize_per_class\n",
    "          end_v += vsize_per_class\n",
    "                    \n",
    "        train_letter = letter_set[vsize_per_class:end_l, :, :]\n",
    "        train_dataset[start_t:end_t, :, :] = train_letter\n",
    "        train_labels[start_t:end_t] = label\n",
    "        start_t += tsize_per_class\n",
    "        end_t += tsize_per_class\n",
    "    except Exception as e:\n",
    "      print('Unable to process data from', pickle_file, ':', e)\n",
    "      raise\n",
    "    \n",
    "  return valid_dataset, valid_labels, train_dataset, train_labels\n",
    "            \n",
    "            \n",
    "train_size = 50000\n",
    "valid_size = 5000\n",
    "test_size = 3000\n",
    "\n",
    "valid_dataset, valid_labels, train_dataset, train_labels = merge_datasets(\n",
    "  train_datasets, train_size, valid_size)\n",
    "_, _, test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying that the data is still good..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 39\n",
      "Label 29\n",
      "Label 26\n",
      "Label 16\n",
      "Label 17\n",
      "Label 10\n",
      "Label 22\n",
      "Label 28\n",
      "Label 10\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP0AAAD+CAYAAADxoQNSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niqIoiqIoiqIoyr75/4Y/cg6QFvStAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107f91c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs_per_set = 3\n",
    "def display_from_array(dataset, label):\n",
    "        \n",
    "    num_imgs, x, y = np.shape(dataset)\n",
    "    \n",
    "    for i in range(0, imgs_per_set):\n",
    "    \n",
    "        idx = np.random.randint(0, num_imgs - 1)\n",
    "\n",
    "        print(\"Label %s\" % label[idx])\n",
    "        plt.imshow(dataset[idx])\n",
    "        \n",
    "display_from_array(train_dataset, train_labels)\n",
    "display_from_array(test_dataset, test_labels)\n",
    "display_from_array(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = 'bengaliOCR.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 580232437\n"
     ]
    }
   ],
   "source": [
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying an off-the-shelf classifier to see how well it fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 37 %\n"
     ]
    }
   ],
   "source": [
    "trn_size = 4000\n",
    "test_size = 500\n",
    "\n",
    "def fitLogisticReg(X, y):\n",
    "    \n",
    "    nsamples, nx, ny = np.shape(X)\n",
    "    d2_X = X.reshape(nsamples, nx * ny)\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(d2_X, y)\n",
    "    \n",
    "    return clf\n",
    "\n",
    "def calcAccuracy(clf, test_X, test_y):\n",
    "    \n",
    "    corr = 0\n",
    "    total = 0\n",
    "    \n",
    "    nsamples, nx, ny = np.shape(test_X)\n",
    "    d2_testX = test_X.reshape(nsamples, nx * ny)\n",
    "    \n",
    "    predict_y = clf.predict(d2_testX)\n",
    "    \n",
    "    for i, prediction in enumerate(predict_y):\n",
    "        \n",
    "        if prediction == test_y[i]:\n",
    "            corr = corr + 1\n",
    "            \n",
    "        total = total + 1\n",
    "        \n",
    "    return corr * 100 / total\n",
    "\n",
    "clf = fitLogisticReg(train_dataset[:trn_size - 1, : , : ], train_labels[ : trn_size - 1])\n",
    "\n",
    "print(\"Accuracy = %d\" % calcAccuracy(clf, test_dataset[ : test_size - 1, : , : ], test_labels[ : test_size - 1]), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An SVM seems to perform a poor fit, at least on this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat the data so that the input matrices become flat matrices, and the labels are represented as one-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (50000, 2500) (50000, 50)\n",
      "Validation set (5000, 2500) (5000, 50)\n",
      "Test set (3000, 2500) (3000, 50)\n"
     ]
    }
   ],
   "source": [
    "image_size = 50\n",
    "num_labels = 50\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out a 1-hidden layer neural-network with ReLUs and 1024 hidden nodes, using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 4.212349\n",
      "Minibatch accuracy: 1.6%\n",
      "Validation accuracy: 2.1%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-179d58c38ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m       \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuracy: %.1f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mSGD_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-192-179d58c38ebb>\u001b[0m in \u001b[0;36mSGD_relu\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_train_labels\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         _, l, predictions = session.run(\n\u001b[0;32m---> 84\u001b[0;31m           [optimizer, loss, train_prediction], feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m           \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Minibatch loss at step %d: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 340\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 564\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 637\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    642\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m--> 628\u001b[0;31m             session, None, feed_dict, fetch_list, target_list, None)\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def SGD_relu():\n",
    "    \n",
    "    batch_size = 128\n",
    "    h = 1024\n",
    "    h2 = 256\n",
    "    num_steps = 4001\n",
    "    beta = 0.0005\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "\n",
    "      # Input data. For the training data, we use a placeholder that will be fed\n",
    "      # at run time with a training minibatch.\n",
    "      tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                        shape=(batch_size, image_size * image_size))\n",
    "      tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "      tf_valid_dataset = tf.constant(valid_dataset)\n",
    "      tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "      # Variables.\n",
    "      weights1 = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, h], stddev = 0.02))\n",
    "      biases1 = tf.Variable(tf.zeros([h]))\n",
    "      weights2 = tf.Variable(\n",
    "        tf.truncated_normal([h, h2], stddev = 0.03125))\n",
    "      biases2 = tf.Variable(tf.zeros([h2]))\n",
    "      weights3 = tf.Variable(\n",
    "        tf.truncated_normal([h2, num_labels], stddev = 0.0884))\n",
    "      biases3 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "      # Training computation.\n",
    "        \n",
    "      def model(dataset):\n",
    "        \n",
    "          logits1 = tf.matmul(dataset, weights1) + biases1\n",
    "\n",
    "          relu_outputs1 = tf.nn.relu(logits1)\n",
    "\n",
    "          logits2 = tf.matmul(relu_outputs1, weights2) + biases2\n",
    "            \n",
    "          relu_outputs2 = tf.nn.relu(logits2)\n",
    "        \n",
    "          logits3 = tf.matmul(relu_outputs2, weights3) + biases3\n",
    "            \n",
    "          return logits3\n",
    "      \n",
    "        \n",
    "      train_logits = model(tf_train_dataset)\n",
    "      valid_logits = model(tf_valid_dataset)\n",
    "      test_logits = model(tf_test_dataset)\n",
    "\n",
    "\n",
    "    \n",
    "      loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(train_logits, tf_train_labels)) + beta * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2) + tf.nn.l2_loss(weights3))\n",
    "\n",
    "\n",
    "        \n",
    "      # Optimizer.\n",
    "      optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "      # Predictions for the training, validation, and test data.\n",
    "      train_prediction = tf.nn.softmax(train_logits)\n",
    "      valid_prediction = tf.nn.softmax(valid_logits)\n",
    "      test_prediction = tf.nn.softmax(test_logits)\n",
    "        \n",
    "        \n",
    "    num_steps = 8001\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "      tf.initialize_all_variables().run()\n",
    "      print(\"Initialized\")\n",
    "      for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "          print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "          print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "          print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "      print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "    \n",
    "SGD_relu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a significant increase in accuracy compared to the simple linear logistic classifier. However, I am worried that the test dataset might be too small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I introduce dropout instead of L2-regularization as a way of controlling overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 4.272541\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 3.2%\n",
      "Minibatch loss at step 500: 1.450829\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 71.2%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-258d73bd869b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuracy: %.1f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mSGD_relu_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-193-258d73bd869b>\u001b[0m in \u001b[0;36mSGD_relu_dropout\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_train_labels\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         _, l, predictions = session.run(\n\u001b[0;32m--> 100\u001b[0;31m           [optimizer, loss, train_prediction], feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m           \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Minibatch loss at step %d: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 340\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 564\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 637\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    642\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m--> 628\u001b[0;31m             session, None, feed_dict, fetch_list, target_list, None)\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def SGD_relu_dropout():\n",
    "    \n",
    "    batch_size = 128\n",
    "    h = 1024\n",
    "    h2 = 256\n",
    "    num_steps = 4001\n",
    "    beta = 0.0005\n",
    "    keep_prob = 0.75\n",
    "    decay_step = 1000\n",
    "    base = 0.86\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "\n",
    "      # Input data. For the training data, we use a placeholder that will be fed\n",
    "      # at run time with a training minibatch.\n",
    "      tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                        shape=(batch_size, image_size * image_size))\n",
    "      tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "      tf_valid_dataset = tf.constant(valid_dataset)\n",
    "      tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "      # Variables.\n",
    "      weights1 = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, h], stddev = 0.02))\n",
    "      biases1 = tf.Variable(tf.zeros([h]))\n",
    "      weights2 = tf.Variable(\n",
    "        tf.truncated_normal([h, h2], stddev = 0.03125))\n",
    "      biases2 = tf.Variable(tf.zeros([h2]))\n",
    "      weights3 = tf.Variable(\n",
    "        tf.truncated_normal([h2, num_labels], stddev = 0.0884))\n",
    "      biases3 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "      global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "      learning_rate = tf.train.exponential_decay(0.5, global_step, decay_step, base)\n",
    "\n",
    "      # Training computation.\n",
    "        \n",
    "      def model(dataset, useDropout = False):\n",
    "        \n",
    "          logits1 = tf.matmul(dataset, weights1) + biases1\n",
    "\n",
    "          relu_outputs1 = tf.nn.relu(logits1)\n",
    "        \n",
    "          if useDropout:\n",
    "                dropout_layer0 = tf.nn.dropout(relu_outputs1, keep_prob)\n",
    "          else:\n",
    "                dropout_layer0 = relu_outputs1\n",
    "\n",
    "          logits2 = tf.matmul(dropout_layer0, weights2) + biases2\n",
    "            \n",
    "          relu_outputs2 = tf.nn.relu(logits2)\n",
    "        \n",
    "          if useDropout:\n",
    "                dropout_layer = tf.nn.dropout(relu_outputs2, keep_prob)\n",
    "          else:\n",
    "                dropout_layer = relu_outputs2\n",
    "        \n",
    "          logits3 = tf.matmul(dropout_layer, weights3) + biases3\n",
    "            \n",
    "          return logits3\n",
    "      \n",
    "        \n",
    "      train_logits = model(tf_train_dataset, True)\n",
    "      valid_logits = model(tf_valid_dataset)\n",
    "      test_logits = model(tf_test_dataset)\n",
    "\n",
    "\n",
    "    \n",
    "      loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(train_logits, tf_train_labels)) + beta * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2) + tf.nn.l2_loss(weights3))\n",
    "\n",
    "\n",
    "        \n",
    "      # Optimizer.\n",
    "      optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step = global_step)\n",
    "      # Predictions for the training, validation, and test data.\n",
    "      train_prediction = tf.nn.softmax(model(tf_train_dataset, False))\n",
    "      valid_prediction = tf.nn.softmax(valid_logits)\n",
    "      test_prediction = tf.nn.softmax(test_logits)\n",
    "        \n",
    "        \n",
    "    num_steps = 20001\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "      tf.initialize_all_variables().run()\n",
    "      print(\"Initialized\")\n",
    "      for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "          print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "          print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "          print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "      print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "    \n",
    "SGD_relu_dropout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout also helps improve performance by a few percentage points. Interestingly, I also discovered that using the Adagrad optimizer instead of regular gradient descent helped improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing dropout on the first hidden layer as well, and annealing the learning rate using a decay function further pushes up the accuracy to 85.6%. This has been achieved using a neural network with only 2 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I introduce a very simple convnet with maxpooling. This net has two convolutional layers followed by 1 fully-connected layer. I do not include dropout or other regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (50000, 50, 50, 1) (50000, 1, 50)\n",
      "Validation set (5000, 50, 50, 1) (5000, 1, 50)\n",
      "Test set (3000, 50, 50, 1) (3000, 1, 50)\n"
     ]
    }
   ],
   "source": [
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (50000, 50, 50, 1) (50000, 1, 1, 50)\n",
      "Validation set (5000, 50, 50, 1) (5000, 1, 1, 50)\n",
      "Test set (3000, 50, 50, 1) (3000, 1, 1, 50)\n"
     ]
    }
   ],
   "source": [
    "image_size = 50\n",
    "num_labels = 50\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'num_channels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-0b295d5d0e14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m       \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy: %.1f%%'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mmax_pool_conv_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-175-0b295d5d0e14>\u001b[0m in \u001b[0;36mmax_pool_conv_net\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;31m# Input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       tf_train_dataset = tf.placeholder(\n\u001b[0;32m---> 16\u001b[0;31m         tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0mtf_train_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mtf_valid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'num_channels' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
