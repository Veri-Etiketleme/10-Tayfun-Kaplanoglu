{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dl_utlils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dl_utlils.py\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(1234)\n",
    "\n",
    "def relu(x):\n",
    "    return T.maximum(0, x)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return T.nnet.sigmoid(x)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return T.tanh(x)\n",
    "\n",
    "\n",
    "class Metric(object):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def negative_log_likelihood(self):\n",
    "        self.prob_of_y_given_x = T.nnet.softmax(self.x)\n",
    "        return -T.mean(T.log(self.prob_of_y_given_x)[T.arange(self.y.shape[0]), self.y])\n",
    "\n",
    "    def cross_entropy(self):\n",
    "        self.prob_of_y_given_x = T.nnet.softmax(self.x)\n",
    "        return T.mean(T.nnet.categorical_crossentropy(self.prob_of_y_given_x, self.y))\n",
    "\n",
    "    def mean_squared_error(self):\n",
    "        return T.mean((self.x - self.y) ** 2)\n",
    "\n",
    "    def errors(self):\n",
    "        if self.y.ndim != self.y_pred.ndim:\n",
    "            raise TypeError('y should have the same shape as self.y_pred',\n",
    "                            ('y', self.y.type, 'y_pred', self.y_pred.type))\n",
    "\n",
    "        if self.y.dtype.startswith('int'):\n",
    "            self.prob_of_y_given_x = T.nnet.softmax(self.x)\n",
    "            self.y_pred = T.argmax(self.prob_of_y_given_x, axis=1)\n",
    "            return T.mean(T.neq(self.y_pred, self.y))\n",
    "        else:\n",
    "            return NotImplementedError()\n",
    "\n",
    "    def accuracy(self):\n",
    "        if self.y.dtype.startswith('int'):\n",
    "            self.prob_of_y_given_x = T.nnet.softmax(self.x)\n",
    "            self.y_pred = T.argmax(self.prob_of_y_given_x, axis=1)\n",
    "            return T.mean(T.eq(self.y_pred, self.y))\n",
    "        else:\n",
    "            return NotImplementedError()\n",
    "\n",
    "\n",
    "def shared_data(x, y):\n",
    "    shared_x = theano.shared(\n",
    "        np.asarray(x, dtype=theano.config.floatX), borrow=True)\n",
    "    if y is None:\n",
    "        return shared_x\n",
    "\n",
    "    shared_y = theano.shared(\n",
    "        np.asarray(y, dtype=theano.config.floatX), borrow=True)\n",
    "\n",
    "    return shared_x, T.cast(shared_y, 'int32')\n",
    "\n",
    "\n",
    "def build_shared_zeros(shape, name):\n",
    "    \"\"\" Builds a theano shared variable filled with a zeros numpy array \"\"\"\n",
    "    return theano.shared(\n",
    "        value=np.zeros(shape, dtype=theano.config.floatX),\n",
    "        name=name,\n",
    "        borrow=True\n",
    "    )\n",
    "\n",
    "\n",
    "def dropout(x, train, p=0.5, rng = np.random.RandomState(1234)):\n",
    "    masked_x = None\n",
    "    if p > 0.0 and p < 1.0:\n",
    "        seed = rng.randint(2 ** 30)\n",
    "        srng = T.shared_randomstreams.RandomStreams(seed)\n",
    "        mask = srng.binomial(\n",
    "            n=1,\n",
    "            p=1.0 - p,\n",
    "            size=x.shape,\n",
    "            dtype=theano.config.floatX\n",
    "        )\n",
    "        masked_x = x * mask\n",
    "    else:\n",
    "        masked_x = x\n",
    "    return T.switch(T.neq(train, 0), masked_x, x * (1.0 - p))\n",
    "\n",
    "\n",
    "class Optimizer(object):\n",
    "\n",
    "    def __init__(self, params=None):\n",
    "        if params is None:\n",
    "            return NotImplementedError()\n",
    "        self.params = params\n",
    "\n",
    "    def updates(self, loss=None):\n",
    "        if loss is None:\n",
    "            return NotImplementedError()\n",
    "\n",
    "        self.updates = OrderedDict()\n",
    "        self.gparams = [T.grad(loss, param) for param in self.params]\n",
    "\n",
    "\n",
    "def build_shared_zeros(shape, name):\n",
    "    \"\"\" Builds a theano shared variable filled with a zeros numpy array \"\"\"\n",
    "    return theano.shared(\n",
    "        value=np.zeros(shape, dtype=theano.config.floatX),\n",
    "        name=name,\n",
    "        borrow=True\n",
    "    )\n",
    "\n",
    "\n",
    "class RMSprop(Optimizer):\n",
    "\n",
    "    def __init__(self, learning_rate=0.001, alpha=0.99, eps=1e-8, params=None):\n",
    "        super(RMSprop, self).__init__(params=params)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.alpha = alpha\n",
    "        self.eps = eps\n",
    "\n",
    "        self.mss = [\n",
    "            build_shared_zeros(t.shape.eval(), 'ms') for t in self.params]\n",
    "\n",
    "    def updates(self, loss=None):\n",
    "        super(RMSprop, self).updates(loss=loss)\n",
    "\n",
    "        for ms, param, gparam in zip(self.mss, self.params, self.gparams):\n",
    "            _ms = ms * self.alpha\n",
    "            _ms += (1 - self.alpha) * gparam * gparam\n",
    "            self.updates[ms] = _ms\n",
    "            self.updates[param] = param - self.learning_rate * \\\n",
    "                gparam / T.sqrt(_ms + self.eps)\n",
    "\n",
    "        return self.updates\n",
    "\n",
    "class AdaDelta(Optimizer):\n",
    "\n",
    "    def __init__(self, rho=0.95, eps=1e-6, params=None):\n",
    "        super(AdaDelta, self).__init__(params=params)\n",
    "\n",
    "        self.rho = rho\n",
    "        self.eps = eps\n",
    "        self.accugrads = [\n",
    "            build_shared_zeros(t.shape.eval(), 'accugrad') for t in self.params]\n",
    "        self.accudeltas = [\n",
    "            build_shared_zeros(t.shape.eval(), 'accudelta') for t in self.params]\n",
    "\n",
    "    def updates(self, loss=None):\n",
    "        super(AdaDelta, self).updates(loss=loss)\n",
    "\n",
    "        for accugrad, accudelta, param, gparam\\\n",
    "                in zip(self.accugrads, self.accudeltas, self.params, self.gparams):\n",
    "            agrad = self.rho * accugrad + (1 - self.rho) * gparam * gparam\n",
    "            dx = - T.sqrt((accudelta + self.eps) / (agrad + self.eps)) * gparam\n",
    "            self.updates[accudelta] = (\n",
    "                self.rho * accudelta + (1 - self.rho) * dx * dx)\n",
    "            self.updates[param] = param + dx\n",
    "            self.updates[accugrad] = agrad\n",
    "\n",
    "        return self.updates\n",
    "\n",
    "class MomentumSGD(Optimizer):\n",
    "\n",
    "    def __init__(self, learning_rate=0.01, momentum=0.9, params=None):\n",
    "        super(MomentumSGD, self).__init__(params=params)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.vs = [build_shared_zeros(t.shape.eval(), 'v')\n",
    "                   for t in self.params]\n",
    "\n",
    "    def updates(self, loss=None):\n",
    "        super(MomentumSGD, self).updates(loss=loss)\n",
    "\n",
    "        for v, param, gparam in zip(self.vs, self.params, self.gparams):\n",
    "            _v = v * self.momentum\n",
    "            _v = _v - self.learning_rate * gparam\n",
    "            self.updates[param] = param + _v\n",
    "            self.updates[v] = _v\n",
    "\n",
    "        return self.updates    \n",
    "\n",
    "class Adam(Optimizer):\n",
    "\n",
    "    def __init__(self, alpha=0.001, beta1=0.9, beta2=0.999, eps=1e-8, gamma=1 - 1e-8, params=None):\n",
    "        super(Adam, self).__init__(params=params)\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.b1 = beta1\n",
    "        self.b2 = beta2\n",
    "        self.gamma = gamma\n",
    "        self.t = theano.shared(np.float32(1))\n",
    "        self.eps = eps\n",
    "\n",
    "        self.ms = [build_shared_zeros(t.shape.eval(), 'm')\n",
    "                   for t in self.params]\n",
    "        self.vs = [build_shared_zeros(t.shape.eval(), 'v')\n",
    "                   for t in self.params]\n",
    "\n",
    "    def updates(self, loss=None):\n",
    "        super(Adam, self).updates(loss=loss)\n",
    "        self.b1_t = self.b1 * self.gamma ** (self.t - 1)\n",
    "\n",
    "        for m, v, param, gparam \\\n",
    "                in zip(self.ms, self.vs, self.params, self.gparams):\n",
    "            _m = self.b1_t * m + (1 - self.b1_t) * gparam\n",
    "            _v = self.b2 * v + (1 - self.b2) * gparam ** 2\n",
    "\n",
    "            m_hat = _m / (1 - self.b1 ** self.t)\n",
    "            v_hat = _v / (1 - self.b2 ** self.t)\n",
    "\n",
    "            self.updates[param] = param - self.alpha * \\\n",
    "                m_hat / (T.sqrt(v_hat) + self.eps)\n",
    "            self.updates[m] = _m\n",
    "            self.updates[v] = _v\n",
    "        self.updates[self.t] = self.t + 1.0\n",
    "\n",
    "        return self.updates\n",
    "\n",
    "# Multi Layer Perceptron\n",
    "\n",
    "class Layer:\n",
    "    # Constructor\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        rng = np.random.RandomState(1234)\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.W = theano.shared(rng.uniform(low=-0.08, high=0.08,\n",
    "                                           size=(in_dim, out_dim)\n",
    "                                           ).astype('float32'), name='W')\n",
    "        self.b = theano.shared(np.zeros(out_dim).astype('float32'), name='b')\n",
    "        self.params = [self.W, self.b]\n",
    "        \n",
    "\n",
    "    # Forward Propagation\n",
    "    def f_prop(self, x):\n",
    "        self.z = T.dot(x, self.W) + self.b\n",
    "        return self.z\n",
    "\n",
    "class Activation:\n",
    "    # Constructor\n",
    "    def __init__(self, function):\n",
    "        self.function = function\n",
    "        self.params = []\n",
    "\n",
    "    # Forward Propagation\n",
    "    def f_prop(self, x):\n",
    "        self.z = self.function(x)\n",
    "        return self.z\n",
    "    \n",
    "class BatchNorm:\n",
    "    # Constructor\n",
    "    def __init__(self, shape, epsilon=np.float32(1e-5)):\n",
    "        self.shape = shape\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.gamma = theano.shared(np.ones(self.shape, dtype=\"float32\"),\n",
    "                                   name=\"gamma\")\n",
    "        self.beta = theano.shared(np.zeros(self.shape, dtype=\"float32\"),\n",
    "                                  name=\"beta\")\n",
    "        self.params = [self.gamma, self.beta]\n",
    "\n",
    "    # Forward Propagation\n",
    "    def f_prop(self, x):\n",
    "        if x.ndim == 2:\n",
    "            mean = T.mean(x, axis=0, keepdims=True)\n",
    "            std = T.sqrt(T.var(x, axis=0, keepdims=True) + self.epsilon)\n",
    "        elif x.ndim == 4:\n",
    "            mean = T.mean(x, axis=(0, 2, 3), keepdims=True)\n",
    "            std = T.sqrt(T.var(x, axis=(0, 2, 3), keepdims=True) +\n",
    "                         self.epsilon)\n",
    "\n",
    "        normalized_x = (x - mean) / std\n",
    "        self.z = self.gamma * normalized_x + self.beta\n",
    "        return self.z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ray/anaconda/envs/pure_theano/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 775M (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import pool\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "rng = np.random.RandomState(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist_X, mnist_y = shuffle(mnist.data.astype('float32'),\n",
    "                           mnist.target.astype('int32'),\n",
    "                           random_state=42)\n",
    "\n",
    "mnist_X = mnist_X / 255.0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(mnist_X, mnist_y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os \n",
    "base_folder = \"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = np.eye(10)[train_y].astype('int32')\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:: 1, Validation cost: 0.008, Validation F1: 0.966\n",
      "EPOCH:: 2, Validation cost: 0.006, Validation F1: 0.975\n",
      "EPOCH:: 3, Validation cost: 0.005, Validation F1: 0.976\n",
      "EPOCH:: 4, Validation cost: 0.004, Validation F1: 0.977\n",
      "EPOCH:: 5, Validation cost: 0.004, Validation F1: 0.974\n",
      "EPOCH:: 6, Validation cost: 0.004, Validation F1: 0.975\n",
      "EPOCH:: 7, Validation cost: 0.004, Validation F1: 0.977\n",
      "EPOCH:: 8, Validation cost: 0.005, Validation F1: 0.970\n",
      "EPOCH:: 9, Validation cost: 0.003, Validation F1: 0.978\n",
      "EPOCH:: 10, Validation cost: 0.004, Validation F1: 0.978\n",
      "EPOCH:: 11, Validation cost: 0.004, Validation F1: 0.977\n",
      "EPOCH:: 12, Validation cost: 0.004, Validation F1: 0.976\n",
      "EPOCH:: 13, Validation cost: 0.004, Validation F1: 0.977\n",
      "EPOCH:: 14, Validation cost: 0.004, Validation F1: 0.977\n",
      "EPOCH:: 15, Validation cost: 0.003, Validation F1: 0.980\n",
      "EPOCH:: 16, Validation cost: 0.003, Validation F1: 0.978\n",
      "EPOCH:: 17, Validation cost: 0.004, Validation F1: 0.976\n",
      "EPOCH:: 18, Validation cost: 0.004, Validation F1: 0.978\n",
      "EPOCH:: 19, Validation cost: 0.004, Validation F1: 0.978\n",
      "EPOCH:: 20, Validation cost: 0.004, Validation F1: 0.977\n",
      "EPOCH:: 21, Validation cost: 0.004, Validation F1: 0.975\n",
      "EPOCH:: 22, Validation cost: 0.004, Validation F1: 0.976\n",
      "EPOCH:: 23, Validation cost: 0.003, Validation F1: 0.979\n",
      "EPOCH:: 24, Validation cost: 0.003, Validation F1: 0.979\n",
      "EPOCH:: 25, Validation cost: 0.003, Validation F1: 0.979\n",
      "EPOCH:: 26, Validation cost: 0.004, Validation F1: 0.978\n",
      "EPOCH:: 27, Validation cost: 0.004, Validation F1: 0.974\n",
      "EPOCH:: 28, Validation cost: 0.004, Validation F1: 0.978\n",
      "EPOCH:: 29, Validation cost: 0.003, Validation F1: 0.979\n",
      "EPOCH:: 30, Validation cost: 0.004, Validation F1: 0.976\n",
      "EPOCH:: 31, Validation cost: 0.003, Validation F1: 0.978\n",
      "EPOCH:: 32, Validation cost: 0.003, Validation F1: 0.979\n",
      "EPOCH:: 33, Validation cost: 0.003, Validation F1: 0.979\n",
      "EPOCH:: 34, Validation cost: 0.004, Validation F1: 0.979\n",
      "EPOCH:: 35, Validation cost: 0.003, Validation F1: 0.980\n",
      "EPOCH:: 36, Validation cost: 0.003, Validation F1: 0.981\n",
      "EPOCH:: 37, Validation cost: 0.003, Validation F1: 0.980\n",
      "EPOCH:: 38, Validation cost: 0.003, Validation F1: 0.981\n",
      "EPOCH:: 39, Validation cost: 0.004, Validation F1: 0.979\n",
      "EPOCH:: 40, Validation cost: 0.003, Validation F1: 0.981\n",
      "EPOCH:: 41, Validation cost: 0.004, Validation F1: 0.979\n",
      "EPOCH:: 42, Validation cost: 0.003, Validation F1: 0.980\n",
      "EPOCH:: 43, Validation cost: 0.003, Validation F1: 0.978\n",
      "EPOCH:: 44, Validation cost: 0.004, Validation F1: 0.977\n",
      "EPOCH:: 45, Validation cost: 0.004, Validation F1: 0.976\n",
      "EPOCH:: 46, Validation cost: 0.003, Validation F1: 0.981\n",
      "EPOCH:: 47, Validation cost: 0.003, Validation F1: 0.981\n",
      "EPOCH:: 48, Validation cost: 0.003, Validation F1: 0.980\n",
      "EPOCH:: 49, Validation cost: 0.003, Validation F1: 0.979\n",
      "EPOCH:: 50, Validation cost: 0.004, Validation F1: 0.975\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "from dl_utlils import *\n",
    "activation = relu\n",
    "mlp_layers =  [784, 500, 500, 500, 10]\n",
    "layers = []\n",
    "for i_layer in range(len(mlp_layers)-2):\n",
    "    layers.append(Layer(mlp_layers[i_layer], mlp_layers[i_layer+1]))\n",
    "    BatchNorm(mlp_layers[i_layer+1],mlp_layers[i_layer+1])\n",
    "    layers.append(Activation(relu))\n",
    "    \n",
    "layers.append(Layer(mlp_layers[-2], mlp_layers[-1]))\n",
    "# layers.append(Activation(T.nnet.softmax))\n",
    "    \n",
    "x = T.fmatrix('x')\n",
    "t = T.fmatrix('t')\n",
    "\n",
    "params = []\n",
    "for i, layer in enumerate(layers):\n",
    "    params += layer.params\n",
    "    if i == 0:\n",
    "        layer_out = layer.f_prop(x)\n",
    "    else:\n",
    "        layer_out = layer.f_prop(layer_out)\n",
    "\n",
    "y = layers[-1].z\n",
    "# cost = T.mean(T.nnet.categorical_crossentropy(y, t))\n",
    "cost = T.mean((y - t) ** 2)\n",
    "optimizer = Adam(params=params)\n",
    "updates = optimizer.updates(cost)\n",
    "\n",
    "train = theano.function(inputs=[x, t], outputs=cost, updates=updates,\n",
    "                        allow_input_downcast=True, name='train')\n",
    "valid = theano.function(inputs=[x, t], outputs=[cost, T.argmax(y, axis=1)],\n",
    "                        allow_input_downcast=True, name='valid')\n",
    "test = theano.function(inputs=[x], outputs=T.argmax(y, axis=1), name='test')\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = train_X.shape[0]//batch_size\n",
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    #train_X, train_y = shuffle(train_X, train_y)\n",
    "    for i in range(n_batches):\n",
    "        start = i*batch_size\n",
    "        end = start + batch_size\n",
    "        train(train_X[start:end], train_y[start:end])\n",
    "    valid_cost, pred_y = valid(valid_X, valid_y)\n",
    "    print('EPOCH:: %i, Validation cost: %.3f, Validation F1: %.3f' %\n",
    "          (epoch + 1, valid_cost,\n",
    "           f1_score(np.argmax(valid_y, axis=1).astype('int32'),\n",
    "                    pred_y, average='macro')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "base_folder = os.path.join(\"..\",\"data\")\n",
    "filename = \"Train_N225_forex.pickle\"\n",
    "path = os.path.join(base_folder, filename)\n",
    "with open(path, mode='rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "train, test = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, train_y = train\n",
    "valid_X, valid_y = test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape\n",
    "train_y = train_y.reshape(len(train_y),1)\n",
    "valid_y = valid_y.reshape(len(valid_y),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:: 1, Validation cost: 0.593, Validation R2: -55.769\n",
      "EPOCH:: 2, Validation cost: 0.533, Validation R2: -50.020\n",
      "EPOCH:: 3, Validation cost: 0.429, Validation R2: -40.079\n",
      "EPOCH:: 4, Validation cost: 0.273, Validation R2: -25.128\n",
      "EPOCH:: 5, Validation cost: 0.113, Validation R2: -9.847\n",
      "EPOCH:: 6, Validation cost: 0.037, Validation R2: -2.522\n",
      "EPOCH:: 7, Validation cost: 0.030, Validation R2: -1.884\n",
      "EPOCH:: 8, Validation cost: 0.037, Validation R2: -2.526\n",
      "EPOCH:: 9, Validation cost: 0.034, Validation R2: -2.248\n",
      "EPOCH:: 10, Validation cost: 0.027, Validation R2: -1.596\n",
      "EPOCH:: 11, Validation cost: 0.023, Validation R2: -1.169\n",
      "EPOCH:: 12, Validation cost: 0.020, Validation R2: -0.897\n",
      "EPOCH:: 13, Validation cost: 0.018, Validation R2: -0.699\n",
      "EPOCH:: 14, Validation cost: 0.014, Validation R2: -0.295\n",
      "EPOCH:: 15, Validation cost: 0.012, Validation R2: -0.125\n",
      "EPOCH:: 16, Validation cost: 0.010, Validation R2: 0.031\n",
      "EPOCH:: 17, Validation cost: 0.008, Validation R2: 0.195\n",
      "EPOCH:: 18, Validation cost: 0.007, Validation R2: 0.317\n",
      "EPOCH:: 19, Validation cost: 0.006, Validation R2: 0.413\n",
      "EPOCH:: 20, Validation cost: 0.005, Validation R2: 0.493\n",
      "EPOCH:: 21, Validation cost: 0.005, Validation R2: 0.554\n",
      "EPOCH:: 22, Validation cost: 0.004, Validation R2: 0.602\n",
      "EPOCH:: 23, Validation cost: 0.004, Validation R2: 0.640\n",
      "EPOCH:: 24, Validation cost: 0.003, Validation R2: 0.670\n",
      "EPOCH:: 25, Validation cost: 0.003, Validation R2: 0.694\n",
      "EPOCH:: 26, Validation cost: 0.003, Validation R2: 0.713\n",
      "EPOCH:: 27, Validation cost: 0.003, Validation R2: 0.729\n",
      "EPOCH:: 28, Validation cost: 0.003, Validation R2: 0.744\n",
      "EPOCH:: 29, Validation cost: 0.003, Validation R2: 0.756\n",
      "EPOCH:: 30, Validation cost: 0.002, Validation R2: 0.768\n",
      "EPOCH:: 31, Validation cost: 0.002, Validation R2: 0.779\n",
      "EPOCH:: 32, Validation cost: 0.002, Validation R2: 0.788\n",
      "EPOCH:: 33, Validation cost: 0.002, Validation R2: 0.798\n",
      "EPOCH:: 34, Validation cost: 0.002, Validation R2: 0.806\n",
      "EPOCH:: 35, Validation cost: 0.002, Validation R2: 0.814\n",
      "EPOCH:: 36, Validation cost: 0.002, Validation R2: 0.822\n",
      "EPOCH:: 37, Validation cost: 0.002, Validation R2: 0.830\n",
      "EPOCH:: 38, Validation cost: 0.002, Validation R2: 0.837\n",
      "EPOCH:: 39, Validation cost: 0.002, Validation R2: 0.844\n",
      "EPOCH:: 40, Validation cost: 0.002, Validation R2: 0.851\n",
      "EPOCH:: 41, Validation cost: 0.001, Validation R2: 0.857\n",
      "EPOCH:: 42, Validation cost: 0.001, Validation R2: 0.863\n",
      "EPOCH:: 43, Validation cost: 0.001, Validation R2: 0.869\n",
      "EPOCH:: 44, Validation cost: 0.001, Validation R2: 0.876\n",
      "EPOCH:: 45, Validation cost: 0.001, Validation R2: 0.881\n",
      "EPOCH:: 46, Validation cost: 0.001, Validation R2: 0.887\n",
      "EPOCH:: 47, Validation cost: 0.001, Validation R2: 0.893\n",
      "EPOCH:: 48, Validation cost: 0.001, Validation R2: 0.898\n",
      "EPOCH:: 49, Validation cost: 0.001, Validation R2: 0.903\n",
      "EPOCH:: 50, Validation cost: 0.001, Validation R2: 0.909\n",
      "EPOCH:: 51, Validation cost: 0.001, Validation R2: 0.913\n",
      "EPOCH:: 52, Validation cost: 0.001, Validation R2: 0.918\n",
      "EPOCH:: 53, Validation cost: 0.001, Validation R2: 0.922\n",
      "EPOCH:: 54, Validation cost: 0.001, Validation R2: 0.927\n",
      "EPOCH:: 55, Validation cost: 0.001, Validation R2: 0.930\n",
      "EPOCH:: 56, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 57, Validation cost: 0.001, Validation R2: 0.937\n",
      "EPOCH:: 58, Validation cost: 0.001, Validation R2: 0.941\n",
      "EPOCH:: 59, Validation cost: 0.001, Validation R2: 0.943\n",
      "EPOCH:: 60, Validation cost: 0.001, Validation R2: 0.946\n",
      "EPOCH:: 61, Validation cost: 0.001, Validation R2: 0.948\n",
      "EPOCH:: 62, Validation cost: 0.001, Validation R2: 0.951\n",
      "EPOCH:: 63, Validation cost: 0.001, Validation R2: 0.952\n",
      "EPOCH:: 64, Validation cost: 0.000, Validation R2: 0.954\n",
      "EPOCH:: 65, Validation cost: 0.000, Validation R2: 0.955\n",
      "EPOCH:: 66, Validation cost: 0.000, Validation R2: 0.957\n",
      "EPOCH:: 67, Validation cost: 0.000, Validation R2: 0.956\n",
      "EPOCH:: 68, Validation cost: 0.000, Validation R2: 0.957\n",
      "EPOCH:: 69, Validation cost: 0.001, Validation R2: 0.931\n",
      "EPOCH:: 70, Validation cost: 0.000, Validation R2: 0.954\n",
      "EPOCH:: 71, Validation cost: 0.005, Validation R2: 0.514\n",
      "EPOCH:: 72, Validation cost: 0.001, Validation R2: 0.914\n",
      "EPOCH:: 73, Validation cost: 0.025, Validation R2: -1.399\n",
      "EPOCH:: 74, Validation cost: 0.002, Validation R2: 0.784\n",
      "EPOCH:: 75, Validation cost: 0.015, Validation R2: -0.473\n",
      "EPOCH:: 76, Validation cost: 0.001, Validation R2: 0.876\n",
      "EPOCH:: 77, Validation cost: 0.005, Validation R2: 0.522\n",
      "EPOCH:: 78, Validation cost: 0.001, Validation R2: 0.918\n",
      "EPOCH:: 79, Validation cost: 0.002, Validation R2: 0.772\n",
      "EPOCH:: 80, Validation cost: 0.001, Validation R2: 0.925\n",
      "EPOCH:: 81, Validation cost: 0.002, Validation R2: 0.840\n",
      "EPOCH:: 82, Validation cost: 0.001, Validation R2: 0.926\n",
      "EPOCH:: 83, Validation cost: 0.001, Validation R2: 0.865\n",
      "EPOCH:: 84, Validation cost: 0.001, Validation R2: 0.927\n",
      "EPOCH:: 85, Validation cost: 0.001, Validation R2: 0.877\n",
      "EPOCH:: 86, Validation cost: 0.001, Validation R2: 0.928\n",
      "EPOCH:: 87, Validation cost: 0.001, Validation R2: 0.885\n",
      "EPOCH:: 88, Validation cost: 0.001, Validation R2: 0.929\n",
      "EPOCH:: 89, Validation cost: 0.001, Validation R2: 0.890\n",
      "EPOCH:: 90, Validation cost: 0.001, Validation R2: 0.931\n",
      "EPOCH:: 91, Validation cost: 0.001, Validation R2: 0.892\n",
      "EPOCH:: 92, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 93, Validation cost: 0.001, Validation R2: 0.894\n",
      "EPOCH:: 94, Validation cost: 0.001, Validation R2: 0.936\n",
      "EPOCH:: 95, Validation cost: 0.001, Validation R2: 0.894\n",
      "EPOCH:: 96, Validation cost: 0.001, Validation R2: 0.938\n",
      "EPOCH:: 97, Validation cost: 0.001, Validation R2: 0.891\n",
      "EPOCH:: 98, Validation cost: 0.001, Validation R2: 0.941\n",
      "EPOCH:: 99, Validation cost: 0.001, Validation R2: 0.882\n",
      "EPOCH:: 100, Validation cost: 0.001, Validation R2: 0.927\n",
      "EPOCH:: 101, Validation cost: 0.001, Validation R2: 0.929\n",
      "EPOCH:: 102, Validation cost: 0.001, Validation R2: 0.943\n",
      "EPOCH:: 103, Validation cost: 0.002, Validation R2: 0.832\n",
      "EPOCH:: 104, Validation cost: 0.001, Validation R2: 0.941\n",
      "EPOCH:: 105, Validation cost: 0.003, Validation R2: 0.713\n",
      "EPOCH:: 106, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 107, Validation cost: 0.005, Validation R2: 0.510\n",
      "EPOCH:: 108, Validation cost: 0.001, Validation R2: 0.920\n",
      "EPOCH:: 109, Validation cost: 0.007, Validation R2: 0.324\n",
      "EPOCH:: 110, Validation cost: 0.001, Validation R2: 0.903\n",
      "EPOCH:: 111, Validation cost: 0.007, Validation R2: 0.290\n",
      "EPOCH:: 112, Validation cost: 0.001, Validation R2: 0.896\n",
      "EPOCH:: 113, Validation cost: 0.006, Validation R2: 0.381\n",
      "EPOCH:: 114, Validation cost: 0.001, Validation R2: 0.902\n",
      "EPOCH:: 115, Validation cost: 0.005, Validation R2: 0.517\n",
      "EPOCH:: 116, Validation cost: 0.001, Validation R2: 0.913\n",
      "EPOCH:: 117, Validation cost: 0.004, Validation R2: 0.630\n",
      "EPOCH:: 118, Validation cost: 0.001, Validation R2: 0.922\n",
      "EPOCH:: 119, Validation cost: 0.003, Validation R2: 0.707\n",
      "EPOCH:: 120, Validation cost: 0.001, Validation R2: 0.929\n",
      "EPOCH:: 121, Validation cost: 0.003, Validation R2: 0.756\n",
      "EPOCH:: 122, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 123, Validation cost: 0.002, Validation R2: 0.787\n",
      "EPOCH:: 124, Validation cost: 0.001, Validation R2: 0.936\n",
      "EPOCH:: 125, Validation cost: 0.002, Validation R2: 0.806\n",
      "EPOCH:: 126, Validation cost: 0.001, Validation R2: 0.937\n",
      "EPOCH:: 127, Validation cost: 0.002, Validation R2: 0.817\n",
      "EPOCH:: 128, Validation cost: 0.001, Validation R2: 0.938\n",
      "EPOCH:: 129, Validation cost: 0.002, Validation R2: 0.822\n",
      "EPOCH:: 130, Validation cost: 0.001, Validation R2: 0.938\n",
      "EPOCH:: 131, Validation cost: 0.002, Validation R2: 0.822\n",
      "EPOCH:: 132, Validation cost: 0.001, Validation R2: 0.939\n",
      "EPOCH:: 133, Validation cost: 0.002, Validation R2: 0.818\n",
      "EPOCH:: 134, Validation cost: 0.001, Validation R2: 0.939\n",
      "EPOCH:: 135, Validation cost: 0.002, Validation R2: 0.809\n",
      "EPOCH:: 136, Validation cost: 0.001, Validation R2: 0.939\n",
      "EPOCH:: 137, Validation cost: 0.002, Validation R2: 0.795\n",
      "EPOCH:: 138, Validation cost: 0.001, Validation R2: 0.938\n",
      "EPOCH:: 139, Validation cost: 0.002, Validation R2: 0.775\n",
      "EPOCH:: 140, Validation cost: 0.001, Validation R2: 0.937\n",
      "EPOCH:: 141, Validation cost: 0.003, Validation R2: 0.748\n",
      "EPOCH:: 142, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 143, Validation cost: 0.003, Validation R2: 0.715\n",
      "EPOCH:: 144, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 145, Validation cost: 0.003, Validation R2: 0.679\n",
      "EPOCH:: 146, Validation cost: 0.001, Validation R2: 0.929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:: 147, Validation cost: 0.004, Validation R2: 0.647\n",
      "EPOCH:: 148, Validation cost: 0.001, Validation R2: 0.926\n",
      "EPOCH:: 149, Validation cost: 0.004, Validation R2: 0.624\n",
      "EPOCH:: 150, Validation cost: 0.001, Validation R2: 0.923\n",
      "EPOCH:: 151, Validation cost: 0.004, Validation R2: 0.615\n",
      "EPOCH:: 152, Validation cost: 0.001, Validation R2: 0.922\n",
      "EPOCH:: 153, Validation cost: 0.004, Validation R2: 0.623\n",
      "EPOCH:: 154, Validation cost: 0.001, Validation R2: 0.923\n",
      "EPOCH:: 155, Validation cost: 0.004, Validation R2: 0.643\n",
      "EPOCH:: 156, Validation cost: 0.001, Validation R2: 0.924\n",
      "EPOCH:: 157, Validation cost: 0.003, Validation R2: 0.669\n",
      "EPOCH:: 158, Validation cost: 0.001, Validation R2: 0.926\n",
      "EPOCH:: 159, Validation cost: 0.003, Validation R2: 0.695\n",
      "EPOCH:: 160, Validation cost: 0.001, Validation R2: 0.929\n",
      "EPOCH:: 161, Validation cost: 0.003, Validation R2: 0.718\n",
      "EPOCH:: 162, Validation cost: 0.001, Validation R2: 0.931\n",
      "EPOCH:: 163, Validation cost: 0.003, Validation R2: 0.737\n",
      "EPOCH:: 164, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 165, Validation cost: 0.003, Validation R2: 0.752\n",
      "EPOCH:: 166, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 167, Validation cost: 0.002, Validation R2: 0.762\n",
      "EPOCH:: 168, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 169, Validation cost: 0.002, Validation R2: 0.768\n",
      "EPOCH:: 170, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 171, Validation cost: 0.002, Validation R2: 0.771\n",
      "EPOCH:: 172, Validation cost: 0.001, Validation R2: 0.936\n",
      "EPOCH:: 173, Validation cost: 0.002, Validation R2: 0.771\n",
      "EPOCH:: 174, Validation cost: 0.001, Validation R2: 0.936\n",
      "EPOCH:: 175, Validation cost: 0.002, Validation R2: 0.768\n",
      "EPOCH:: 176, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 177, Validation cost: 0.002, Validation R2: 0.762\n",
      "EPOCH:: 178, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 179, Validation cost: 0.003, Validation R2: 0.753\n",
      "EPOCH:: 180, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 181, Validation cost: 0.003, Validation R2: 0.743\n",
      "EPOCH:: 182, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 183, Validation cost: 0.003, Validation R2: 0.731\n",
      "EPOCH:: 184, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 185, Validation cost: 0.003, Validation R2: 0.720\n",
      "EPOCH:: 186, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 187, Validation cost: 0.003, Validation R2: 0.709\n",
      "EPOCH:: 188, Validation cost: 0.001, Validation R2: 0.931\n",
      "EPOCH:: 189, Validation cost: 0.003, Validation R2: 0.700\n",
      "EPOCH:: 190, Validation cost: 0.001, Validation R2: 0.930\n",
      "EPOCH:: 191, Validation cost: 0.003, Validation R2: 0.695\n",
      "EPOCH:: 192, Validation cost: 0.001, Validation R2: 0.929\n",
      "EPOCH:: 193, Validation cost: 0.003, Validation R2: 0.694\n",
      "EPOCH:: 194, Validation cost: 0.001, Validation R2: 0.929\n",
      "EPOCH:: 195, Validation cost: 0.003, Validation R2: 0.696\n",
      "EPOCH:: 196, Validation cost: 0.001, Validation R2: 0.929\n",
      "EPOCH:: 197, Validation cost: 0.003, Validation R2: 0.701\n",
      "EPOCH:: 198, Validation cost: 0.001, Validation R2: 0.930\n",
      "EPOCH:: 199, Validation cost: 0.003, Validation R2: 0.709\n",
      "EPOCH:: 200, Validation cost: 0.001, Validation R2: 0.930\n",
      "EPOCH:: 201, Validation cost: 0.003, Validation R2: 0.717\n",
      "EPOCH:: 202, Validation cost: 0.001, Validation R2: 0.931\n",
      "EPOCH:: 203, Validation cost: 0.003, Validation R2: 0.726\n",
      "EPOCH:: 204, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 205, Validation cost: 0.003, Validation R2: 0.734\n",
      "EPOCH:: 206, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 207, Validation cost: 0.003, Validation R2: 0.740\n",
      "EPOCH:: 208, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 209, Validation cost: 0.003, Validation R2: 0.745\n",
      "EPOCH:: 210, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 211, Validation cost: 0.003, Validation R2: 0.749\n",
      "EPOCH:: 212, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 213, Validation cost: 0.003, Validation R2: 0.751\n",
      "EPOCH:: 214, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 215, Validation cost: 0.003, Validation R2: 0.751\n",
      "EPOCH:: 216, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 217, Validation cost: 0.003, Validation R2: 0.750\n",
      "EPOCH:: 218, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 219, Validation cost: 0.003, Validation R2: 0.747\n",
      "EPOCH:: 220, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 221, Validation cost: 0.003, Validation R2: 0.744\n",
      "EPOCH:: 222, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 223, Validation cost: 0.003, Validation R2: 0.740\n",
      "EPOCH:: 224, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 225, Validation cost: 0.003, Validation R2: 0.736\n",
      "EPOCH:: 226, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 227, Validation cost: 0.003, Validation R2: 0.732\n",
      "EPOCH:: 228, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 229, Validation cost: 0.003, Validation R2: 0.728\n",
      "EPOCH:: 230, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 231, Validation cost: 0.003, Validation R2: 0.725\n",
      "EPOCH:: 232, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 233, Validation cost: 0.003, Validation R2: 0.724\n",
      "EPOCH:: 234, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 235, Validation cost: 0.003, Validation R2: 0.723\n",
      "EPOCH:: 236, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 237, Validation cost: 0.003, Validation R2: 0.724\n",
      "EPOCH:: 238, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 239, Validation cost: 0.003, Validation R2: 0.726\n",
      "EPOCH:: 240, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 241, Validation cost: 0.003, Validation R2: 0.728\n",
      "EPOCH:: 242, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 243, Validation cost: 0.003, Validation R2: 0.731\n",
      "EPOCH:: 244, Validation cost: 0.001, Validation R2: 0.932\n",
      "EPOCH:: 245, Validation cost: 0.003, Validation R2: 0.734\n",
      "EPOCH:: 246, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 247, Validation cost: 0.003, Validation R2: 0.737\n",
      "EPOCH:: 248, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 249, Validation cost: 0.003, Validation R2: 0.740\n",
      "EPOCH:: 250, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 251, Validation cost: 0.003, Validation R2: 0.743\n",
      "EPOCH:: 252, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 253, Validation cost: 0.003, Validation R2: 0.744\n",
      "EPOCH:: 254, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 255, Validation cost: 0.003, Validation R2: 0.745\n",
      "EPOCH:: 256, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 257, Validation cost: 0.003, Validation R2: 0.746\n",
      "EPOCH:: 258, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 259, Validation cost: 0.003, Validation R2: 0.746\n",
      "EPOCH:: 260, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 261, Validation cost: 0.003, Validation R2: 0.745\n",
      "EPOCH:: 262, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 263, Validation cost: 0.003, Validation R2: 0.744\n",
      "EPOCH:: 264, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 265, Validation cost: 0.003, Validation R2: 0.743\n",
      "EPOCH:: 266, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 267, Validation cost: 0.003, Validation R2: 0.742\n",
      "EPOCH:: 268, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 269, Validation cost: 0.003, Validation R2: 0.740\n",
      "EPOCH:: 270, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 271, Validation cost: 0.003, Validation R2: 0.739\n",
      "EPOCH:: 272, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 273, Validation cost: 0.003, Validation R2: 0.738\n",
      "EPOCH:: 274, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 275, Validation cost: 0.003, Validation R2: 0.738\n",
      "EPOCH:: 276, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 277, Validation cost: 0.003, Validation R2: 0.737\n",
      "EPOCH:: 278, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 279, Validation cost: 0.003, Validation R2: 0.738\n",
      "EPOCH:: 280, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 281, Validation cost: 0.003, Validation R2: 0.738\n",
      "EPOCH:: 282, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 283, Validation cost: 0.003, Validation R2: 0.739\n",
      "EPOCH:: 284, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 285, Validation cost: 0.003, Validation R2: 0.741\n",
      "EPOCH:: 286, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 287, Validation cost: 0.003, Validation R2: 0.742\n",
      "EPOCH:: 288, Validation cost: 0.001, Validation R2: 0.933\n",
      "EPOCH:: 289, Validation cost: 0.003, Validation R2: 0.743\n",
      "EPOCH:: 290, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 291, Validation cost: 0.003, Validation R2: 0.744\n",
      "EPOCH:: 292, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 293, Validation cost: 0.003, Validation R2: 0.746\n",
      "EPOCH:: 294, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 295, Validation cost: 0.003, Validation R2: 0.747\n",
      "EPOCH:: 296, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 297, Validation cost: 0.003, Validation R2: 0.747\n",
      "EPOCH:: 298, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 299, Validation cost: 0.003, Validation R2: 0.748\n",
      "EPOCH:: 300, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 301, Validation cost: 0.003, Validation R2: 0.748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:: 302, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 303, Validation cost: 0.003, Validation R2: 0.748\n",
      "EPOCH:: 304, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 305, Validation cost: 0.003, Validation R2: 0.748\n",
      "EPOCH:: 306, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 307, Validation cost: 0.003, Validation R2: 0.748\n",
      "EPOCH:: 308, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 309, Validation cost: 0.003, Validation R2: 0.747\n",
      "EPOCH:: 310, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 311, Validation cost: 0.003, Validation R2: 0.747\n",
      "EPOCH:: 312, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 313, Validation cost: 0.003, Validation R2: 0.746\n",
      "EPOCH:: 314, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 315, Validation cost: 0.003, Validation R2: 0.746\n",
      "EPOCH:: 316, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 317, Validation cost: 0.003, Validation R2: 0.746\n",
      "EPOCH:: 318, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 319, Validation cost: 0.003, Validation R2: 0.746\n",
      "EPOCH:: 320, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 321, Validation cost: 0.003, Validation R2: 0.746\n",
      "EPOCH:: 322, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 323, Validation cost: 0.003, Validation R2: 0.746\n",
      "EPOCH:: 324, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 325, Validation cost: 0.003, Validation R2: 0.747\n",
      "EPOCH:: 326, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 327, Validation cost: 0.003, Validation R2: 0.747\n",
      "EPOCH:: 328, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 329, Validation cost: 0.003, Validation R2: 0.748\n",
      "EPOCH:: 330, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 331, Validation cost: 0.003, Validation R2: 0.749\n",
      "EPOCH:: 332, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 333, Validation cost: 0.003, Validation R2: 0.749\n",
      "EPOCH:: 334, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 335, Validation cost: 0.003, Validation R2: 0.750\n",
      "EPOCH:: 336, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 337, Validation cost: 0.003, Validation R2: 0.751\n",
      "EPOCH:: 338, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 339, Validation cost: 0.003, Validation R2: 0.752\n",
      "EPOCH:: 340, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 341, Validation cost: 0.003, Validation R2: 0.752\n",
      "EPOCH:: 342, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 343, Validation cost: 0.003, Validation R2: 0.752\n",
      "EPOCH:: 344, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 345, Validation cost: 0.003, Validation R2: 0.752\n",
      "EPOCH:: 346, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 347, Validation cost: 0.003, Validation R2: 0.752\n",
      "EPOCH:: 348, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 349, Validation cost: 0.003, Validation R2: 0.753\n",
      "EPOCH:: 350, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 351, Validation cost: 0.003, Validation R2: 0.753\n",
      "EPOCH:: 352, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 353, Validation cost: 0.003, Validation R2: 0.753\n",
      "EPOCH:: 354, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 355, Validation cost: 0.003, Validation R2: 0.753\n",
      "EPOCH:: 356, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 357, Validation cost: 0.003, Validation R2: 0.753\n",
      "EPOCH:: 358, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 359, Validation cost: 0.003, Validation R2: 0.753\n",
      "EPOCH:: 360, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 361, Validation cost: 0.003, Validation R2: 0.753\n",
      "EPOCH:: 362, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 363, Validation cost: 0.003, Validation R2: 0.753\n",
      "EPOCH:: 364, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 365, Validation cost: 0.003, Validation R2: 0.754\n",
      "EPOCH:: 366, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 367, Validation cost: 0.003, Validation R2: 0.753\n",
      "EPOCH:: 368, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 369, Validation cost: 0.003, Validation R2: 0.754\n",
      "EPOCH:: 370, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 371, Validation cost: 0.003, Validation R2: 0.754\n",
      "EPOCH:: 372, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 373, Validation cost: 0.003, Validation R2: 0.755\n",
      "EPOCH:: 374, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 375, Validation cost: 0.003, Validation R2: 0.756\n",
      "EPOCH:: 376, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 377, Validation cost: 0.003, Validation R2: 0.756\n",
      "EPOCH:: 378, Validation cost: 0.001, Validation R2: 0.934\n",
      "EPOCH:: 379, Validation cost: 0.003, Validation R2: 0.757\n",
      "EPOCH:: 380, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 381, Validation cost: 0.003, Validation R2: 0.757\n",
      "EPOCH:: 382, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 383, Validation cost: 0.003, Validation R2: 0.758\n",
      "EPOCH:: 384, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 385, Validation cost: 0.003, Validation R2: 0.758\n",
      "EPOCH:: 386, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 387, Validation cost: 0.003, Validation R2: 0.758\n",
      "EPOCH:: 388, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 389, Validation cost: 0.003, Validation R2: 0.759\n",
      "EPOCH:: 390, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 391, Validation cost: 0.003, Validation R2: 0.759\n",
      "EPOCH:: 392, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 393, Validation cost: 0.003, Validation R2: 0.759\n",
      "EPOCH:: 394, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 395, Validation cost: 0.003, Validation R2: 0.759\n",
      "EPOCH:: 396, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 397, Validation cost: 0.003, Validation R2: 0.759\n",
      "EPOCH:: 398, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 399, Validation cost: 0.003, Validation R2: 0.759\n",
      "EPOCH:: 400, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 401, Validation cost: 0.003, Validation R2: 0.759\n",
      "EPOCH:: 402, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 403, Validation cost: 0.003, Validation R2: 0.760\n",
      "EPOCH:: 404, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 405, Validation cost: 0.003, Validation R2: 0.760\n",
      "EPOCH:: 406, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 407, Validation cost: 0.003, Validation R2: 0.760\n",
      "EPOCH:: 408, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 409, Validation cost: 0.003, Validation R2: 0.761\n",
      "EPOCH:: 410, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 411, Validation cost: 0.002, Validation R2: 0.761\n",
      "EPOCH:: 412, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 413, Validation cost: 0.002, Validation R2: 0.762\n",
      "EPOCH:: 414, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 415, Validation cost: 0.002, Validation R2: 0.762\n",
      "EPOCH:: 416, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 417, Validation cost: 0.002, Validation R2: 0.762\n",
      "EPOCH:: 418, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 419, Validation cost: 0.002, Validation R2: 0.763\n",
      "EPOCH:: 420, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 421, Validation cost: 0.002, Validation R2: 0.763\n",
      "EPOCH:: 422, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 423, Validation cost: 0.002, Validation R2: 0.764\n",
      "EPOCH:: 424, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 425, Validation cost: 0.002, Validation R2: 0.764\n",
      "EPOCH:: 426, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 427, Validation cost: 0.002, Validation R2: 0.764\n",
      "EPOCH:: 428, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 429, Validation cost: 0.002, Validation R2: 0.765\n",
      "EPOCH:: 430, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 431, Validation cost: 0.002, Validation R2: 0.765\n",
      "EPOCH:: 432, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 433, Validation cost: 0.002, Validation R2: 0.765\n",
      "EPOCH:: 434, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 435, Validation cost: 0.002, Validation R2: 0.765\n",
      "EPOCH:: 436, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 437, Validation cost: 0.002, Validation R2: 0.765\n",
      "EPOCH:: 438, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 439, Validation cost: 0.002, Validation R2: 0.765\n",
      "EPOCH:: 440, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 441, Validation cost: 0.002, Validation R2: 0.765\n",
      "EPOCH:: 442, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 443, Validation cost: 0.002, Validation R2: 0.766\n",
      "EPOCH:: 444, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 445, Validation cost: 0.002, Validation R2: 0.766\n",
      "EPOCH:: 446, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 447, Validation cost: 0.002, Validation R2: 0.766\n",
      "EPOCH:: 448, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 449, Validation cost: 0.002, Validation R2: 0.767\n",
      "EPOCH:: 450, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 451, Validation cost: 0.002, Validation R2: 0.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:: 452, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 453, Validation cost: 0.002, Validation R2: 0.768\n",
      "EPOCH:: 454, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 455, Validation cost: 0.002, Validation R2: 0.768\n",
      "EPOCH:: 456, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 457, Validation cost: 0.002, Validation R2: 0.769\n",
      "EPOCH:: 458, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 459, Validation cost: 0.002, Validation R2: 0.769\n",
      "EPOCH:: 460, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 461, Validation cost: 0.002, Validation R2: 0.770\n",
      "EPOCH:: 462, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 463, Validation cost: 0.002, Validation R2: 0.771\n",
      "EPOCH:: 464, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 465, Validation cost: 0.002, Validation R2: 0.771\n",
      "EPOCH:: 466, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 467, Validation cost: 0.002, Validation R2: 0.772\n",
      "EPOCH:: 468, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 469, Validation cost: 0.002, Validation R2: 0.772\n",
      "EPOCH:: 470, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 471, Validation cost: 0.002, Validation R2: 0.772\n",
      "EPOCH:: 472, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 473, Validation cost: 0.002, Validation R2: 0.773\n",
      "EPOCH:: 474, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 475, Validation cost: 0.002, Validation R2: 0.773\n",
      "EPOCH:: 476, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 477, Validation cost: 0.002, Validation R2: 0.773\n",
      "EPOCH:: 478, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 479, Validation cost: 0.002, Validation R2: 0.773\n",
      "EPOCH:: 480, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 481, Validation cost: 0.002, Validation R2: 0.773\n",
      "EPOCH:: 482, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 483, Validation cost: 0.002, Validation R2: 0.774\n",
      "EPOCH:: 484, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 485, Validation cost: 0.002, Validation R2: 0.774\n",
      "EPOCH:: 486, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 487, Validation cost: 0.002, Validation R2: 0.774\n",
      "EPOCH:: 488, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 489, Validation cost: 0.002, Validation R2: 0.775\n",
      "EPOCH:: 490, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 491, Validation cost: 0.002, Validation R2: 0.775\n",
      "EPOCH:: 492, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 493, Validation cost: 0.002, Validation R2: 0.775\n",
      "EPOCH:: 494, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 495, Validation cost: 0.002, Validation R2: 0.776\n",
      "EPOCH:: 496, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 497, Validation cost: 0.002, Validation R2: 0.776\n",
      "EPOCH:: 498, Validation cost: 0.001, Validation R2: 0.935\n",
      "EPOCH:: 499, Validation cost: 0.002, Validation R2: 0.776\n",
      "EPOCH:: 500, Validation cost: 0.001, Validation R2: 0.935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "activation = relu\n",
    "mlp_layers =  [11, 20, 20, 20, 1]\n",
    "layers = []\n",
    "for i_layer in range(len(mlp_layers)-2):\n",
    "    layers.append(Layer(mlp_layers[i_layer], mlp_layers[i_layer+1]))\n",
    "    BatchNorm(mlp_layers[i_layer+1],mlp_layers[i_layer+1])\n",
    "    layers.append(Activation(relu))\n",
    "    \n",
    "layers.append(Layer(mlp_layers[-2], mlp_layers[-1]))\n",
    "# layers.append(Activation(T.nnet.softmax))\n",
    "    \n",
    "x = T.fmatrix('x')\n",
    "t = T.fmatrix('t')\n",
    "\n",
    "params = []\n",
    "for i, layer in enumerate(layers):\n",
    "    params += layer.params\n",
    "    if i == 0:\n",
    "        layer_out = layer.f_prop(x)\n",
    "    else:\n",
    "        layer_out = layer.f_prop(layer_out)\n",
    "\n",
    "y = layers[-1].z\n",
    "# cost = T.mean(T.nnet.categorical_crossentropy(y, t))\n",
    "cost = T.mean((y - t) ** 2)\n",
    "optimizer = Adam(params=params)\n",
    "updates = optimizer.updates(cost)\n",
    "\n",
    "train = theano.function(inputs=[x, t], outputs=cost, updates=updates,\n",
    "                        allow_input_downcast=True, name='train')\n",
    "valid = theano.function(inputs=[x, t], outputs=[cost, y],\n",
    "                        allow_input_downcast=True, name='valid')\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = train_X.shape[0]//batch_size\n",
    "n_epochs = 500\n",
    "for epoch in range(n_epochs):\n",
    "    #train_X, train_y = shuffle(train_X, train_y)\n",
    "    for i in range(n_batches):\n",
    "        start = i*batch_size\n",
    "        end = start + batch_size\n",
    "        train(train_X[start:end], train_y[start:end])\n",
    "    valid_cost, pred_y = valid(valid_X, valid_y)\n",
    "    print('EPOCH:: %i, Validation cost: %.3f, Validation R2: %.3f' %\n",
    "          (epoch + 1, valid_cost,\n",
    "           r2_score(valid_y.astype('float32'),\n",
    "                    pred_y)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
