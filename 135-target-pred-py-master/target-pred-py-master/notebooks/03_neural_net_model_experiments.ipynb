{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.features.build_features import Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load up our training features. X for the features, y for the labels for the respective features, and y_transform for the text classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training features\n",
    "features = Features(project_base=\"../\")\n",
    "X, y, y_transform = features.load_training_features()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(525782, 2048)\n",
      "(525782,)\n",
      "417 417\n",
      "(473203, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(len(y_transform), len(set(y))) # should be the same\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 525,779 data points, each with 2048 features. There are 418 different classes.\n",
    "\n",
    "We save 10% of these for testing, so our traing set has 473,201 data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y  # Delete original X and y to free up ~10GB of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an experiment, we will try a simple neural network model in PyTorch. The model needs 2048 input neurons and 2018 outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train = torch.Tensor(X_train).float()\n",
    "y_train = torch.Tensor(y_train).long()\n",
    "\n",
    "my_dataset = TensorDataset(X_train, y_train)\n",
    "trainloader = DataLoader(my_dataset, batch_size=100, shuffle=True, num_workers=2)\n",
    "\n",
    "X_test = torch.Tensor(X_test).float()\n",
    "y_test = torch.Tensor(y_test).long()\n",
    "\n",
    "my_testset = TensorDataset(X_test, y_test)\n",
    "testloader = DataLoader(my_testset, batch_size=100, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.971\n",
      "[1,  4000] loss: 0.923\n",
      "[2,  2000] loss: 0.630\n",
      "[2,  4000] loss: 0.608\n",
      "[3,  2000] loss: 0.488\n",
      "[3,  4000] loss: 0.501\n",
      "[4,  2000] loss: 0.425\n",
      "[4,  4000] loss: 0.447\n",
      "[5,  2000] loss: 0.391\n",
      "[5,  4000] loss: 0.406\n",
      "[6,  2000] loss: 0.370\n",
      "[6,  4000] loss: 0.389\n",
      "[7,  2000] loss: 0.357\n",
      "[7,  4000] loss: 0.370\n",
      "[8,  2000] loss: 0.346\n",
      "[8,  4000] loss: 0.359\n",
      "[9,  2000] loss: 0.333\n",
      "[9,  4000] loss: 0.350\n",
      "[10,  2000] loss: 0.328\n",
      "[10,  4000] loss: 0.345\n",
      "[11,  2000] loss: 0.323\n",
      "[11,  4000] loss: 0.338\n",
      "[12,  2000] loss: 0.316\n",
      "[12,  4000] loss: 0.331\n",
      "[13,  2000] loss: 0.311\n",
      "[13,  4000] loss: 0.326\n",
      "[14,  2000] loss: 0.307\n",
      "[14,  4000] loss: 0.322\n",
      "[15,  2000] loss: 0.302\n",
      "[15,  4000] loss: 0.319\n",
      "[16,  2000] loss: 0.304\n",
      "[16,  4000] loss: 0.314\n",
      "[17,  2000] loss: 0.297\n",
      "[17,  4000] loss: 0.315\n",
      "[18,  2000] loss: 0.297\n",
      "[18,  4000] loss: 0.310\n",
      "[19,  2000] loss: 0.293\n",
      "[19,  4000] loss: 0.308\n",
      "[20,  2000] loss: 0.292\n",
      "[20,  4000] loss: 0.306\n",
      "[21,  2000] loss: 0.291\n",
      "[21,  4000] loss: 0.301\n",
      "[22,  2000] loss: 0.288\n",
      "[22,  4000] loss: 0.301\n",
      "[23,  2000] loss: 0.287\n",
      "[23,  4000] loss: 0.298\n",
      "[24,  2000] loss: 0.284\n",
      "[24,  4000] loss: 0.297\n",
      "[25,  2000] loss: 0.284\n",
      "[25,  4000] loss: 0.295\n",
      "[26,  2000] loss: 0.284\n",
      "[26,  4000] loss: 0.293\n",
      "[27,  2000] loss: 0.279\n",
      "[27,  4000] loss: 0.293\n",
      "[28,  2000] loss: 0.280\n",
      "[28,  4000] loss: 0.291\n",
      "[29,  2000] loss: 0.275\n",
      "[29,  4000] loss: 0.292\n",
      "[30,  2000] loss: 0.276\n",
      "[30,  4000] loss: 0.288\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.L1 = nn.Linear(2048, 1024)\n",
    "        self.L2 = nn.Linear(1024, 512)\n",
    "        self.output = nn.Linear(512, 418)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = F.relu(self.L1(x))\n",
    "        x = F.relu(self.L2(x))\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "\n",
    "    \n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"../models/simple_nn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test set: 79 %\n",
      "Top 5 accuracy of the network on the test set: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test set: %d %%' % (100 * correct / total))\n",
    "\n",
    "correct_k = 0\n",
    "total_k = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, pred = torch.topk(outputs.data, 5, 1)\n",
    "        for i, p5 in enumerate(pred):\n",
    "            if labels.data[i] in p5:\n",
    "                correct_k += 1\n",
    "            total_k += 1\n",
    "print('Top 5 accuracy of the network on the test set: %d %%' % (100 * correct_k / total_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Phosphodiesterase 4D, Phosphodiesterase 4A, Phosphodiesterase 4B, Phosphodiesterase 3B, Phosphodiesterase 5A, Phosphodiesterase 4C, Phosphodiesterase 2A, Phosphodiesterase 7A, Phosphodiesterase 3A, Phosphodiesterase 10A, Phosphodiesterase 11A, Phosphodiesterase 9A, Phosphodiesterase 6C, Phosphodiesterase 1A, Phosphodiesterase 1C, Phosphodiesterase 7B, Phosphodiesterase 8B, Phosphodiesterase 8A, Phosphodiesterase 1B, Phosphodiesterase 6A, Phosphodiesterase 6D\n",
      "2. Indoleamine 2,3-dioxygenase, Indoleamine 2,3-dioxygenase 2\n",
      "3. Cyclin-dependent kinase 1/cyclin B1, Cyclin-dependent kinase 2/cyclin A, Cyclin-dependent kinase 1/cyclin B, Cyclin-dependent kinase 2/cyclin E, Cyclin-dependent kinase 4/cyclin D1, Cyclin-dependent kinase 2/cyclin E1, Cyclin-dependent kinase 4/cyclin D, Cyclin-dependent kinase 4/cyclin D2\n",
      "4. Monoamine oxidase B, Monoamine oxidase A\n",
      "5. Cytochrome P450 11B1, Cytochrome P450 11B2, Cytochrome P450 1B1, Cytochrome P450 17A1, Cytochrome P450 19A1, Cytochrome P450 2J2, Cytochrome P450 24A1, Cytochrome P450 51, Cytochrome P450 26A1, Cytochrome P450 1A2, Cytochrome P450 2C9, Cytochrome P450 3A4, Cytochrome P450 4F2, Cytochrome P450 1A1, Cytochrome P450 2D6, Cytochrome P450 2A6, Cytochrome P450 2C19, Cytochrome P450 26B1, Cytochrome P450 21, Cytochrome P450 2E1\n",
      "6. Lysine-specific histone demethylase 1, Lysine-specific histone demethylase 1B\n",
      "7. Acetylcholinesterase\n",
      "8. Alkaline phosphatase, tissue-nonspecific isozyme\n",
      "9. Heat shock protein HSP 90-alpha, Heat shock protein HSP 90-beta\n",
      "10. GABA-A receptor alpha-1/beta-3/gamma-2, GABA-A receptor alpha-1/beta-2/gamma-2, GABA A receptor alpha-2/beta-2/gamma-2, GABA A receptor alpha-1/beta-1/gamma-2, GABA-A receptor alpha-2/beta-3/gamma-2, GABA-A receptor alpha-3/beta-3/gamma-2, GABA-A receptor alpha-5/beta-3/gamma-2, GABA A receptor alpha-3/beta-2/gamma-2, GABA-A receptor alpha-1/beta-3, GABA-A receptor alpha-6/beta-3/gamma-2, GABA A receptor alpha-4/beta-3/gamma-2, GABA A receptor alpha-6/beta-2/gamma-2\n",
      "11. Glutaminyl-peptide cyclotransferase\n",
      "12. Mannose-6-phosphate isomerase\n",
      "13. Bromodomain-containing protein 4, Bromodomain-containing protein 2, Bromodomain-containing protein 3, Bromodomain-containing protein 9, Bromodomain-containing protein 1, Bromodomain-containing protein 7\n",
      "14. Quinone reductase 1), Quinone reductase 2\n",
      "15. Rho-associated protein kinase 1, Rho-associated protein kinase 2\n"
     ]
    }
   ],
   "source": [
    "smiles = \"O=C1NC2=CC=C([N+]([O-])=O)C=C2C(C3=CC=CC=C3F)=NC1\"\n",
    "model_input = features.get_numpy_fingerprint_from_smiles(smiles)\n",
    "model_input = torch.Tensor(model_input).float()\n",
    "inputs = model_input.to(device)\n",
    "\n",
    "output = net(inputs)\n",
    "\n",
    "_, pred = torch.topk(output, 15)\n",
    "preds = [y_transform[x] for x in pred]\n",
    "for i, pred in enumerate(preds):\n",
    "    print(\"{}. {}\".format(i+1, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
