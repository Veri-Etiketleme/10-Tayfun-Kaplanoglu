{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Driving Car - Lane Lines & Vehicle Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import section for our used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import data, color, exposure\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from scipy.ndimage.measurements import label\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Convolution2D, Flatten, Input, Conv2D, MaxPooling2D, Lambda\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Show plots inline notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Import the dataset containing cars and non-cars images with a resolution of 64x64 pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cars = glob.glob(\"./dataset/vehicles/*/*.png\")\n",
    "non_cars = glob.glob(\"./dataset/non-vehicles/*/*.png\")\n",
    "\n",
    "# Read X Vector\n",
    "X = []\n",
    "for file in cars:    \n",
    "    X.append(skimage.io.imread(file))\n",
    "for file in non_cars:    \n",
    "    X.append(skimage.io.imread(file))\n",
    "X = np.array(X)\n",
    "\n",
    "# Generate Y Vector\n",
    "Y = np.concatenate([np.ones(len(cars)), np.zeros(len(non_cars))])\n",
    "\n",
    "# Split train and validation dataset with 10%\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=63)\n",
    "\n",
    "# Show messages\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Explore the dataset by showing 40 random images from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def showRandomImages():\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    for i in range(0, 40):\n",
    "        number = np.random.randint(0, len(X_train))\n",
    "        axis = fig.add_subplot(4,10,i+1)\n",
    "        axis.set_xlabel(Y_train[number])\n",
    "        plt.xticks(np.array([]))\n",
    "        plt.yticks(np.array([]))\n",
    "        axis.imshow(X_train[number])\n",
    "    plt.show()\n",
    "\n",
    "showRandomImages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a distribution to see if the dataset is balanced or unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def showDistribution():\n",
    "    _, training_counts = np.unique(Y_train, return_counts = True)\n",
    "    _, test_counts = np.unique(Y_test, return_counts = True)\n",
    "    plt.bar( np.arange( 2 ), training_counts,   color='b', label='Training Data')\n",
    "    plt.bar( np.arange( 2 ), test_counts,  color='g', label='Testing Data')\n",
    "    plt.xlabel('ClassID')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "showDistribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create the all-convolutional network and add a flatten layer at the end for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape=(64,64,3)):\n",
    "    model = Sequential()\n",
    "    # Center and normalize our data\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,input_shape=input_shape, output_shape=input_shape))\n",
    "    # 1st conv layer with 128 filter, 3x3 each, 50% dropout\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv1',input_shape=input_shape, border_mode=\"same\"))  \n",
    "    model.add(Dropout(0.5))\n",
    "    # 2nd conv layer with 128 filter, 3x3 each, 50% dropout\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2',border_mode=\"same\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    # 3rd conv layer with 128 filter, 3x3 each, 8x8 pooling and dropout\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv3',border_mode=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(8,8)))\n",
    "    model.add(Dropout(0.5))\n",
    "    # This acts like a 128 neuron dense layer\n",
    "    model.add(Convolution2D(128,8,8,activation=\"relu\",name=\"dense1\")) \n",
    "    model.add(Dropout(0.5))\n",
    "    # This is like a 1 neuron dense layer with tanh [-1, 1]\n",
    "    model.add(Convolution2D(1,1,1,name=\"dense2\", activation=\"tanh\")) \n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train the network using the dataset, ONLY DO THIS ONCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot the results of the training\n",
    "def plot_results(history):\n",
    "    # Summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # Summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=128, nb_epoch=20, verbose=2, validation_data=(X_test, Y_test))\n",
    "\n",
    "plot_results(history)\n",
    "\n",
    "model.save_weights('./dataset/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Load the weights from the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load the fine-tuned for the final network\n",
    "model.load_weights('./dataset/model.h5')\n",
    "print(\"Weights loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Initialize the weights for the network and try it on a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Pick a random image from the test set\n",
    "rand = np.random.randint(X_test.shape[0])\n",
    "plt.imshow(X_test[rand])\n",
    "\n",
    "# Predict the correct label\n",
    "sample = np.reshape(X_test[rand], (1, 64,64,3))\n",
    "prediction = model.predict(sample, batch_size=64, verbose=0)\n",
    "prediction = prediction[0][0]\n",
    "\n",
    "# Check if the prediction is a car or a non-car\n",
    "if prediction >= 0.5:\n",
    "    print(\"NN Prediction: CAR with value \" + str(prediction))\n",
    "else:\n",
    "    print(\"NN Prediction: NO CAR with value \" + str(prediction))\n",
    "    \n",
    "# Compare with the ground-truth\n",
    "truth = Y_test[rand]\n",
    "if truth == 1:\n",
    "    print(\"Ground-truth: CAR with value \" + str(truth))\n",
    "else:\n",
    "    print(\"Ground-truth: NO CAR with value \" + str(truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We load a sample image to test our neural network on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load a specific sample image\n",
    "img = skimage.io.imread('./test_images/test4.jpg')\n",
    "\n",
    "# Display it\n",
    "fig = plt.figure(figsize=(12,20))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Search for cars in the image using the neural network, create bounding boxes for each hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    draw_img = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(draw_img, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return draw_img\n",
    "\n",
    "def search_cars(img):\n",
    "    # We crop the image to 440-660px in the vertical direction\n",
    "    cropped = img[400:660, 0:1280]\n",
    "    heat = heatmodel.predict(cropped.reshape(1,cropped.shape[0],cropped.shape[1],cropped.shape[2]))\n",
    "    # This finds us rectangles that are interesting\n",
    "    xx, yy = np.meshgrid(np.arange(heat.shape[2]),np.arange(heat.shape[1]))\n",
    "    x = (xx[heat[0,:,:,0]>0.9999999])\n",
    "    y = (yy[heat[0,:,:,0]>0.9999999])\n",
    "    hot_windows = []\n",
    "    # We save those rects in a list\n",
    "    for i,j in zip(x,y):\n",
    "        hot_windows.append(((i*8,400 + j*8), (i*8+64,400 +j*8+64)))\n",
    "    return hot_windows\n",
    "\n",
    "# Init a version of our network with another resolution without the flatten layer\n",
    "heatmodel = create_model((260, 1280, 3))\n",
    "# Load the weights\n",
    "heatmodel.load_weights('./dataset/model.h5')\n",
    "\n",
    "# Search for our windows\n",
    "hot_windows = search_cars(img)\n",
    "\n",
    "# Draw the found boxes on the test image\n",
    "window_img = draw_boxes(img, hot_windows, (0, 255, 0), 6)                    \n",
    "\n",
    "# Show the image with the windows on top\n",
    "fig = plt.figure(figsize=(12,20))\n",
    "plt.imshow(window_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a heatmap out of the found bounding boxes, threshold it and find the final bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,255,0), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "# Create image for the heat similar to one shown above \n",
    "heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "\n",
    "# Add heat to each box in box list\n",
    "heat = add_heat(heat,hot_windows)\n",
    "    \n",
    "# Apply threshold to help remove false positives\n",
    "heat = apply_threshold(heat, 3)\n",
    "\n",
    "# Visualize the heatmap when displaying    \n",
    "heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "# Find final boxes from heatmap using label function\n",
    "boxes = label(heatmap)\n",
    "\n",
    "# Create the final image\n",
    "draw_img = draw_labeled_bboxes(np.copy(img), boxes)\n",
    "\n",
    "# Show the car positions and the heat map with threshold applied\n",
    "fig = plt.figure(figsize=(12,20))\n",
    "plt.subplot(121)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Car Positions')\n",
    "plt.subplot(122)\n",
    "plt.imshow(heatmap, cmap='hot')\n",
    "plt.title('Heat Map')\n",
    "fig.tight_layout()\n",
    "\n",
    "# Print information about the cars found\n",
    "print(boxes[1], 'cars found')\n",
    "fig = plt.figure(figsize=(12,20))\n",
    "plt.imshow(boxes[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline identifies the area inside two lanes and draws a blue polygon on top of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define the source points\n",
    "src_points = np.float32([[0 , 720],\n",
    "                         [1280 , 720],\n",
    "                         [750 , 470],\n",
    "                         [530 , 470]])\n",
    "\n",
    "# Define the destination points\n",
    "dst_points = np.float32([[320 , 720],\n",
    "                         [960 , 720],\n",
    "                         [960 , 0],\n",
    "                         [320 , 0]])\n",
    "# Storing our averages\n",
    "prev_frames = []\n",
    "prev_curvatures = []\n",
    "prev_car_off = []\n",
    "\n",
    "def region_of_interest(img,vertices):\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "\n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def applyTransformation(img):\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    transformed = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # Return transformed image\n",
    "    return transformed\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255):\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(img, thresh_min=0, thresh_max=255):\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=9)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=9)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= thresh_min) & (gradmag <= thresh_max)] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "def applySobelMask(img):\n",
    "    # Convert to HLS and extract L and S channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Apply sobel in x direction on L and S channel\n",
    "    l_channel_sobel_x = abs_sobel_thresh(l_channel,'x', 20, 200)\n",
    "    s_channel_sobel_x = abs_sobel_thresh(s_channel,'x', 60, 200)\n",
    "    sobel_combined_x = cv2.bitwise_or(s_channel_sobel_x, l_channel_sobel_x)\n",
    "    \n",
    "    # Apply magnitude sobel\n",
    "    l_channel_mag = mag_thresh(l_channel, 80, 200)\n",
    "    s_channel_mag = mag_thresh(s_channel, 80, 200)\n",
    "    mag_combined = cv2.bitwise_or(l_channel_mag, s_channel_mag)\n",
    "    \n",
    "    # Combine all the sobel filters\n",
    "    mask_combined = cv2.bitwise_or(mag_combined, sobel_combined_x)\n",
    "    \n",
    "    # Mask out the desired image and filter image again\n",
    "    mask_combined = region_of_interest(mask_combined, np.array([[(330, 0),(950, 0), (950, 680), (330, 680)]]))\n",
    "    \n",
    "    # Return the sobel mask\n",
    "    return mask_combined\n",
    "\n",
    "def applyColorMask(img):\n",
    "    # Convert to HLS and extract S and V channel\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Define color thresholds in HSV\n",
    "    white_low = np.array([[[0, 0, 210]]])\n",
    "    white_high = np.array([[[255, 30, 255]]])\n",
    "\n",
    "    yellow_low = np.array([[[18, 80, 80]]])\n",
    "    yellow_high = np.array([[[30, 255, 255]]])\n",
    "\n",
    "    # Apply the thresholds to get only white and yellow\n",
    "    white_mask = cv2.inRange(img_hsv, white_low, white_high)\n",
    "    yellow_mask = cv2.inRange(img_hsv, yellow_low, yellow_high)\n",
    "\n",
    "    # Bitwise or the yellow and white mask\n",
    "    color_mask = cv2.bitwise_or(yellow_mask, white_mask)\n",
    "    return color_mask\n",
    "\n",
    "def combineMasks(sobel_mask, color_mask):\n",
    "    mask_combined = np.zeros_like(sobel_mask)\n",
    "    mask_combined[(color_mask>=.5)|(sobel_mask>=.5)] = 1\n",
    "    return mask_combined\n",
    "\n",
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "def slidingWindow(img):\n",
    "    # Window settings\n",
    "    window_width = 50\n",
    "    window_height = 100\n",
    "    # How much to slide left and right for searching\n",
    "    margin = 30\n",
    "    \n",
    "    # Store the (left,right) window centroid positions per level\n",
    "    window_centroids = [] \n",
    "    # Create our window template that we will use for convolutions\n",
    "    window = np.ones(window_width) \n",
    "    \n",
    "    # Find the starting point for the lines\n",
    "    l_sum = np.sum(img[int(3*img.shape[0]/5):,:int(img.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    r_sum = np.sum(img[int(3*img.shape[0]/5):,int(img.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(img.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1, (int)(img.shape[0] / window_height)):\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        image_layer = np.sum(img[int(img.shape[0]-(level+1)*window_height):int(img.shape[0]-level*window_height),:], axis=0)\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "        offset = window_width / 2\n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        l_min_index = int(max(l_center+offset-margin,0))\n",
    "        l_max_index = int(min(l_center+offset+margin,img.shape[1]))\n",
    "        l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        r_min_index = int(max(r_center+offset-margin,0))\n",
    "        r_max_index = int(min(r_center+offset+margin,img.shape[1]))\n",
    "        r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # If we have found any window centers, print error and return\n",
    "    if len(window_centroids) == 0:\n",
    "        print(\"No windows found in this frame!\")\n",
    "        return\n",
    "    \n",
    "    # Points used to draw all the left and right windows\n",
    "    l_points = np.zeros_like(img)\n",
    "    r_points = np.zeros_like(img)\n",
    "\n",
    "    # Go through each level and draw the windows\n",
    "    for level in range(0,len(window_centroids)):\n",
    "        # Window_mask is a function to draw window areas\n",
    "        l_mask = window_mask(window_width,window_height,img,window_centroids[level][0],level)\n",
    "        r_mask = window_mask(window_width,window_height,img,window_centroids[level][1],level)\n",
    "        # Add graphic points from window mask here to total pixels found \n",
    "        l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "        r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "    # Draw the results\n",
    "    template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "    zero_channel = np.zeros_like(template) # create a zero color channle \n",
    "    template = np.array(cv2.merge((template, template, template)),np.uint8) # make window pixels green\n",
    "    warpage = np.array(cv2.merge((img, img, img)),np.uint8) # making the original road pixels 3 color channels\n",
    "    output = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = np.nonzero(l_points)[1]\n",
    "    lefty = np.nonzero(l_points)[0]\n",
    "    rightx = np.nonzero(r_points)[1]\n",
    "    righty = np.nonzero(r_points)[0]\n",
    "            \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Return left and right lines as well as the image\n",
    "    return left_fit, right_fit, output\n",
    "\n",
    "def calcCurvature(left_fit, right_fit):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    ploty = np.linspace(0, 719, num=720)\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    \n",
    "    # Set y-value to bottom of the image\n",
    "    y_eval = 719\n",
    "    # Calculate left and right curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    # Match them together\n",
    "    curverad = (left_curverad + right_curverad) / 2\n",
    "    \n",
    "    # Use the last ten values and build the average of them\n",
    "    prev_curvatures.append(curverad)\n",
    "    avg_curverad = np.average(prev_curvatures[-10:])\n",
    "    \n",
    "    # Return the average curvature in meter\n",
    "    return avg_curverad\n",
    "\n",
    "def calcCarOff(left_fit, right_fit):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Left and right line intercept on x axis\n",
    "    left_intcpt = left_fit[0]*720**2 + left_fit[1]*720 + left_fit[2]\n",
    "    right_intcpt = right_fit[0]*720**2 + right_fit[1]*720 + right_fit[2]\n",
    "\n",
    "    # Calculate the middle of the lanes\n",
    "    lane_mid = (left_intcpt + right_intcpt)/2.0\n",
    "\n",
    "    # Calculate the offset\n",
    "    car_off = (lane_mid - 1280/2.0)*xm_per_pix\n",
    "    \n",
    "    # Average over the last ten positions\n",
    "    prev_car_off.append(car_off)\n",
    "    avg_car_off = np.average(prev_car_off[-10:])\n",
    "    \n",
    "    return avg_car_off\n",
    "\n",
    "def displayInfo(img, curverad, car_off):\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "    curve_disp_txt = 'Curvature: ' + str(np.round(curverad,2)) + 'm'\n",
    "    off_disp_txt = 'Car offset: ' + str(np.round(car_off,2)) + 'm'\n",
    "    cv2.putText(img, curve_disp_txt, (20, 30), font, 1, (0,0,0), 2)\n",
    "    cv2.putText(img, off_disp_txt, (20, 60), font, 1, (0,0,0), 2)\n",
    "    return img\n",
    "\n",
    "def applyBackTrans(img, left_fit, right_fit):\n",
    "    ploty = np.linspace(0, 719, num=720)\n",
    "    # Calculate left and right x positions\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    # Defining a blank mask to start with\n",
    "    polygon = np.zeros_like(img) \n",
    "\n",
    "    # Create an array of points for the polygon\n",
    "    plot_y = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, plot_y]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, plot_y])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the polygon in blue\n",
    "    cv2.fillPoly(polygon, np.int_([pts]), (0, 0, 255))\n",
    "    \n",
    "    # Calculate top and bottom distance between the lanes\n",
    "    top_dist = right_fitx[0] - left_fitx[0]\n",
    "    bottom_dist = right_fitx[-1] - left_fitx[-1]\n",
    "    \n",
    "    # Add the polygon to the list of last frames if it makes sense\n",
    "    if len(prev_frames) > 0: \n",
    "        if top_dist < 300 or bottom_dist < 300 or top_dist > 500 or bottom_dist > 500:\n",
    "            polygon = prev_frames[-1]\n",
    "        else:\n",
    "            prev_frames.append(polygon)\n",
    "    else:\n",
    "        prev_frames.append(polygon)\n",
    "        \n",
    "    # Check that the new detected lane is similar to the one detected in the previous frame\n",
    "    polygon_gray = cv2.cvtColor(polygon, cv2.COLOR_RGB2GRAY) \n",
    "    prev_gray = cv2.cvtColor(prev_frames[-1], cv2.COLOR_RGB2GRAY)  \n",
    "    non_similarity = cv2.matchShapes(polygon_gray,prev_gray, 1, 0.0)\n",
    "    if non_similarity > 0.002: \n",
    "        polygon = prev_frames[-1]\n",
    "\n",
    "    # Calculate the inverse transformation matrix\n",
    "    M_inv = cv2.getPerspectiveTransform(dst_points, src_points)\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    image_backtrans = cv2.warpPerspective(polygon, M_inv, (img.shape[1], img.shape[0])) \n",
    "    \n",
    "    # Return the 8-bit mask\n",
    "    return np.uint8(image_backtrans)\n",
    "\n",
    "def findLanes(img):   \n",
    "    # Copy and crop the image\n",
    "    img_cropped = np.copy(img)\n",
    "    img_cropped = region_of_interest(img_cropped, [src_points.astype(np.int32)])\n",
    "    \n",
    "    # Apply image transformation\n",
    "    img_warped = applyTransformation(img_cropped)\n",
    "    \n",
    "    # Apply the sobel mask to the image\n",
    "    img_sobel = applySobelMask(img_warped)\n",
    "    \n",
    "    # Apply the color mask to the image\n",
    "    img_color = applyColorMask(img_warped)\n",
    "    \n",
    "    # Combine color and sobel mask\n",
    "    img_mask = combineMasks(img_sobel, img_color)\n",
    "    \n",
    "    # Find the lines from polyfit\n",
    "    left_fit, right_fit, _ = slidingWindow(img_mask)\n",
    "    \n",
    "    # Create the lane mask and apply backtransformation\n",
    "    lane_mask = applyBackTrans(img, left_fit, right_fit)\n",
    "    \n",
    "    # Combine the sample image with the lane layer\n",
    "    img_result = cv2.addWeighted(img, 1, lane_mask, 1, 0)\n",
    "    \n",
    "    # Add the information for the image\n",
    "    curverad = calcCurvature(left_fit, right_fit)\n",
    "    car_off = calcCarOff(left_fit, right_fit)\n",
    "    img_info = displayInfo(img_result, curverad, car_off)\n",
    "    return img_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is our final image pipeline, where we draw the bounding boxes on top of each frame and also identify the lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_image(img):      \n",
    "    # Find the lane lines first\n",
    "    img_lanes = findLanes(img)\n",
    "    \n",
    "    # Create image for the heat similar to one shown above \n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    \n",
    "    # Search for cars\n",
    "    hot_windows = search_cars(img)\n",
    "\n",
    "    # Create image for the heat similar to one shown above \n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "\n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat,hot_windows)\n",
    "    \n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat, 3)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    boxes = label(heatmap)\n",
    "\n",
    "    # Create the final image\n",
    "    draw_img = draw_labeled_bboxes(img_lanes, boxes)\n",
    "    \n",
    "    # Return it to the video processing tool\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Apply the image pipeline to all test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Repeat for all images\n",
    "for index, image in enumerate(os.listdir(\"test_images/\")):\n",
    "    # Restore averages for every image\n",
    "    prev_frames = []\n",
    "    prev_curvatures = []\n",
    "    prev_car_off = []\n",
    "    \n",
    "    # Read in image\n",
    "    img = skimage.io.imread('test_images/' + image)\n",
    "    \n",
    "    # Let the image go through the pipeline\n",
    "    img_lane = process_image(img)\n",
    "    \n",
    "    #Display the final image\n",
    "    fig = plt.figure(figsize=(12,20))\n",
    "    plt.imshow(img_lane)\n",
    "    \n",
    "    #Save it to file\n",
    "    fig.savefig('output_images/' + image, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Pipeline for our videos with avering over several frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create history element\n",
    "history = None\n",
    "\n",
    "# Our video processing pipeline\n",
    "def process_video(img):\n",
    "    # Find the lane lines first\n",
    "    img_lanes = findLanes(img)\n",
    "    \n",
    "    # Create image for the heat similar to one shown above \n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "\n",
    "    # Find the cars\n",
    "    hot_windows = search_cars(img)\n",
    "\n",
    "    # Create image for the heat similar to one shown above \n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "\n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat,hot_windows)\n",
    "    \n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,3)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    boxes = label(heatmap)\n",
    "    \n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, boxes[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (boxes[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Append current boxe to history\n",
    "        history.append([np.min(nonzerox),np.min(nonzeroy),np.max(nonzerox),np.max(nonzeroy)])\n",
    "    \n",
    "    # Get recent boxes for the last 30 fps\n",
    "    recent_boxes = np.array(history).tolist()\n",
    "\n",
    "    # Groups the object candidate rectangles with difference of 10%\n",
    "    boxes = cv2.groupRectangles(recent_boxes, 10, .1)\n",
    "    \n",
    "    # Draw rectangles if found\n",
    "    if len(boxes[0]) != 0:\n",
    "        for box in boxes[0]:\n",
    "            cv2.rectangle(img_lanes, (box[0], box[1]), (box[2],box[3]), (0,255,0), 6)\n",
    "            \n",
    "    # Return image with found cars and lanes\n",
    "    return img_lanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Process the project video and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Restore averages\n",
    "prev_frames = []\n",
    "prev_curvatures = []\n",
    "prev_car_off = []\n",
    "# Create history for 30 frames\n",
    "history = deque(maxlen=30)\n",
    "# Process the video\n",
    "clip_output = 'output_videos/project_video.mp4'\n",
    "clip = VideoFileClip(\"test_videos/project_video.mp4\")\n",
    "clip_process = clip.fl_image(process_video)\n",
    "%time clip_process.write_videofile(clip_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
