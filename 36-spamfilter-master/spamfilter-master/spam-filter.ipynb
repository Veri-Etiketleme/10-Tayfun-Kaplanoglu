{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected:\n",
      " 501  Spam Files\n",
      " 2501  Ham Files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strings Loaded:\n",
      " 501  Spam Files\n",
      " 2501  Ham Files\n"
     ]
    }
   ],
   "source": [
    "# Read in Files (Complete)\n",
    "import os \n",
    "\n",
    "ppath = '/home/lucas/Cloud/code-projects/Machine-Learning-OReilly/classification/spam_dataset' \n",
    "\n",
    "spam_files = os.listdir('/home/lucas/Cloud/code-projects/Machine-Learning-OReilly/classification/spam_dataset/spam')\n",
    "ham_files = os.listdir('/home/lucas/Cloud/code-projects/Machine-Learning-OReilly/classification/spam_dataset/ham')\n",
    "\n",
    "print(\"Detected:\\n\", len(spam_files), ' Spam Files\\n', len(ham_files), \" Ham Files\")\n",
    "\n",
    "\n",
    "# Spam: Reading Files to String\n",
    "spam_raw = []\n",
    "for file in spam_files:\n",
    "    temp = codecs.open(ppath+'/spam/'+file, 'r', encoding='utf-8', errors='ignore').read()\n",
    "    spam_raw.append(temp)\n",
    "\n",
    "# Ham: Reading Files to String \n",
    "ham_raw = []\n",
    "for file in ham_files:\n",
    "    temp = codecs.open(ppath+'/ham/'+file, 'r', encoding='utf-8', errors='ignore').read()\n",
    "    ham_raw.append(temp)\n",
    "\n",
    "print(\"Strings Loaded:\\n\", len(spam_raw), \" Spam Files\\n\", len(ham_raw), \" Ham Files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentType textplain charsetiso88591\n",
      "ContentDisposition inline\n",
      "ContentTransferEncoding 7bit\n",
      "\n",
      "To view this newsletter in fullcolor\n",
      "\n",
      "\n",
      "Media Unspun\n",
      "What the Press is Reporting and Why wwwmediaunspuncom\n",
      "\n",
      "October 8 2002\n",
      "\n",
      "\n",
      "IN THIS ISSUE\n",
      "\n",
      " BUSH COVERS THE WATERFRONT\n",
      " THE BIGGEST CABLE HOOKUP\n",
      "\n",
      "\n",
      "EDITORS NOTE\n",
      "\n",
      "Is Media Unspun useful to you? Then pass it on to a colleague\n",
      "The more readers we have the more successful well be The more \n",
      "successful we are the more useful we can be to you Pass it\n",
      "on\n",
      "\n",
      "Media Unspun serves business news and analysis authoritatively\n",
      "and irreverently every business day An annual subscription\n",
      "costs 50 less than a dollar a week If your fourweek free\n",
      "trial is coming to an end soon please visit\n",
      " and sign up via credit card \n",
      "or check\n",
      "\n",
      "\n",
      "\n",
      "ADVERTISEMENT\n",
      "\n",
      "PopTech 2002\n",
      "October 18  20 2002 Camden Maine\n",
      "Join 500 big thinkers to discuss\n",
      "the collision of technology and culture\n",
      "Register now at \n",
      "\n",
      "\n",
      "\n",
      "BUSH COVERS THE WATERFRONT\n",
      "\n",
      "It may seem like all Iraq all the time in the Oval Office but\n",
      "the president has at least one other thing on his mind this\n",
      "week that pesky port lockout The freight still isnt moving\n",
      "factories are running out of parts produce is rotting and\n",
      "retailers are more freaked about Christmas with every passing\n",
      "day \n",
      "\n",
      "On Monday Bush stepped in and appointed a threemember panel to \n",
      "see how badly this shutdown is hosing the economy We hope this \n",
      "isnt a difficult question as the panels been given all of one \n",
      "day to report back When Bush gets the report on Tuesday the\n",
      "next step might be a court order to reopen the ports under the\n",
      "1947 TaftHartley Act That would send employees back to work\n",
      "for 80 days while federal mediators duke it out over the\n",
      "disputed contract and retailers lower their Xanax dosages\n",
      "\n",
      "Invoking TaftHartley requires a threat to national health or\n",
      "safety  not the economy But Labor Secretary Elaine Chao\n",
      "covered that base in a statement on Monday saying the work\n",
      "stoppage threatens the flow of supplies to the military we knew \n",
      "Iraq would be in here somewhere Union officials quickly\n",
      "responded that their members have been unloading military cargo\n",
      "throughout the 10day shutdown said the LA Times but an\n",
      "anonymous Bush administration official said that only a portion \n",
      "of what the Defense Department needs has made it ashore\n",
      "\n",
      "Politically this has been a tricky one Using TaftHartley\n",
      "would annoy labor right before congressional elections On the\n",
      "other hand Voter discontent with Bushs handling of the\n",
      "increasingly fragile economic recovery has begun showing up in\n",
      "polls and such concerns may have outweighed the political\n",
      "danger to the Republican administration said the San Francisco \n",
      "Chronicle Also Bush stepped in on the same day that a poll\n",
      "reported twothirds of Americans wanted him to focus more on the \n",
      "economy Though the administration promised an unbiased\n",
      "examination of the lockout Bush appeared to have made up his\n",
      "mind that it was hurting national security and the economy\n",
      "andmerited federal intervention said the AP \n",
      "\n",
      "As for TaftHartley its not exactly famous for solving labor\n",
      "disputes Often the 80day coolingoff period ends and workers\n",
      "simply walk out again or get locked out again in this case\n",
      "One gets the sense however that fixing the dockworkers\n",
      "contract isnt the point of this particular 80 days Its 78\n",
      "days until Christmas The race is on  Jen Muehlbauer\n",
      "\n",
      "President Acts To Halt Port Lockout for 80 Days Seattle\n",
      "Times\n",
      "\n",
      "\n",
      "Bush Expected To Act on Ports Crisis \n",
      "\n",
      "\n",
      "President Moves Toward Forcing the Reopening of West Coast\n",
      "Ports\n",
      "01021983story\n",
      "\n",
      "\n",
      "Bush Takes Step Toward Halting Lockout After West Coast Port\n",
      "Talks Break Off AP\n",
      "\n",
      "\n",
      "White House Intervenes on Docks Dispute Financial Times\n",
      "\n",
      "\n",
      "Coolingoff Period Likely in Port Fight SF Chronicle\n",
      "\n",
      "\n",
      "Bush Moves Toward Halting Port Shutdown\n",
      "\n",
      "\n",
      "Trouble On The Docks\n",
      "2086400html\n",
      "Paid subscription required\n",
      "\n",
      "Charges of Politics Have Dogged TaftHartley Act\n",
      "\n",
      "\n",
      "TaftHartley Act No QuickFix For Port Dispute Reuters\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ADVERTISEMENT\n",
      "\n",
      "SPECIAL OFFER   Save 24 on a subscription to MIT TECHNOLOGY\n",
      "REVIEW Get an inside view into the technologies deals and\n",
      "companies emerging from one of the leading research institutes\n",
      " MIT \n",
      " \n",
      "\n",
      "\n",
      "THE BIGGEST CABLE HOOKUP\n",
      "\n",
      "wo birds want to join forces and the FCC is about to cry fowl \n",
      "We mean foul The two dominant direct broadcast satellite\n",
      "players want to join forces the better to compete with Big\n",
      "Cable Federal regulators both the FCC and the Justice\n",
      "Department are concerned that the resulting conglomerate of\n",
      "DirecTV with Dish Network would command roughly 95 of satellite \n",
      "service in the US\n",
      "\n",
      "The press could not settle on a price tag for the proposed\n",
      "merger between EchoStar Communications and Hughes Electronics  \n",
      "it was described as being worth anywhere from 15 billion and\n",
      "25 billion It was a challenge to keep the players straight as \n",
      "some outlets talked of a merger between the corporate parents\n",
      "and others referred to the service monikers Hughes is DirecTV\n",
      "and EchoStar is Dish All straight?\n",
      "\n",
      "The two companies sent a letter to the FCC urging them to hold\n",
      "off ruling on read rejecting the merger until the Justice\n",
      "Department has spoken EchoStar and Hughes offered unspecified\n",
      "major revisions to the deal that they want to discuss with\n",
      "Justice in the next weeks\n",
      "\n",
      "The Wall Street Journal delved deeply into the form those\n",
      "revisions could take  specifically selling some frequencies\n",
      "to Cablevision The Journal reported that Cablevision has wanted \n",
      "to get into the satellite business for 10 years and outlined the \n",
      "cable companys plans and past spending on such a project\n",
      "\n",
      "TheStreetcom turned in an extensive analysis of the deal for\n",
      "investors in the satellite space It seems the market for\n",
      "expandedservice television may be nearing saturation\n",
      "TheStreetcom quoted an analysts report which concluded\n",
      "Consumers should benefit from  continued rivalry but\n",
      "shareholders may realize much smaller returns\n",
      "\n",
      "The New York Times and the Journal both mentioned Rupert Murdoch \n",
      "waiting in the wings Last year Murdochs News Corp bid for\n",
      "DirecTV but lost out at the last minute to EchoStar If the\n",
      "current deal falls through hell be back  Keith Dawson\n",
      "\n",
      "EchoStar and Hughes Propose Concessions in Bid to Save Deal\n",
      "SB10340331425809456000html\n",
      "Paid subscription required\n",
      "\n",
      "Regulators Set to Block EchoStars Hughes Purchase\n",
      "SB103393990134622839300html\n",
      "Paid subscription required\n",
      "\n",
      "Lastditch effort Rocky Mountain News\n",
      "\n",
      "\n",
      "EchoStar Hughes See a Glimmer of Hope\n",
      "\n",
      "\n",
      "FCC Asked to Put Off Merger Ruling\n",
      "\n",
      "\n",
      "EchoStar Hughes ask FCC to defer decision\n",
      "\n",
      "\n",
      "EchoStar Hughes offer merger changes Reuters \n",
      "\n",
      "\n",
      "Delay in satelliteTV merger OK requested AP\n",
      "\n",
      "\n",
      "EchoStar Hughes Seek to Delay Ruling\n",
      "03454976story\n",
      "\n",
      "\n",
      "EchoStar pleads to FCC on merger Denver Post\n",
      "\n",
      "\n",
      "\n",
      "OTHER STORIES\n",
      "\n",
      "SEC Probes AOLOxygen Pact For DoubleBooking of Revenue\n",
      "SB103393811368473119300html\n",
      "Paid subscription required\n",
      "\n",
      "Tivo Raises 25 Million in Stock Offering AP\n",
      "\n",
      "\n",
      "WorldCom Officer Pleads Guilty to Fraud\n",
      "\n",
      "\n",
      "\n",
      "Two Magazines Are Shut and a Third Revamps\n",
      "\n",
      "\n",
      "Regulators Say They Have CSFB Smoking Gun\n",
      "\n",
      "\n",
      "\n",
      "Expected Cold Winter Could Increase Natural Gas Prices \n",
      "\n",
      "\n",
      "Frozen World Found Beyond Pluto\n",
      "\n",
      "\n",
      "Fool Me Once\n",
      "\n",
      "\n",
      "New Northwest System for Internet Bookings\n",
      "\n",
      "\n",
      "The FastestGrowing Tech Companies\n",
      "1100html\n",
      "\n",
      "Debating the Baby Bells\n",
      "\n",
      "Paid subscription required\n",
      "\n",
      "Silicon Valley Is Yearning For UserFriendly Microsoft\n",
      "SB103403665130002876000html\n",
      "Paid subscription required\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Do you want to reach the Nets savviest audience?\n",
      "Advertise in Media Unspun\n",
      "Contact Erik Vanderkolk for details at erikvanderkolkyahoocom \n",
      "today\n",
      "\n",
      "\n",
      "STAFF\n",
      "\n",
      "Written by Deborah Asbrand dasbrandworldstdcom Keith\n",
      "Dawson dawsonworldstdcom Jen Muehlbauer\n",
      "jenenglishmajorcom and Lori Patel loripatelhotmailcom\n",
      "\n",
      "Copyedited by Jim Duffy jimduffy86yahoocom \n",
      "Advertising Erik Vanderkolk erikvanderkolkyahoocom \n",
      "Editor and publisher Jimmy Guterman gutermanvineyardcom\n",
      "\n",
      "Media Unspun is produced by The Vineyard Group Inc \n",
      "Copyright 2002 Media Unspun Inc and The Vineyard Group Inc\n",
      "\n",
      "Subscribe already willya? \n",
      " \n",
      "Redistribution by email is permitted as long as a link to\n",
      " is included\n",
      "\n",
      "\n",
      "|\n",
      "POWERED BY \n",
      "To be removed from this list use this link\n",
      "\n",
      "To receive future messages in HTML format use this link\n",
      "\n",
      "To change your subscriber information use this link\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text Cleaner Functions (Complete)\n",
    "\n",
    "import re\n",
    "import email\n",
    "import mailparser\n",
    "# import lxml.html as lxml\n",
    "\n",
    "\n",
    "IGNORED_CHARACTERS = \".,<>[]()=:;-/!@#$%^&*()_\\\\+\\\"*@'\"\n",
    "\n",
    "\n",
    "def remove_characters(text):\n",
    "    for c in IGNORED_CHARACTERS:\n",
    "        text = text.replace(c, \"\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def hyper_links(text):\n",
    "    result = re.findall(r'\\b(?:https?|telnet|gopher|file|wais|ftp):[\\w/#~:.?+=&%@!\\-.:?\\\\-]+?(?=[.:?\\-]*(?:[^\\w/#~:.?+=&%@!\\-.:?\\-]|$))', text)\n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_links(text):\n",
    "    result = re.sub(r'\\b(?:https?|telnet|gopher|file|wais|ftp):[\\w/#~:.?+=&%@!\\-.:?\\\\-]+?(?=[.:?\\-]*(?:[^\\w/#~:.?+=&%@!\\-.:?\\-]|$))',\"\" ,text)\n",
    "    return result\n",
    "\n",
    "\n",
    "def payload(text):\n",
    "    mail = mailparser.parse_from_string(text)\n",
    "    \n",
    "    return mail.body\n",
    "\n",
    "\n",
    "def get_payload(text):\n",
    "    result = \"\"\n",
    "    msg = email.message_from_string(text)\n",
    "    if msg.is_multipart():\n",
    "        return msg.get_payload(0, decode=False).__str__()\n",
    "    else:\n",
    "        return msg.get_payload(None, decode=False).__str__()\n",
    "\n",
    "\n",
    "def clean_html(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "\n",
    "# def word_count(text):\n",
    "#     word_count = dict()\n",
    "#     for word in text.split():\n",
    "#         if word in word_count:\n",
    "#             word_count[word] += 1\n",
    "#         else:\n",
    "#             word_count[word] = 1\n",
    "#     return word_count\n",
    "\n",
    "\n",
    "result_string = ham_raw[2476]\n",
    "result_string = get_payload(result_string)\n",
    "result_string = remove_links(result_string)\n",
    "result_string = clean_html(result_string)\n",
    "result_string = remove_characters(result_string)\n",
    "print(result_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content-type: text/plain; charset=\"iso-8859-1\"\n",
      "content-disposition: inline\n",
      "content-transfer-encoding: 7bit\n",
      "\n",
      "to view this newsletter in full-color:\n",
      "http://newsletter.mediaunspun.com/index000021410.cfm\n",
      "\n",
      "media unspun\n",
      "what the press is reporting and why (www.mediaunspun.com)\n",
      "-----------------------------------------------------------------\n",
      "october 8, 2002\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "in this issue\n",
      "-----------------------------------------------------------------\n",
      "* bush covers the waterfront\n",
      "* the biggest cable hookup\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "editor's note\n",
      "-----------------------------------------------------------------\n",
      "is media unspun useful to you? then pass it on to a colleague.\n",
      "the more readers we have, the more successful we'll be. the more \n",
      "successful we are, the more useful we can be to you. pass it\n",
      "on!\n",
      "\n",
      "media unspun serves business news and analysis, authoritatively\n",
      "and irreverently, every business day. an annual subscription\n",
      "costs $50, less than a dollar a week. if your four-week free\n",
      "trial is coming to an end soon, please visit\n",
      "http://www.mediaunspun.com/subscribe.html and sign up via credit card \n",
      "or check.\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "advertisement\n",
      "-----------------------------------------------------------------\n",
      "pop!tech 2002\n",
      "october 18 - 20, 2002: camden, maine\n",
      "join 500 big thinkers to discuss\n",
      "the collision of technology and culture\n",
      "register now at: http://www.poptech.org\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "bush covers the waterfront\n",
      "-----------------------------------------------------------------\n",
      "it may seem like all iraq, all the time in the oval office, but\n",
      "the president has at least one other thing on his mind this\n",
      "week: that pesky port lockout. the freight still isn't moving,\n",
      "factories are running out of parts, produce is rotting, and\n",
      "retailers are more freaked about christmas with every passing\n",
      "day. \n",
      "\n",
      "on monday, bush stepped in and appointed a three-member panel to \n",
      "see how badly this shutdown is hosing the economy. (we hope this \n",
      "isn't a difficult question, as the panel's been given all of one \n",
      "day to report back.) when bush gets the report on tuesday, the\n",
      "next step might be a court order to reopen the ports under the\n",
      "1947 taft-hartley act. that would send employees back to work\n",
      "for 80 days while federal mediators duke it out over the\n",
      "disputed contract and retailers lower their xanax dosages.\n",
      "\n",
      "invoking taft-hartley requires a threat to national health or\n",
      "safety -- not the economy. but labor secretary elaine chao\n",
      "covered that base in a statement on monday, saying the work\n",
      "stoppage threatens the flow of supplies to the military (we knew \n",
      "iraq would be in here somewhere). \"union officials quickly\n",
      "responded that their members have been unloading military cargo\n",
      "throughout the 10-day shutdown,\" said the l.a. times, but an\n",
      "anonymous bush administration official \"said that only a portion \n",
      "of what the defense department needs has made it ashore.\"\n",
      "\n",
      "politically, this has been a tricky one. using taft-hartley\n",
      "would annoy labor right before congressional elections. on the\n",
      "other hand, \"voter discontent with bush's handling of the\n",
      "increasingly fragile economic recovery has begun showing up in\n",
      "polls, and such concerns may have outweighed the political\n",
      "danger to the republican administration,\" said the san francisco \n",
      "chronicle. also, bush stepped in on the same day that a poll\n",
      "reported two-thirds of americans wanted him to focus more on the \n",
      "economy. \"though the administration promised an unbiased\n",
      "examination of the lockout, bush appeared to have made up his\n",
      "mind that it was hurting national security and the economy,\n",
      "andmerited federal intervention,\" said the ap. \n",
      "\n",
      "as for taft-hartley, it's not exactly famous for solving labor\n",
      "disputes. often the 80-day cooling-off period ends, and workers\n",
      "simply walk out again (or get locked out again, in this case).\n",
      "one gets the sense, however, that fixing the dockworkers'\n",
      "contract isn't the point of this particular 80 days. it's 78\n",
      "days until christmas. the race is on. - jen muehlbauer\n",
      "\n",
      "president acts to halt port lockout for 80 days (seattle\n",
      "times)\n",
      "http://tinyurl.com/1usn\n",
      "\n",
      "bush expected to act on ports crisis \n",
      "http://www.accessatlanta.com/ajc/business/1002/08ports.html\n",
      "\n",
      "president moves toward forcing the reopening of west coast\n",
      "ports\n",
      "http://www.latimes.com/business/la-fi-ports8oct08001439,0,1021983.story\n",
      "\n",
      "\n",
      "bush takes step toward halting lockout after west coast port\n",
      "talks break off (ap)\n",
      "http://tinyurl.com/1usk\n",
      "\n",
      "white house intervenes on docks dispute (financial times)\n",
      "http://tinyurl.com/1usm\n",
      "\n",
      "cooling-off period likely in port fight (sf chronicle)\n",
      "http://tinyurl.com/1usp\n",
      "\n",
      "bush moves toward halting port shutdown\n",
      "http://www.nytimes.com/2002/10/08/national/08port.html\n",
      "\n",
      "trouble on the docks\n",
      "http://online.wsj.com/page/0,,2_0864,00.html\n",
      "(paid subscription required.)\n",
      "\n",
      "charges of politics have dogged taft-hartley act\n",
      "http://seattlepi.nwsource.com/business/90243_hartley08.shtml\n",
      "\n",
      "taft-hartley act no quick-fix for port dispute (reuters)\n",
      "http://www.forbes.com/work/newswire/2002/10/02/rtr739458.html\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "advertisement\n",
      "-----------------------------------------------------------------\n",
      "special offer!   save 24% on a subscription to mit technology\n",
      "review. get an inside view into the technologies, deals, and\n",
      "companies emerging from one of the leading research institutes\n",
      "-- mit. \n",
      "http://www.technologyinsider.com/new/news1 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "the biggest cable hookup\n",
      "-----------------------------------------------------------------\n",
      "wo birds want to join forces and the fcc is about to cry \"fowl.\" \n",
      "we mean \"foul.\" the two dominant direct broadcast satellite\n",
      "players want to join forces, the better to compete with big\n",
      "cable. federal regulators, both the fcc and the justice\n",
      "department, are concerned that the resulting conglomerate of\n",
      "directv with dish network would command roughly 95% of satellite \n",
      "service in the us.\n",
      "\n",
      "the press could not settle on a price tag for the proposed\n",
      "merger between echostar communications and hughes electronics -- \n",
      "it was described as being worth anywhere from $15 billion and\n",
      "$25 billion. it was a challenge to keep the players straight, as \n",
      "some outlets talked of a merger between the corporate parents,\n",
      "and others referred to the service monikers. hughes is directv\n",
      "and echostar is dish. all straight?\n",
      "\n",
      "the two companies sent a letter to the fcc urging them to hold\n",
      "off ruling on (read, rejecting) the merger until the justice\n",
      "department has spoken. echostar and hughes offered unspecified\n",
      "\"major revisions\" to the deal that they want to discuss with\n",
      "justice in the next weeks.\n",
      "\n",
      "the wall street journal delved deeply into the form those\n",
      "revisions could take -- specifically, selling some frequencies\n",
      "to cablevision. the journal reported that cablevision has wanted \n",
      "to get into the satellite business for 10 years and outlined the \n",
      "cable company's plans and past spending on such a project.\n",
      "\n",
      "thestreet.com turned in an extensive analysis of the deal for\n",
      "investors in the satellite space. it seems the market for\n",
      "expanded-service television may be nearing saturation.\n",
      "thestreet.com quoted an analyst's report which concluded,\n",
      "\"consumers should benefit from ... continued rivalry, but\n",
      "shareholders may realize much smaller returns.\"\n",
      "\n",
      "the new york times and the journal both mentioned rupert murdoch \n",
      "waiting in the wings. last year murdoch's news corp. bid for\n",
      "directv, but lost out at the last minute to echostar. if the\n",
      "current deal falls through, he'll be back. - keith dawson\n",
      "\n",
      "echostar and hughes propose concessions in bid to save deal\n",
      "http://online.wsj.com/article/0,,sb103403314258094560,00.html\n",
      "(paid subscription required)\n",
      "\n",
      "regulators set to block echostar's hughes purchase\n",
      "http://online.wsj.com/article/0,,sb1033939901346228393,00.html\n",
      "(paid subscription required)\n",
      "\n",
      "'last-ditch effort' (rocky mountain news)\n",
      "http://tinyurl.com/1upi\n",
      "\n",
      "echostar, hughes see a glimmer of hope\n",
      "http://www.thestreet.com/tech/georgemannes/10046366.html\n",
      "\n",
      "f.c.c. asked to put off merger ruling\n",
      "http://www.nytimes.com/2002/10/08/business/media/08bird.html\n",
      "\n",
      "echostar, hughes ask fcc to defer decision\n",
      "http://www.nypost.com/business/59145.htm\n",
      "\n",
      "echostar, hughes offer merger changes (reuters) \n",
      "http://news.com.com/2100-1023-961138.html\n",
      "\n",
      "delay in satellite-tv merger ok requested (ap)\n",
      "http://www.bayarea.com/mld/mercurynews/business/4236430.htm\n",
      "\n",
      "echostar, hughes seek to delay ruling\n",
      "http://www.latimes.com/technology/la-fi-echo8oct08,0,3454976.story\n",
      "\n",
      "\n",
      "echostar pleads to fcc on merger (denver post)\n",
      "http://tinyurl.com/1ut7\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "other stories\n",
      "-----------------------------------------------------------------\n",
      "sec probes aol-oxygen pact for double-booking of revenue\n",
      "http://online.wsj.com/article/0,,sb1033938113684731193,00.html\n",
      "(paid subscription required.)\n",
      "\n",
      "tivo raises $25 million in stock offering (ap)\n",
      "http://www.siliconvalley.com/mld/siliconvalley/4235118.htm\n",
      "\n",
      "worldcom officer pleads guilty to fraud\n",
      "http://www.washingtonpost.com/wp-dyn/articles/a57300-2002oct7.html\n",
      "\n",
      "\n",
      "two magazines are shut and a third revamps\n",
      "http://www.nytimes.com/2002/10/08/business/media/08mag.html\n",
      "\n",
      "regulators say they have csfb 'smoking gun'\n",
      "http://www.usatoday.com/money/industries/banking/2002-10-06-csfb_x.htm\n",
      "\n",
      "\n",
      "expected cold winter could increase natural gas prices \n",
      "http://www.accessatlanta.com/ajc/business/1002/08gas.html\n",
      "\n",
      "frozen world found beyond pluto\n",
      "http://www.msnbc.com/news/818195.asp\n",
      "\n",
      "fool me once\n",
      "http://www.nytimes.com/2002/10/08/opinion/08krug.html\n",
      "\n",
      "new northwest system for internet bookings\n",
      "http://www.nytimes.com/2002/10/08/business/08memo.html\n",
      "\n",
      "the fastest-growing tech companies\n",
      "http://www.business2.com/b2100/0,,1-1,00.html\n",
      "\n",
      "debating the baby bells\n",
      "http://www.nytimes.com/2002/10/07/business/07plac.html\n",
      "(paid subscription required)\n",
      "\n",
      "silicon valley is yearning for user-friendly microsoft\n",
      "http://online.wsj.com/article/0,,sb1034036651300028760,00.html\n",
      "(paid subscription required)\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "do you want to reach the net's savviest audience?\n",
      "advertise in media unspun.\n",
      "contact erik vanderkolk for details at erikvanderkolk@yahoo.com \n",
      "today.\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "staff\n",
      "-----------------------------------------------------------------\n",
      "written by deborah asbrand (dasbrand@world.std.com), keith\n",
      "dawson (dawson@world.std.com), jen muehlbauer\n",
      "(jen@englishmajor.com), and lori patel (loripatel@hotmail.com).\n",
      "\n",
      "copyedited by jim duffy (jimduffy86@yahoo.com). \n",
      "advertising: erik vanderkolk (erikvanderkolk@yahoo.com). \n",
      "editor and publisher: jimmy guterman (guterman@vineyard.com).\n",
      "\n",
      "media unspun is produced by the vineyard group inc. \n",
      "copyright 2002 media unspun, inc., and the vineyard group, inc.\n",
      "\n",
      "subscribe already, willya? http://www.mediaunspun.com\n",
      " \n",
      "redistribution by email is permitted as long as a link to\n",
      "http://newsletter.mediaunspun.com is included.\n",
      "\n",
      "\n",
      "-|________________\n",
      "powered by: http://www.imakenews.com\n",
      "to be removed from this list, use this link:\n",
      "http://www.imakenews.com/eletra/remove.cfm?x=mediaunspun%2czzzz-unspun@spamassassin.taint.org\n",
      "to receive future messages in html format, use this link:\n",
      "http://www.imakenews.com/eletra/change.cfm?x=mediaunspun%2czzzz-unspun@spamassassin.taint.org%2chtm\n",
      "to change your subscriber information, use this link:\n",
      "http://www.imakenews.com/eletra/update.cfm?x=mediaunspun%2czzzz-unspun@spamassassin.taint.org\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text Cleaner (Complete)\n",
    "\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, toLowerCase=False, removeLinks=True, cleanHTML=True):\n",
    "        self.toLowerCase = toLowerCase\n",
    "        self.removeLinks = removeLinks\n",
    "        self.cleanHTML = cleanHTML\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        result = []\n",
    "        for text in X:\n",
    "            temp = get_payload(text)\n",
    "            if self.removeLinks:\n",
    "                temp = remove_links(temp)\n",
    "            if self.cleanHTML:\n",
    "                temp = clean_html(temp)\n",
    "            if self.removeLinks:\n",
    "                temp = remove_characters(temp)\n",
    "            if self.toLowerCase:\n",
    "                temp = temp[:].lower()\n",
    "            result.append(temp)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "cleaner = TextCleaner(toLowerCase=True, removeLinks=False)\n",
    "cleaned_spam = cleaner.transform(spam_raw)\n",
    "cleaned_ham = cleaner.transform(ham_raw)\n",
    "\n",
    "print(cleaned_ham[2476])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<option', 'kingdom', 'enenkio', 'islands', 'marshall', 'u.s.', 'king', 'atoll', 'grants', 'guide', 'contains', 'eneen-kio', 'the', 'wake', 'name', 'les', 'marshallese', 'pour', 'enenkio,', 'shangrila', 'zowie', 'botanical', 'wowie', 'atoll,', 'ratak', 'hermios', 'send', 'hermios,', 'emails', 'value=3d=', 'northern', 'majesty', 'murjel', 'guides', 'address', '\\\\tab', 'iroijlaplap', 'oz.', 'nation', 'rmi', '(tm)', 'jurisdiction', 'vous', 'internal', 'color=red><img', 'monarch', 'atolls', 'moore', 'intro', 'kathmandu']\n"
     ]
    }
   ],
   "source": [
    "# Word Occurance Analysis\n",
    "\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def subtract_dicts(dict1, dict2):\n",
    "    size_factor = len(dict1) / len(dict2)\n",
    "    result = OrderedDict(dict1)\n",
    "    for element in dict2.keys():\n",
    "        if element in result.keys():\n",
    "            result[element] = dict1.get(element, 0) - dict2.get(element, 0) * size_factor\n",
    "        else:\n",
    "            result[element] = 0\n",
    "            \n",
    "    dict1 = OrderedDict(sorted(result.items(), key=itemgetter(1), reverse=True))\n",
    "    return result\n",
    "    \n",
    "\n",
    "# Most Used Words\n",
    "def count_words_in_string(text):\n",
    "    result = OrderedDict()\n",
    "    for word in text.split():\n",
    "        if word in result:\n",
    "            result[word] = result[word] + 1\n",
    "        else:\n",
    "            result[word] = 1  \n",
    "    return result\n",
    "\n",
    "def filter_words(words):\n",
    "    filtered_words = []\n",
    "    for word_el in words:\n",
    "        if len(word_el) < 15 and len(word_el) > 2:\n",
    "            filtered_words.append(word_el)\n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "spam_words = OrderedDict()\n",
    "ham_words = OrderedDict()\n",
    "\n",
    "\n",
    "\n",
    "for elem in cleaned_spam:\n",
    "    spam_words.update(count_words_in_string(elem))\n",
    "\n",
    "for elem in cleaned_ham:\n",
    "    ham_words.update(count_words_in_string(elem))\n",
    "    \n",
    "\n",
    "spam_words = OrderedDict(sorted(spam_words.items(), key=itemgetter(1), reverse=True))\n",
    "ham_words = OrderedDict(sorted(ham_words.items(), key=itemgetter(1), reverse=True))\n",
    "\n",
    "\n",
    "\n",
    "result = OrderedDict()\n",
    "result = subtract_dicts(spam_words, ham_words)\n",
    "result = filter_words(list(result.keys()))\n",
    "\n",
    "\n",
    "word_vector_labels = list(result)\n",
    "\n",
    "print(word_vector_labels[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "missing ), unterminated subpattern at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6f4ff4d8a97a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# words_spam = pd.DataFrame(counter.fit_transform(spam_raw))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mwords_ham\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mham_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# df_spam = pd.concat([attributes_spam, words_spam], axis=1, sort=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/machine-learning/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-6f4ff4d8a97a>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk_word\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/machine-learning/lib/python3.6/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/machine-learning/lib/python3.6/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/machine-learning/lib/python3.6/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/machine-learning/lib/python3.6/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, pattern)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/machine-learning/lib/python3.6/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0;32m--> 416\u001b[0;31m                            not nested and not items))\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/machine-learning/lib/python3.6/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\")\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 raise source.error(\"missing ), unterminated subpattern\",\n\u001b[0;32m--> 768\u001b[0;31m                                    source.tell() - start)\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosegroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: missing ), unterminated subpattern at position 0"
     ]
    }
   ],
   "source": [
    "# Transformer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Categorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, spam=1):\n",
    "        self.spam = spam\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        link_count = []\n",
    "        label = []\n",
    "        for elem in X:\n",
    "            link_count.append(len(hyper_links(elem)))\n",
    "            label.append(self.spam)\n",
    "        d = {'label': label, 'link_count': link_count}\n",
    "        result = pd.DataFrame(data=d, dtype=np.int)\n",
    "        return result\n",
    "            \n",
    "            \n",
    "class WordCounter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key_words):\n",
    "        self.key_words = key_words\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        tmp = []\n",
    "        for text in X:\n",
    "            for k_word in self.key_words:\n",
    "                tmp.append(len(re.findall(k_word, text)))\n",
    "        return np.array(tmp).reshape(len(X), len(self.key_words))\n",
    "    \n",
    "\n",
    "# cat = Categorizer()\n",
    "# attributes_spam = cat.fit_transform(spam_raw)\n",
    "cat = Categorizer(spam=0)\n",
    "attributes_ham = cat.fit_transform(ham_raw)\n",
    "\n",
    "counter = WordCounter(key_words=word_vector_labels)\n",
    "# np.set_printoptions(threshold=np.nan)\n",
    "# print(counter.fit_transform(spam_raw))\n",
    "\n",
    "# words_spam = pd.DataFrame(counter.fit_transform(spam_raw))\n",
    "words_ham = pd.DataFrame(counter.fit_transform(ham_raw))\n",
    "\n",
    "# df_spam = pd.concat([attributes_spam, words_spam], axis=1, sort=False)\n",
    "df_ham = pd.concat([attributes_ham, words_ham], axis=1, sort=False)\n",
    "\n",
    "# print(df_ham)\n",
    "\n",
    "# combine = pd.concat([df_spam, df_ham], axis=0)\n",
    "\n",
    "# print(df_ham)\n",
    "  # Base Attributes\n",
    "base_attribute_cat = Categorizer(spam=0)\n",
    "base_attributes = base_attribute_cat.fit_transform(X=ham_raw, y=None)\n",
    "# Word Analysis\n",
    "counter = WordCounter(key_words=word_vector_labels)\n",
    "words = pd.DataFrame(counter.fit_transform(ham_raw), dtype=np.int)\n",
    "\n",
    "# Combiner\n",
    "data_frame= pd.concat([base_attributes, words], axis=1, sort=False)\n",
    "# print(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3002, 22)\n",
      "59706\n"
     ]
    }
   ],
   "source": [
    "# Pipelines\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "class DataFrameGenerator(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, key_words_count=20, key_words=None, link_count=True, label=None):\n",
    "        self.key_words_count = key_words_count  # How many Keywords will get used\n",
    "        self.link_count = link_count  # Count of Links in Text as Attribute\n",
    "        self.key_words = key_words  # List of Words that get used as key words\n",
    "        self.label = label  # Label that gets assigned to each element in the DF\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Base Attributes\n",
    "        base_attribute_cat = Categorizer(spam=self.label)\n",
    "        base_attributes = base_attribute_cat.fit_transform(X=X, y=None)\n",
    "        \n",
    "        cleaner = TextCleaner(cleanHTML=False)\n",
    "        X = cleaner.fit_transform(X)\n",
    "        # Word Analysis\n",
    "        counter = WordCounter(key_words=self.key_words[:self.key_words_count])\n",
    "        words = pd.DataFrame(counter.fit_transform(X=X, y=None))\n",
    "\n",
    "        # Combiner\n",
    "        data_frame = pd.concat([base_attributes, words], axis=1, sort=False)\n",
    "        return data_frame\n",
    "        \n",
    "        \n",
    "        \n",
    "spam_processing_pipeline = Pipeline([\n",
    "    ('text_processor', TextCleaner(removeLinks=False)),\n",
    "    ('df_generator', DataFrameGenerator(key_words_count=20, key_words=word_vector_labels, label=1, \n",
    "                                        link_count=True))\n",
    "])\n",
    "\n",
    "        \n",
    "ham_processing_pipeline = Pipeline([\n",
    "    ('text_processor', TextCleaner(removeLinks=False)),\n",
    "    ('df_generator', DataFrameGenerator(key_words_count=20, key_words=word_vector_labels, label=0, \n",
    "                                        link_count=True))\n",
    "])\n",
    "\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attributes='label'):\n",
    "        self.attributes = attributes\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if(self.attributes == 'label'):\n",
    "            return X.iloc[:, 0].values\n",
    "        if(self.attributes == 'attributes'):\n",
    "            return X.iloc[:, 1:].values\n",
    "\n",
    "\n",
    "class FrameCombiner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "spam_data = spam_processing_pipeline.fit_transform(spam_raw)\n",
    "\n",
    "ham_data = ham_processing_pipeline.fit_transform(ham_raw)\n",
    "\n",
    "\n",
    "data = pd.concat([spam_data, ham_data])\n",
    "\n",
    "print(data.shape)\n",
    "print(len(word_vector_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/Applications/anaconda3/envs/machine-learning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "data_rand = shuffle(data)\n",
    "\n",
    "\n",
    "svm = svm.SVC(kernel='linear',C = 200)\n",
    "\n",
    "classifier = SGDClassifier(random_state=20, max_iter=5)\n",
    "    \n",
    "data_selector = DataFrameSelector(attributes='attributes')\n",
    "label_selector = DataFrameSelector(attributes='label')\n",
    "\n",
    "training_data = data_selector.fit_transform(data_rand)[:2000]\n",
    "training_labels = label_selector.fit_transform(data_rand)[:2000]\n",
    "\n",
    "# print(training_labels)\n",
    "\n",
    "classifier.fit(training_data, training_labels)\n",
    "svm.fit(training_data, training_labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P=  [0 0 0 ... 0 0 0]\n",
      "L=  [0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "testing_data = data_selector.fit_transform(data_rand)[2000:]\n",
    "testing_labels = label_selector.fit_transform(data_rand)[2000:]\n",
    "\n",
    "# predictions = classifier.predict(testing_data)\n",
    "predictions = svm.predict(testing_data)\n",
    "\n",
    "print(\"P= \", predictions)\n",
    "print(\"L= \", testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/Applications/anaconda3/envs/machine-learning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/lucas/Applications/anaconda3/envs/machine-learning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/lucas/Applications/anaconda3/envs/machine-learning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "168\n",
      "1002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score = cross_val_score(classifier, testing_data, testing_labels, cv=3, scoring='accuracy')\n",
    "\n",
    "\n",
    "x = np.linspace(0, len(predictions), len(predictions))\n",
    "# print(len(x), len(predictions))\n",
    "test = [predictions, testing_labels]\n",
    "\n",
    "min, max = 250, 300\n",
    "\n",
    "plt.scatter(x[min:max], predictions[min:max])\n",
    "plt.scatter(x[min:max], testing_labels[min:max], marker='*')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if testing_labels[i] == 1:\n",
    "        total += 1\n",
    "        if predictions[i] == testing_labels[i]:\n",
    "            correct += 1\n",
    "\n",
    "print(correct)\n",
    "print(total)\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023529411764705882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "conf_mtrx = f1_score(predictions, testing_labels)\n",
    "\n",
    "print(conf_mtrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
